
@article{public_health_england_official_2020,
	title = {Official {UK} {Coronavirus} {Dashboard}},
	url = {https://coronavirus.data.gov.uk/details/cases},
	author = {{Public Health England}},
	month = nov,
	year = {2020},
}

@misc{noauthor_european_nodate,
	title = {European {Covid}-19 {Forecast} {Hub}},
	url = {https://covid19forecasthub.eu/},
}

@article{wong_evidence_2020,
	title = {Evidence that coronavirus superspreading is fat-tailed},
	volume = {117},
	doi = {10.1073/pnas.2018490117},
	abstract = {Superspreaders, infected individuals who result in an outsized number of secondary cases, are believed to underlie a significant fraction of total SARS-CoV-2 transmission. Here, we combine empirical observations of SARS-CoV and SARS-CoV-2 transmission and extreme value statistics to show that the distribution of secondary cases is consistent with being fat-tailed, implying that large superspreading events are extremal, yet probable, occurrences. We integrate these results with interaction-based network models of disease transmission and show that superspreading, when it is fat-tailed, leads to pronounced transmission by increasing dispersion. Our findings indicate that large superspreading events should be the targets of interventions that minimize tail exposure.},
	number = {47},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Wong, Felix and Collins, James J.},
	month = nov,
	year = {2020},
}

@article{gelman_weakly_2008,
	title = {A weakly informative default prior distribution for logistic and other regression models},
	volume = {2},
	doi = {10.1214/08-AOAS191},
	number = {4},
	journal = {The Annals of Applied Statistics},
	author = {Gelman, Andrew and Jakulin, Aleks and Pittau, Maria Grazia and Su, Yu-Sung},
	month = dec,
	year = {2008},
}

@article{gelman_philosophy_2013,
	title = {Philosophy and the practice of {Bayesian} statistics},
	volume = {66},
	doi = {10.1111/j.2044-8317.2011.02037.x},
	number = {1},
	journal = {British Journal of Mathematical and Statistical Psychology},
	author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
	month = feb,
	year = {2013},
}

@article{grinsztajn_bayesian_2021,
	title = {Bayesian workflow for disease transmission modeling in {Stan}},
	author = {Grinsztajn, Léo and Semenova, Elizaveta and Margossian, Charles C and Riou, Julien},
	year = {2021},
}

@article{olney_estimating_2021,
	title = {Estimating the {Effect} of {Social} {Distancing} {Interventions} on {COVID}-19 in the {United} {States}},
	doi = {10.1093/aje/kwaa293},
	abstract = {Since its global emergence in 2020, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused multiple epidemics in the United States. Because medical treatments for the virus are still emerging and a vaccine is not yet available, state and local governments have sought to limit its spread by enacting various social distancing interventions such as school closures and lockdown, but the effectiveness of these interventions is unknown. We applied an established, semi-mechanistic Bayesian hierarchical model of these interventions on SARS-CoV-2 spread in Europe to the United States, using case fatalities from February 29, 2020 up to April 25, 2020, when some states began reversing their interventions. We estimated the effect of interventions across all states, contrasted the estimated reproduction number, Rt, for each state before and after lockdown, and contrasted predicted future fatalities with actual fatalities as a check on the model’s validity. Overall, school closures and lockdown are the only interventions modeled that have a reliable impact on Rt, and lockdown appears to have played a key role in reducing Rt below 1.0. We conclude that reversal of lockdown, without implementation of additional, equally effective interventions, will enable continued, sustained transmission of SARS-CoV-2 in the United States.},
	journal = {American Journal of Epidemiology},
	author = {Olney, Andrew M and Smith, Jesse and Sen, Saunak and Thomas, Fridtjof and Unwin, H Juliette T},
	month = jan,
	year = {2021},
}

@article{chatzilena_contemporary_2019,
	title = {Contemporary statistical inference for infectious disease models using {Stan}},
	volume = {29},
	doi = {10.1016/j.epidem.2019.100367},
	journal = {Epidemics},
	author = {Chatzilena, Anastasia and van Leeuwen, Edwin and Ratmann, Oliver and Baguelin, Marc and Demiris, Nikolaos},
	month = dec,
	year = {2019},
}

@article{van_doremalen_aerosol_2020,
	title = {Aerosol and {Surface} {Stability} of {SARS}-{CoV}-2 as {Compared} with {SARS}-{CoV}-1},
	volume = {382},
	doi = {10.1056/NEJMc2004973},
	number = {16},
	journal = {New England Journal of Medicine},
	author = {van Doremalen, Neeltje and Bushmaker, Trenton and Morris, Dylan H. and Holbrook, Myndi G. and Gamble, Amandine and Williamson, Brandi N. and Tamin, Azaibi and Harcourt, Jennifer L. and Thornburg, Natalie J. and Gerber, Susan I. and Lloyd-Smith, James O. and de Wit, Emmie and Munster, Vincent J.},
	month = apr,
	year = {2020},
}

@article{hauser_estimation_2020,
	title = {Estimation of {SARS}-{CoV}-2 mortality during the early stages of an epidemic: {A} modeling study in {Hubei}, {China}, and six regions in {Europe}},
	volume = {17},
	doi = {10.1371/journal.pmed.1003189},
	number = {7},
	journal = {PLOS Medicine},
	author = {Hauser, Anthony and Counotte, Michel J. and Margossian, Charles C. and Konstantinoudis, Garyfallos and Low, Nicola and Althaus, Christian L. and Riou, Julien},
	month = jul,
	year = {2020},
}

@article{held_modeling_2012,
	title = {Modeling seasonality in space-time infectious disease surveillance data},
	volume = {54},
	doi = {10.1002/bimj.201200037},
	number = {6},
	journal = {Biometrical Journal},
	author = {Held, Leonhard and Paul, Michaela},
	month = nov,
	year = {2012},
}

@article{paul_predictive_2011,
	title = {Predictive assessment of a non-linear random effects model for multivariate time series of infectious disease counts},
	volume = {30},
	doi = {10.1002/sim.4177},
	number = {10},
	journal = {Statistics in Medicine},
	author = {Paul, M. and Held, L.},
	month = may,
	year = {2011},
}

@article{paul_multivariate_2008,
	title = {Multivariate modelling of infectious disease surveillance data},
	volume = {27},
	doi = {10.1002/sim.3440},
	number = {29},
	journal = {Statistics in Medicine},
	author = {Paul, M. and Held, L. and Toschke, A. M.},
	month = dec,
	year = {2008},
}

@article{held_statistical_2005,
	title = {A statistical framework for the analysis of multivariate infectious disease surveillance counts},
	volume = {5},
	doi = {10.1191/1471082X05st098oa},
	abstract = {A framework for the statistical analysis of counts from infectious disease surveillance databases is proposed. In its simplest form, the model can be seen as a Poisson branching process model with immigration. Extensions to include seasonal effects, time trends and overdispersion are outlined. The model is shown to provide an adequate fit and reliable one-step-ahead prediction intervals for a typical infectious disease time series. In addition, a multivariate formulation is proposed, which is well suited to capture space-time dependence caused by the spatial spread of a disease over time. An analysis of two multivariate time series is described. All analyses have been done using general optimization routines, where ML estimates and corresponding standard errors are readily available.},
	number = {3},
	journal = {Statistical Modelling},
	author = {Held, Leonhard and Höhle, Michael and Hofmann, Mathias},
	month = oct,
	year = {2005},
}

@article{meyer_spatio-temporal_2017,
	title = {Spatio-{Temporal} {Analysis} of {Epidemic} {Phenomena} {Using} the {R} {Package} surveillance},
	volume = {77},
	doi = {10.18637/jss.v077.i11},
	number = {11},
	journal = {Journal of Statistical Software},
	author = {Meyer, Sebastian and Held, Leonhard and Höhle, Michael},
	year = {2017},
}

@article{liboschik_tscount_2017,
	title = {\{tscount\}: {An} \{{R}\} {Package} for {Analysis} of {Count} {Time} {Series} {Following} {Generalized} {Linear} {Models}},
	volume = {82},
	doi = {10.18637/jss.v082.i05},
	number = {5},
	journal = {Journal of Statistical Software},
	author = {Liboschik, Tobias and Fokianos, Konstantinos and Fried, Roland},
	year = {2017},
	pages = {1--51},
}

@article{vasileios_acp_2015,
	title = {acp: {Autoregressive} {Conditional} {Poisson}},
	url = {https://cran.r-project.org/package=acp},
	author = {Vasileios, Siakoulis},
	year = {2015},
	annote = {R package version 2.1},
}

@misc{noauthor_comprehensive_nodate,
	title = {The {Comprehensive} {R} {Archive} {Network}},
}

@misc{noauthor_r_nodate,
	title = {The {R} {Epidemics} {Consortium}},
	url = {https://www.repidemicsconsortium.org/},
}

@article{jenness_epimodel_2018,
	title = {{EpiModel} : {An} {R} {Package} for {Mathematical} {Modeling} of {Infectious} {Disease} over {Networks}},
	volume = {84},
	doi = {10.18637/jss.v084.i08},
	number = {8},
	journal = {Journal of Statistical Software},
	author = {Jenness, Samuel M. and Goodreau, Steven M. and Morris, Martina},
	year = {2018},
}

@article{groendyke_epinet_2018,
	title = {epinet : {An} {R} {Package} to {Analyze} {Epidemics} {Spread} across {Contact} {Networks}},
	volume = {83},
	doi = {10.18637/jss.v083.i11},
	number = {11},
	journal = {Journal of Statistical Software},
	author = {Groendyke, Chris and Welch, David},
	year = {2018},
}

@article{merl_amei_2010,
	title = {amei : {An} {R} {Package} for the {Adaptive} {Management} of {Epidemiological} {Interventions}},
	volume = {36},
	doi = {10.18637/jss.v036.i06},
	number = {6},
	journal = {Journal of Statistical Software},
	author = {Merl, Daniel and Johnson, Leah R. and Gramacy, Robert B. and Mangel, Marc},
	year = {2010},
}

@article{hohle_rladybugr_2007,
	title = {{RLadyBug}—{An} {R} package for stochastic epidemic models},
	volume = {52},
	doi = {10.1016/j.csda.2006.11.016},
	number = {2},
	journal = {Computational Statistics {\textbackslash}\& Data Analysis},
	author = {Höhle, Michael and Feldmann, Ulrike},
	month = oct,
	year = {2007},
}

@book{andersson_stochastic_2000,
	address = {New York, NY},
	title = {Stochastic {Epidemic} {Models} and {Their} {Statistical} {Analysis}},
	volume = {151},
	isbn = {978-0-387-95050-1},
	publisher = {Springer New York},
	author = {Andersson, Håkan and Britton, Tom},
	year = {2000},
	doi = {10.1007/978-1-4612-1158-7},
}

@article{obadia_r0_2012,
	title = {The {R0} package: a toolbox to estimate reproduction numbers for epidemic outbreaks},
	volume = {12},
	doi = {10.1186/1472-6947-12-147},
	number = {1},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Obadia, Thomas and Haneef, Romana and Boëlle, Pierre-Yves},
	month = dec,
	year = {2012},
}

@article{hawryluk_inference_2020,
	title = {Inference of {COVID}-19 epidemiological distributions from {Brazilian} hospital data},
	volume = {17},
	doi = {10.1098/rsif.2020.0596},
	abstract = {Knowing COVID-19 epidemiological distributions, such as the time from patient admission to death, is directly relevant to effective primary and secondary care planning, and moreover, the mathematical modelling of the pandemic generally. We determine epidemiological distributions for patients hospitalized with COVID-19 using a large dataset ( N = 21 000 − 157 000) from the Brazilian Sistema de Informação de Vigilância Epidemiológica da Gripe database. A joint Bayesian subnational model with partial pooling is used to simultaneously describe the 26 states and one federal district of Brazil, and shows significant variation in the mean of the symptom-onset-to-death time, with ranges between 11.2 and 17.8 days across the different states, and a mean of 15.2 days for Brazil. We find strong evidence in favour of specific probability density function choices: for example, the gamma distribution gives the best fit for onset-to-death and the generalized lognormal for onset-to-hospital-admission. Our results show that epidemiological distributions have considerable geographical variation, and provide the first estimates of these distributions in a low and middle-income setting. At the subnational level, variation in COVID-19 outcome timings are found to be correlated with poverty, deprivation and segregation levels, and weaker correlation is observed for mean age, wealth and urbanicity.},
	number = {172},
	journal = {Journal of The Royal Society Interface},
	author = {Hawryluk, Iwona and Mellan, Thomas A. and Hoeltgebaum, Henrique and Mishra, Swapnil and Schnekenberg, Ricardo P. and Whittaker, Charles and Zhu, Harrison and Gandy, Axel and Donnelly, Christl A. and Flaxman, Seth and Bhatt, Samir},
	month = nov,
	year = {2020},
}

@article{olney_estimating_2021-1,
	title = {Estimating the {Effect} of {Social} {Distancing} {Interventions} on {COVID}-19 in the {United} {States}},
	doi = {10.1093/aje/kwaa293},
	abstract = {Since its global emergence in 2020, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused multiple epidemics in the United States. Because medical treatments for the virus are still emerging and a vaccine is not yet available, state and local governments have sought to limit its spread by enacting various social distancing interventions such as school closures and lockdown, but the effectiveness of these interventions is unknown. We applied an established, semi-mechanistic Bayesian hierarchical model of these interventions on SARS-CoV-2 spread in Europe to the United States, using case fatalities from February 29, 2020 up to April 25, 2020, when some states began reversing their interventions. We estimated the effect of interventions across all states, contrasted the estimated reproduction number, Rt, for each state before and after lockdown, and contrasted predicted future fatalities with actual fatalities as a check on the model’s validity. Overall, school closures and lockdown are the only interventions modeled that have a reliable impact on Rt, and lockdown appears to have played a key role in reducing Rt below 1.0. We conclude that reversal of lockdown, without implementation of additional, equally effective interventions, will enable continued, sustained transmission of SARS-CoV-2 in the United States.},
	journal = {American Journal of Epidemiology},
	author = {Olney, Andrew M and Smith, Jesse and Sen, Saunak and Thomas, Fridtjof and Unwin, H Juliette T},
	month = jan,
	year = {2021},
}

@article{faria_genomics_2021,
	title = {Genomics and epidemiology of the {P}.1 {SARS}-{CoV}-2 lineage in {Manaus}, {Brazil}},
	doi = {10.1126/science.abh2644},
	abstract = {Cases of SARS-CoV-2 infection in Manaus, Brazil, resurged in late 2020, despite previously high levels of infection. Genome sequencing of viruses sampled in Manaus between November 2020 and January 2021 revealed the emergence and circulation of a novel SARS-CoV-2 variant of concern. Lineage P.1, acquired 17 mutations, including a trio in the spike protein (K417T, E484K and N501Y) associated with increased binding to the human ACE2 receptor. Molecular clock analysis shows that P.1 emergence occurred around mid-November 2020 and was preceded by a period of faster molecular evolution. Using a two-category dynamical model that integrates genomic and mortality data, we estimate that P.1 may be 1.7–2.4-fold more transmissible, and that previous (non-P.1) infection provides 54–79\% of the protection against infection with P.1 that it provides against non-P.1 lineages. Enhanced global genomic surveillance of variants of concern, which may exhibit increased transmissibility and/or immune evasion, is critical to accelerate pandemic responsiveness.},
	journal = {Science},
	author = {Faria, Nuno R. and Mellan, Thomas A. and Whittaker, Charles and Claro, Ingra M. and Candido, Darlan da S. and Mishra, Swapnil and Crispim, Myuki A. E. and Sales, Flavia C. S. and Hawryluk, Iwona and McCrone, John T. and Hulswit, Ruben J. G. and Franco, Lucas A. M. and Ramundo, Mariana S. and de Jesus, Jaqueline G. and Andrade, Pamela S. and Coletti, Thais M. and Ferreira, Giulia M. and Silva, Camila A. M. and Manuli, Erika R. and Pereira, Rafael H. M. and Peixoto, Pedro S. and Kraemer, Moritz U. G. and Gaburo, Nelson and Camilo, Cecilia da C. and Hoeltgebaum, Henrique and Souza, William M. and Rocha, Esmenia C. and de Souza, Leandro M. and de Pinho, Mariana C. and Araujo, Leonardo J. T and Malta, Frederico S. V. and de Lima, Aline B. and Silva, Joice do P. and Zauli, Danielle A. G. and Ferreira, Alessandro C. de S. and Schnekenberg, Ricardo P and Laydon, Daniel J. and Walker, Patrick G. T. and Schlüter, Hannah M. and dos Santos, Ana L. P. and Vidal, Maria S. and Del Caro, Valentina S. and Filho, Rosinaldo M. F. and dos Santos, Helem M. and Aguiar, Renato S. and Proença-Modena, José L. and Nelson, Bruce and Hay, James A. and Monod, Mélodie and Miscouridou, Xenia and Coupland, Helen and Sonabend, Raphael and Vollmer, Michaela and Gandy, Axel and Prete, Carlos A. and Nascimento, Vitor H. and Suchard, Marc A. and Bowden, Thomas A. and Pond, Sergei L. K. and Wu, Chieh-Hsi and Ratmann, Oliver and Ferguson, Neil M. and Dye, Christopher and Loman, Nick J. and Lemey, Philippe and Rambaut, Andrew and Fraiji, Nelson A. and Carvalho, Maria do P. S. S. and Pybus, Oliver G. and Flaxman, Seth and Bhatt, Samir and Sabino, Ester C.},
	month = apr,
	year = {2021},
}

@article{unwin_state-level_2020,
	title = {State-level tracking of {COVID}-19 in the {United} {States}},
	volume = {11},
	doi = {10.1038/s41467-020-19652-6},
	abstract = {As of 1st June 2020, the US Centres for Disease Control and Prevention reported 104,232 confirmed or probable COVID-19-related deaths in the US. This was more than twice the number of deaths reported in the next most severely impacted country. We jointly model the US epidemic at the state-level, using publicly available death data within a Bayesian hierarchical semi-mechanistic framework. For each state, we estimate the number of individuals that have been infected, the number of individuals that are currently infectious and the time-varying reproduction number (the average number of secondary infections caused by an infected person). We use changes in mobility to capture the impact that non-pharmaceutical interventions and other behaviour changes have on the rate of transmission of SARS-CoV-2. We estimate that Rt was only below one in 23 states on 1st June. We also estimate that 3.7\% [3.4\%–4.0\%] of the total population of the US had been infected, with wide variation between states, and approximately 0.01\% of the population was infectious. We demonstrate good 3 week model forecasts of deaths with low error and good coverage of our credible intervals.},
	number = {1},
	journal = {Nature Communications},
	author = {Unwin, H. Juliette T. and Mishra, Swapnil and Bradley, Valerie C. and Gandy, Axel and Mellan, Thomas A. and Coupland, Helen and Ish-Horowicz, Jonathan and Vollmer, Michaela A.C. and Whittaker, Charles and Filippi, Sarah L. and Xi, Xiaoyue and Monod, Mélodie and Ratmann, Oliver and Hutchinson, Michael and Valka, Fabian and Zhu, Harrison and Hawryluk, Iwona and Milton, Philip and Ainslie, Kylie E.C. and Baguelin, Marc and Boonyasiri, Adhiratha and Brazeau, Nick F. and Cattarino, Lorenzo and Cucunuba, Zulma and Cuomo-Dannenburg, Gina and Dorigatti, Ilaria and Eales, Oliver D. and Eaton, Jeffrey W. and van Elsland, Sabine L. and FitzJohn, Richard G. and Gaythorpe, Katy A.M. and Green, William and Hinsley, Wes and Jeffrey, Benjamin and Knock, Edward and Laydon, Daniel J. and Lees, John and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Okell, Lucy and Parag, Kris V. and Siveroni, Igor and Thompson, Hayley A. and Walker, Patrick and Walters, Caroline E. and Watson, Oliver J. and Whittles, Lilith K. and Ghani, Azra C. and Ferguson, Neil M. and Riley, Steven and Donnelly, Christl A. and Bhatt, Samir and Flaxman, Seth},
	year = {2020},
}

@article{mellan_subnational_2020,
	title = {Subnational analysis of the {COVID}-19 epidemic in {Brazil}},
	doi = {10.1101/2020.05.09.20096701},
	abstract = {Brazil is currently reporting the second highest number of COVID-19 deaths in the world. Here we characterise the initial dynamics of COVID-19 across the country and assess the impact of non-pharmaceutical interventions (NPIs) that were implemented using a semi-mechanistic Bayesian hierarchical modelling approach. Our results highlight the significant impact these NPIs had across states, reducing an average Rt {\textgreater} 3 to an average of 1.5 by 9-May-2020, but that these interventions failed to reduce Rt {\textless} 1, congruent with the worsening epidemic Brazil has experienced since. We identify extensive heterogeneity in the epidemic trajectory across Brazil, with the estimated number of days to reach 0.1\% of the state population infected since the first nationally recorded case ranging from 20 days in São Paulo compared to 60 days in Goiás, underscoring the importance of sub-national analyses in understanding asynchronous state-level epidemics underlying the national spread and burden of COVID-19.},
	journal = {medRxiv},
	author = {Mellan, Thomas A. and Hoeltgebaum, Henrique H. and Mishra, Swapnil and Whittaker, Charlie and Schnekenberg, Ricardo P. and Gandy, Axel and Unwin, H. Juliette T. and Vollmer, Michaela A.C. and Coupland, Helen and Hawryluk, Iwona and Faria, Nuno Rodrigues and Vesga, Juan and Zhu, Harrison and Hutchinson, Michael and Ratmann, Oliver and Monod, Mélodie and Ainslie, Kylie E.C. and Baguelin, Marc and Bhatia, Sangeeta and Boonyasiri, Adhiratha and Brazeau, Nicholas and Charles, Giovanni and Cucunuba, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Eaton, Jeff and van Elsland, Sabine L. and Gaythorpe, Katy A.M. and Green, Will and Knock, Edward and Laydon, Daniel and Lees, John A. and Mousa, Andria and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Parag, Kris V. and Thompson, Hayley A. and Verity, Robert and Walters, Caroline E. and Wang, Haowei and Wang, Yuanrong and Watson, Oliver J. and Whittles, Lilith and Xi, Xiaoyue and Dorigatti, Ilaria and Walker, Patrick and Ghani, Azra C. and Riley, Steven and Ferguson, Neil M. and Donnelly, Christl A. and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
}

@article{vollmer_report_2020,
	title = {Report 20: {Using} mobility to estimate the transmission intensity of {COVID}-19 in {Italy}: {A} subnational analysis with future scenarios},
	doi = {10.1101/2020.05.05.20089359},
	abstract = {Italy was the first European country to experience sustained local transmission of COVID-19. As of 1st May 2020, the Italian health authorities reported 28,238 deaths nationally. To control the epidemic, the Italian government implemented a suite of non-pharmaceutical interventions (NPIs), including school and university closures, social distancing and full lockdown involving banning of public gatherings and non essential movement. In this report, we model the effect of NPIs on transmission using data on average mobility. We estimate that the average reproduction number (a measure of transmission intensity) is currently below one for all Italian regions, and significantly so for the majority of the regions. Despite the large number of deaths, the proportion of population that has been infected by SARS-CoV-2 (the attack rate) is far from the herd immunity threshold in all Italian regions, with the highest attack rate observed in Lombardy (13.18\% [10.66\%-16.70\%]). Italy is set to relax the currently implemented NPIs from 4th May 2020. Given the control achieved by NPIs, we consider three scenarios for the next 8 weeks: a scenario in which mobility remains the same as during the lockdown, a scenario in which mobility returns to pre-lockdown levels by 20\%, and a scenario in which mobility returns to pre-lockdown levels by 40\%. The scenarios explored assume that mobility is scaled evenly across all dimensions, that behaviour stays the same as before NPIs were implemented, that no pharmaceutical interventions are introduced, and it does not include transmission reduction from contact tracing, testing and the isolation of confirmed or suspected cases. New interventions, such as enhanced testing and contact tracing are going to be introduced and will likely contribute to reductions in transmission; therefore our estimates should be viewed as pessimistic projections. We find that, in the absence of additional interventions, even a 20\% return to pre-lockdown mobility could lead to a resurgence in the number of deaths far greater than experienced in the current wave in several regions. Future increases in the number of deaths will lag behind the increase in transmission intensity and so a second wave will not be immediately apparent from just monitoring of the daily number of deaths. Our results suggest that SARS-CoV-2 transmission as well as mobility should be closely monitored in the next weeks and months. To compensate for the increase in mobility that will occur due to the relaxation of the currently implemented NPIs, adherence to the recommended social distancing measures alongside enhanced community surveillance including swab testing, contact tracing and the early isolation of infections are of paramount importance to reduce the risk of resurgence in transmission.},
	journal = {medRxiv},
	author = {Vollmer, Michaela A.C. and Mishra, Swapnil and T Unwin, H. Juliette and Gandy, Axel and Mellan, Thomas A. and Bradley, Valerie and Zhu, Harrison and Coupland, Helen and Hawryluk, Iwona and Hutchinson, Michael and Ratmann, Oliver and Monod, Melodie and Walker, Patrick and Whittaker, Charlie and Cattarino, Lorenzo and Ciavarella, Constance and Cilloni, Lucia and Ainslie, Kylie and Baguelin, Marc and Bhatia, Sangeeta and Boonyasiri, Adhiratha and Brazeau, Nicholas and Charles, Giovanni and Cooper, Laura V. and Cucunuba, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Djaafara, Bimandra and Eaton, Jeff and van Elsland, Sabine L. and FitzJohn, Richard and Fraser, Keith and Gaythorpe, Katy and Green, Will and Hayes, Sarah and Imai, Natsuko and Jeffrey, Ben and Knock, Edward and Laydon, Daniel and Lees, John and Mangal, Tara and Mousa, Andria and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Olivera, Daniela and Parag, Kris V. and Pickles, Michael and Thompson, Hayley A. and Verity, Robert and Walters, Caroline and Wang, Haowei and Wang, Yuanrong and Watson, Oliver J. and Whittles, Lilith and Xi, Xiaoyue and Ghani, Azra and Riley, Steven M. and Okell, Lucy and Donnelly, Christl A. and Ferguson, Neil M. and Dorigatti, Ilaria and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
}

@article{volz_assessing_2021,
	title = {Assessing transmissibility of {SARS}-{CoV}-2 lineage {B}.1.1.7 in {England}},
	doi = {10.1038/s41586-021-03470-x},
	abstract = {The SARS-CoV-2 lineage B.1.1.7, designated a Variant of Concern 202012/01 (VOC) by Public Health England1, originated in the UK in late Summer to early Autumn 20202. Whole genome SARS-CoV-2 sequence data collected from community-based diagnostic testing shows an unprecedentedly rapid expansion of the B.1.1.7 lineage during Autumn 2020, suggesting a selective advantage. We find that changes in VOC frequency inferred from genetic data correspond closely to changes inferred by S-gene target failures (SGTF) in community-based diagnostic PCR testing. Analysis of trends in SGTF and non-SGTF case numbers in local areas across England shows that the VOC has higher transmissibility than non-VOC lineages, even if the VOC has a different latent period or generation time. The SGTF data indicate a transient shift in the age composition of reported cases, with a larger share of under 20 year olds among reported VOC than non-VOC cases. Time-varying reproduction numbers for the VOC and cocirculating lineages were estimated using SGTF and genomic data. The best supported models did not indicate a substantial difference in VOC transmissibility among different age groups. There is a consensus among all analyses that the VOC has a substantial transmission advantage with a 50\% to 100\% higher reproduction number.},
	journal = {Nature},
	author = {Volz, Erik and Mishra, Swapnil and Chand, Meera and Barrett, Jeffrey C. and Johnson, Robert and Geidelberg, Lily and Hinsley, Wes R. and Laydon, Daniel J. and Dabrera, Gavin and O’Toole, Áine and Amato, Roberto and Ragonnet-Cronin, Manon and Harrison, Ian and Jackson, Ben and Ariani, Cristina V. and Boyd, Olivia and Loman, Nicholas J. and McCrone, John T. and Gonçalves, Sónia and Jorgensen, David and Myers, Richard and Hill, Verity and Jackson, David K. and Gaythorpe, Katy and Groves, Natalie and Sillitoe, John and Kwiatkowski, Dominic P. and Flaxman, Seth and Ratmann, Oliver and Bhatt, Samir and Hopkins, Susan and Gandy, Axel and Rambaut, Andrew and Ferguson, Neil M.},
	year = {2021},
}

@article{dym_principles_1980,
	title = {Principles of {Mathematical} {Modeling}},
	volume = {48},
	doi = {10.1119/1.12359},
	number = {11},
	journal = {American Journal of Physics},
	author = {Dym, Clive L. and Ivey, Elizabeth S. and Stewart, Maurice Bruce},
	month = nov,
	year = {1980},
}

@article{reich_accuracy_2019,
	title = {Accuracy of real-time multi-model ensemble forecasts for seasonal influenza in the {U}.{S}.},
	volume = {15},
	doi = {10.1371/journal.pcbi.1007486},
	number = {11},
	journal = {PLOS Computational Biology},
	author = {Reich, Nicholas G. and McGowan, Craig J. and Yamana, Teresa K. and Tushar, Abhinav and Ray, Evan L. and Osthus, Dave and Kandula, Sasikiran and Brooks, Logan C. and Crawford-Crudell, Willow and Gibson, Graham Casey and Moore, Evan and Silva, Rebecca and Biggerstaff, Matthew and Johansson, Michael A. and Rosenfeld, Roni and Shaman, Jeffrey},
	month = nov,
	year = {2019},
}

@misc{noauthor_covid_nodate,
	title = {{COVID} 19 forecast hub},
	url = {https://covid19forecasthub.org/},
}

@misc{noauthor_flusight_nodate,
	title = {{FluSight}: {Flu} {Forecasting}},
	url = {https://www.cdc.gov/flu/weekly/flusight/index.html},
}

@article{kucukelbir_automatic_2017,
	title = {Automatic {Differentiation} {Variational} {Inference}},
	volume = {18},
	abstract = {Probabilistic modeling is iterative. A scientist posits a simple model, fits it to her data, refines it according to her analysis, and repeats. However, fitting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difficult to efficiently cycle through the steps. To this end, we develop automatic differentiation variational inference (advi). Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. advi automatically derives an efficient variational inference algorithm, freeing the scientist to refine and explore many models. advi supports a broad class of models-no conjugacy assumptions are required. We study advi across ten modern probabilistic models and apply it to a dataset with millions of observations. We deploy advi as part of Stan, a probabilistic programming system.},
	journal = {Journal of Machine Learning Research},
	author = {Kucukelbir, Alp and Blei, David M. and Gelman, Andrew and Ranganath, Rajesh and Tran, Dustin},
	year = {2017},
}

@inproceedings{kucukelbir_automatic_2015,
	title = {Automatic variational inference in {Stan}},
	volume = {2015-January},
	abstract = {Variational inference is a scalable technique for approximate Bayesian inference. Deriving variational inference algorithms requires tedious model-specific calculations; this makes it difficult for non-experts to use. We propose an automatic variational inference algorithm, automatic differentiation variational inference (ADVI); we implement it in Stan (code available), a probabilistic programming system. In ADVI the user provides a Bayesian model and a dataset, nothing else. We make no conjugacy assumptions and support a broad class of models. The algorithm automatically determines an appropriate variational family and optimizes the variational objective. We compare ADVI to MCMC sampling across hierarchical generalized linear models, nonconjugate matrix factorization, and a mixture model. We train the mixture model on a quarter million images. With ADVI we can use variational inference on any model we write in Stan.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kucukelbir, Alp and Ranganath, Rajesh and Gelman, Andrew and Blei, David M.},
	year = {2015},
}

@book{team_stan_2017,
	title = {Stan {Modeling} {Language}},
	abstract = {RSTAN package Stan Development Team (2013). Stan: A C++ Library for Probability and Sampling, Version 2.2.0. URL http://mc-stan.org/. Stan Development Team (2013). Stan Modeling Language User's Guide and Reference Manual, Version 2.2.0. URL http://mc-stan.org/. Hoffman, Matthew D. and Andrew Gelman. In press. The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research.},
	author = {Team, Stan Development},
	year = {2017},
	note = {Publication Title: Web},
}

@article{stan_development_team_stan_2020,
	title = {Stan {Modeling} {Language} {User}’s {Guide} and {Reference} {Manual}, {Version} 2.19.2.},
	abstract = {RSTAN package Stan Development Team (2013). Stan: A C++ Library for Probability and Sampling, Version 2.2.0. URL http://mc-stan.org/. Stan Development Team (2013). Stan Modeling Language User's Guide and Reference Manual, Version 2.2.0. URL http://mc-stan.org/. Hoffman, Matthew D. and Andrew Gelman. In press. The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research.},
	journal = {Interaction Flow Modeling Language},
	author = {{Stan Development Team}},
	year = {2020},
}

@article{hoffman_no-u-turn_2014,
	title = {The no-{U}-turn sampler: {Adaptively} setting path lengths in {Hamiltonian} {Monte} {Carlo}},
	volume = {15},
	abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size e and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more efficiently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter e on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" samplers. © 2014 Matthew D. Hoffman and Andrew Gelman.},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matthew D. and Gelman, Andrew},
	year = {2014},
}

@article{bates_fitting_2015,
	title = {Fitting linear mixed-effects models using lme4},
	volume = {67},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v067i01/v67i01.pdf},
	doi = {10.18637/jss.v067.i01},
	abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Benjamin M. and Walker, Steven C.},
	month = oct,
	year = {2015},
	note = {Publisher: American Statistical Association},
	keywords = {Cholesky decomposition, Linear mixed models, Penalized least squares, Sparse matrix methods},
	pages = {1--48},
}

@article{gibbons_measuring_2014,
	title = {Measuring underreporting and under-ascertainment in infectious disease datasets: a comparison of methods},
	volume = {14},
	doi = {10.1186/1471-2458-14-147},
	number = {1},
	journal = {BMC Public Health},
	author = {Gibbons, Cheryl L and Mangen, Marie-Josée J and Plass, Dietrich and Havelaar, Arie H and Brooke, Russell John and Kramarz, Piotr and Peterson, Karen L and Stuurman, Anke L and Cassini, Alessandro and Fèvre, Eric M and Kretzschmar, Mirjam EE},
	month = dec,
	year = {2014},
}

@article{roosa_assessing_2019,
	title = {Assessing parameter identifiability in compartmental dynamic models using a computational approach: application to infectious disease transmission models},
	volume = {16},
	doi = {10.1186/s12976-018-0097-6},
	number = {1},
	journal = {Theoretical Biology and Medical Modelling},
	author = {Roosa, Kimberlyn and Chowell, Gerardo},
	month = dec,
	year = {2019},
}

@article{box_statistical_1962,
	title = {Some {Statistical} {Aspects} of {Adaptive} {Optimization} and {Control}},
	volume = {24},
	url = {https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.2517-6161.1962.tb00460.x},
	doi = {10.1111/j.2517-6161.1962.tb00460.x},
	abstract = {It is often necessary to adjust some variable X, such as the concentration of consecutive batches of a product, to keep X close to a specified target value. A second more complicated problem occurs when the independent variables X in a response function ?(X) are to be adjusted so that the derivatives ??/? X are kept close to a target value zero, thus maximizing or minimizing the response. These are shown to be problems of prediction, essentially, and the paper is devoted mainly to the estimation from past data of the "best" adjustments to be applied in the first problem.},
	number = {2},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Box, G. E. P. and Jenkins, G. M.},
	month = jul,
	year = {1962},
	note = {Publisher: Wiley},
	pages = {297--331},
}

@article{kermack_contributions_1933,
	title = {Contributions to the mathematical theory of epidemics. {III}.—{Further} studies of the problem of endemicity},
	volume = {141},
	doi = {10.1098/rspa.1933.0106},
	abstract = {In a previous paper (Part II of this series) an attempt was made to treat from a general point of view the problem of a single disease in a population which consisted of three categories of people—namely, never infected, sick and recovered—and in which the infectivity of the disease was a function of the period of illness, whilst the susceptibility of a recovered person was a function of the period which had elapsed since the time of his recovery. New individuals entering the population either by birth or by immigration naturally entered the category of the never infected which for convenience we called “virgins.” It was pointed out that the results obtained were subject to two important limitations: (1) that the disease under consideration was the only cause of death, and (2) that the age of the individuals did not affect their infectivity, susceptibility or reproductiveness. It is the purpose of the present paper to remove the first of these limitations by the introduction of constant non-specific death rates, which for the sake of generality are assumed to be different for virgins, sick, and recovered. It may be stated at once that the introduction of this additional factor produces surprisingly little change in the general nature of the results previously obtained, and that the conclusions of the previous paper hold with very little modifica­tion.},
	number = {843},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	author = {Kermack, A. G., William Ogilvy {and} McKendrick},
	month = jul,
	year = {1933},
}

@article{kermack_contributions_1932,
	title = {Contributions to the mathematical theory of epidemics. {II}. —{The} problem of endemicity},
	volume = {138},
	doi = {10.1098/rspa.1932.0171},
	abstract = {In a previous communication an attempt was made to investigate mathe­matically the course of an epidemic in a closed population of susceptible individuals. In order to simplify the problem certain definite assumptions were made, namely, that all individuals were equally susceptible, and that death resulted, or complete immunity was conferred, as the result of an attack. The infectivity of the individual and his chances of death or recovery were represented by arbitrary functions, and the chance of a new infection occurring was assumed to be proportional to the product of the infected and susceptible members of the population. In spite of the introduction of the arbitrary functions, it was shown that in general a critical density of population existed, such that if the actual density was less than this, no epidemic could occur, but if it exceeded this by n an epidemic would appear on the introduction of a focus of infection, and further that if n was small relative to the population density, the size of the epidemic would be 2 n per unit area. It was shown that these conclusions could be readily extended to the case of a metaxenous disease, that is, one in which transmission takes place through an intermediate host. It is the purpose of the present paper to consider the effect of the continuous introduction of fresh susceptible individuals into the population. It appeared desirable to investigate this point, since it might make it possible to interpret certain aspects of the incidence of disease not only in human communities where there is usually an influx of fresh susceptible individuals either by immigration or by birth, but also in the animal experiments carried out by Topley and others—where fresh animals were introduced at a constant rate into the cages in which cases of disease were already present—from which certain definite results were obtained.},
	number = {834},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	author = {Kermack, A. G., William Ogilvy {and} McKendrick},
	month = oct,
	year = {1932},
}

@article{tokuda_visualizing_2011,
	title = {Visualizing distributions of covariance matrices},
	journal = {Columbia Univ., New York, USA, Tech. Rep},
	author = {Tokuda, Tomoki and Goodrich, Ben and Van Mechelen, I and Gelman, Andrew and Tuerlinckx, F},
	year = {2011},
	note = {Publisher: Citeseer},
	pages = {18--18},
}

@article{bhatt_semi-mechanistic_2020,
	title = {Semi-{Mechanistic} {Bayesian} {Modeling} of {COVID}-19 with {Renewal} {Processes}},
	url = {https://arxiv.org/abs/2012.00394},
	journal = {arXiv preprint arXiv:2012.00394},
	author = {Bhatt, Samir and Ferguson, Neil and Flaxman, Seth and Gandy, Axel and Mishra, Swapnil and Scott, James A},
	year = {2020},
}

@article{mishra_derivation_2020,
	title = {On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective},
	journal = {arXiv preprint arXiv:2006.16487},
	author = {Mishra, Swapnil and Berah, Tresnia and Mellan, Thomas A and Unwin, H Juliette T and Vollmer, Michaela A and Parag, Kris V and Gandy, Axel and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
}

@article{flaxman_reply_2020,
	title = {Reply to: {The} effect of interventions on {COVID}-19},
	volume = {588},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/s41586-020-3026-x},
	doi = {10.1038/s41586-020-3026-x},
	number = {7839},
	journal = {Nature},
	author = {Flaxman, Seth and Mishra, Swapnil and Scott, James and Ferguson, Neil and Gandy, Axel and Bhatt, Samir},
	year = {2020},
	pages = {E29--E32},
}

@article{myers_forecasting_2000,
	title = {Forecasting disease risk for increased epidemic preparedness in public health},
	volume = {47},
	url = {/pmc/articles/PMC3196833/},
	doi = {10.1016/s0065-308x(00)47013-2},
	abstract = {Emerging infectious diseases pose a growing threat to human populations. Many of the world's epidemic diseases (particularly those transmitted by intermediate hosts) are known to be highly sensitive to long-term changes in climate and short-term fluctuations in the weather. The application of environmental data to the study of disease offers the capability to demonstrate vector-environment relationships and potentially forecast the risk of disease outbreaks or epidemics. Accurate disease forecasting models would markedly improve epidemic prevention and control capabilities. This chapter examines the potential for epidemic forecasting and discusses the issues associated with the development of global networks for surveillance and prediction. Existing global systems for epidemic preparedness focus on disease surveillance using either expert knowledge or statistical modelling of disease activity and thresholds to identify times and areas of risk. Predictive health information systems would use monitored environmental variables, linked to a disease system, to be observed and provide prior information of outbreaks. The components and varieties of forecasting systems are discussed with selected examples, along with issues relating to further development.},
	journal = {Advances in Parasitology},
	author = {Myers, M. F. and Rogers, D. J. and Cox, J. and Flahault, A. and Hay, S. I.},
	year = {2000},
	note = {Publisher: Academic Press},
	pages = {309--330},
}

@article{unkel_statistical_2012,
	title = {Statistical methods for the prospective detection of infectious disease outbreaks: {A} review},
	volume = {175},
	url = {https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-985X.2011.00714.x},
	doi = {10.1111/j.1467-985X.2011.00714.x},
	abstract = {Unusual clusters of disease must be detected rapidly for effective public health interventions to be introduced. Over the past decade there has been a surge in interest in statistical methods for the early detection of infectious disease outbreaks. This growth in interest has given rise to much new methodological work, ranging across the spectrum of statistical methods. The paper presents a comprehensive review of the statistical approaches that have been proposed. Applications to both laboratory and syndromic surveillance data are provided to illustrate the various methods. © 2011 Royal Statistical Society.},
	number = {1},
	journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
	author = {Unkel, Steffen and Farrington, C. Paddy and Garthwaite, Paul H. and Robertson, Chris and Andrews, Nick},
	month = jan,
	year = {2012},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Biosurveillance, Clusters, Control chart, Epidemics, Infectious diseases, Outbreak, Prospective detection, Surveillance},
	pages = {49--82},
}

@article{nsoesie_systematic_2014,
	title = {A systematic review of studies on forecasting the dynamics of influenza outbreaks},
	volume = {8},
	url = {www.influenzajournal.com},
	doi = {10.1111/irv.12226},
	abstract = {Forecasting the dynamics of influenza outbreaks could be useful for decision-making regarding the allocation of public health resources. Reliable forecasts could also aid in the selection and implementation of interventions to reduce morbidity and mortality due to influenza illness. This paper reviews methods for influenza forecasting proposed during previous influenza outbreaks and those evaluated in hindsight. We discuss the various approaches, in addition to the variability in measures of accuracy and precision of predicted measures. PubMed and Google Scholar searches for articles on influenza forecasting retrieved sixteen studies that matched the study criteria. We focused on studies that aimed at forecasting influenza outbreaks at the local, regional, national, or global level. The selected studies spanned a wide range of regions including USA, Sweden, Hong Kong, Japan, Singapore, United Kingdom, Canada, France, and Cuba. The methods were also applied to forecast a single measure or multiple measures. Typical measures predicted included peak timing, peak height, daily/weekly case counts, and outbreak magnitude. Due to differences in measures used to assess accuracy, a single estimate of predictive error for each of the measures was difficult to obtain. However, collectively, the results suggest that these diverse approaches to influenza forecasting are capable of capturing specific outbreak measures with some degree of accuracy given reliable data and correct disease assumptions. Nonetheless, several of these approaches need to be evaluated and their performance quantified in real-time predictions. © 2013 The Authors. Influenza and Other Respiratory Viruses Published by John Wiley \& Sons Ltd.},
	number = {3},
	journal = {Influenza and other Respiratory Viruses},
	author = {Nsoesie, Elaine O. and Brownstein, John S. and Ramakrishnan, Naren and Marathe, Madhav V.},
	month = may,
	year = {2014},
	note = {Publisher: Blackwell Publishing},
	keywords = {Infectious diseases, Compartmental models, Individual-based models, Influenza forecasting, Pandemics, Time series models},
	pages = {309--316},
}

@article{chretien_influenza_2014,
	title = {Influenza forecasting in human populations: {A} scoping review},
	volume = {9},
	url = {www.plosone.org},
	doi = {10.1371/journal.pone.0094130},
	abstract = {Forecasts of influenza activity in human populations could help guide key preparedness tasks. We conducted a scoping review to characterize these methodological approaches and identify research gaps. Adapting the PRISMA methodology for systematic reviews, we searched PubMed, CINAHL, Project Euclid, and Cochrane Database of Systematic Reviews for publications in English since January 1, 2000 using the terms "influenza AND (forecast*OR predict*)", excluding studies that did not validate forecasts against independent data or incorporate influenza-related surveillance data from the season or pandemic for which the forecasts were applied. We included 35 publications describing population-based (N = 27), medical facility-based (N = 4), and regional or global pandemic spread (N = 4) forecasts. They included areas of North America (N = 15), Europe (N = 14), and/or Asia-Pacific region (N = 4), or had global scope (N = 3). Forecasting models were statistical (N = 18) or epidemiological (N = 17). Five studies used data assimilation methods to update forecasts with new surveillance data. Models used virological (N = 14), syndromic (N = 13), meteorological (N = 6), internet search query (N = 4), and/or other surveillance data as inputs. Forecasting outcomes and validation metrics varied widely. Two studies compared distinct modeling approaches using common data, 2 assessed model calibration, and 1 systematically incorporated expert input. Of the 17 studies using epidemiological models, 8 included sensitivity analysis. This review suggests need for use of good practices in influenza forecasting (e.g., sensitivity analysis); direct comparisons of diverse approaches; assessment of model calibration; integration of subjective expert input; operational research in pilot, real-world applications; and improved mutual understanding among modelers and public health officials. © 2014 Chretien et al.},
	number = {4},
	journal = {PLoS ONE},
	author = {Chretien, Jean Paul and George, Dylan and Shaman, Jeffrey and Chitale, Rohit A. and McKenzie, F. Ellis},
	month = apr,
	year = {2014},
	note = {Publisher: Public Library of Science},
	keywords = {Pandemics, Database searching, Epidemiology, Forecasting, Infectious disease surveillance, Influenza, Public and occupational health, Systematic reviews},
	pages = {94130--94130},
	file = {Chretien et al. - 2014 - Influenza forecasting in human populations A scoping review:/Users/jamesscott/Zotero/storage/SS9FSDX9/Chretien et al. - 2014 - Influenza forecasting in human populations A scoping review.pdf:application/pdf},
}

@article{siettos_mathematical_2013,
	title = {Mathematical modeling of infectious disease dynamics},
	volume = {4},
	url = {/pmc/articles/PMC3710332/},
	doi = {10.4161/viru.24041},
	abstract = {Over the last years, an intensive worldwide effort is speeding up the developments in the establishment of a global surveillance network for combating pandemics of emergent and re-emergent infectious diseases. Scientists from different fields extending from medicine and molecular biology to computer science and applied mathematics have teamed up for rapid assessment of potentially urgent situations. Toward this aim mathematical modeling plays an important role in efforts that focus on predicting, assessing, and controlling potential outbreaks. To better understand and model the contagious dynamics the impact of numerous variables ranging from the micro host-pathogen level to host-to-host interactions, as well as prevailing ecological, social, economic, and demographic factors across the globe have to be analyzed and thoroughly studied. Here, we present and discuss the main approaches that are used for the surveillance and modeling of infectious disease dynamics. We present the basic concepts underpinning their implementation and practice and for each category we give an annotated list of representative works.},
	number = {4},
	journal = {Virulence},
	author = {Siettos, Constantinos I. and Russo, Lucia},
	year = {2013},
	note = {Publisher: Taylor and Francis Inc.},
	keywords = {Agent-based models, Dynamical models, Machine learning models, Mathematical epidemiology, Statistical models},
	pages = {295--306},
	file = {Siettos, Russo - 2013 - Mathematical modeling of infectious disease dynamics:/Users/jamesscott/Zotero/storage/LGT7FXV5/Siettos, Russo - 2013 - Mathematical modeling of infectious disease dynamics.pdf:application/pdf},
}

@article{heesterbeek_modeling_2015,
	title = {Modeling infectious disease dynamics in the complex landscape of global health},
	volume = {347},
	url = {http://science.sciencemag.org/},
	doi = {10.1126/science.aaa4339},
	abstract = {Despite some notable successes in the control of infectious diseases, transmissible pathogens still pose an enormous threat to human and animal health. The ecological and evolutionary dynamics of infections play out on a wide range of interconnected temporal, organizational, and spatial scales, which span hours to months, cells to ecosystems, and local to global spread. Moreover, some pathogens are directly transmitted between individuals of a single species, whereas others circulate among multiple hosts, need arthropod vectors, or can survive in environmental reservoirs. Many factors, including increasing antimicrobial resistance, increased human connectivity and changeable human behavior, elevate prevention and control from matters of national policy to international challenge. In the face of this complexity, mathematical models offer valuable tools for synthesizing information to understand epidemiological patterns, and for developing quantitative evidence for decision-making in global health.},
	number = {6227},
	journal = {Science},
	author = {Heesterbeek, Hans and Anderson, Roy M. and Andreasen, Viggo and Bansal, Shweta and DeAngelis, Daniela and Dye, Chris and Eames, Ken T.D. and Edmunds, W. John and Frost, Simon D.W. and Funk, Sebastian and Hollingsworth, T. Deirdre and House, Thomas and Isham, Valerie and Klepac, Petra and Lessler, Justin and Lloyd-Smith, James O. and Metcalf, C. Jessica E. and Mollison, Denis and Pellis, Lorenzo and Pulliam, Juliet R.C. and Roberts, Mick G. and Viboud, Cecile and Arinaminpathy, Nimalan and Ball, Frank and Bogich, Tiffany and Gog, Julia and Grenfell, Bryan and Lloyd, Alun L. and Mclean, Angela and O'Neill, Philip and Pearson, Carl and Riley, Steven and Tomba, Gianpaolo Scalia and Trapman, Pieter and Wood, James},
	month = mar,
	year = {2015},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Heesterbeek et al. - 2015 - Modeling infectious disease dynamics in the complex landscape of global health:/Users/jamesscott/Zotero/storage/BI6DW5LB/Heesterbeek et al. - 2015 - Modeling infectious disease dynamics in the complex landscape of global health.pdf:application/pdf},
}

@article{ferguson_report_2020,
	title = {Report 13: {Estimating} the number of infections and the impact of non-pharmaceutical interventions on {COVID}-19 in 11 {European} countries},
	abstract = {The global impact of COVID-19 has been profound, and the public health threat it represents is the most serious seen in a respiratory virus since the 1918 H1N1 influenza pandemic. Here we present the results of epidemiological modelling which has informed policymaking in the UK and other countries in recent weeks. In the absence of a COVID-19 vaccine, we assess the potential role of a number of public health measures-so-called non-pharmaceutical interventions (NPIs)-aimed at reducing contact rates in the population and thereby reducing transmission of the virus. In the results presented here, we apply a previously published microsimulation model to two countries: the UK (Great Britain specifically) and the US. We conclude that the effectiveness of any one intervention in isolation is likely to be limited, requiring multiple interventions to be combined to have a substantial impact on transmission. Two fundamental strategies are possible: (a) mitigation, which focuses on slowing but not necessarily stopping epidemic spread-reducing peak healthcare demand while protecting those most at risk of severe disease from infection, and (b) suppression, which aims to reverse epidemic growth, reducing case numbers to low levels and maintaining that situation indefinitely. Each policy has major challenges. We find that that optimal mitigation policies (combining home isolation of suspect cases, home quarantine of those living in the same household as suspect cases, and social distancing of the elderly and others at most risk of severe disease) might reduce peak healthcare demand by 2/3 and deaths by half. However, the resulting mitigated epidemic would still likely result in hundreds of thousands of deaths and health systems (most notably intensive care units) being overwhelmed many times over. For countries able to achieve it, this leaves suppression as the preferred policy option. We show that in the UK and US context, suppression will minimally require a combination of social distancing of the entire population, home isolation of cases and household quarantine of their family members. This may need to be supplemented by school and university closures, though it should be recognised that such closures may have negative impacts on health systems due to increased},
	journal = {Imperial College COVID-19 Response Team},
	author = {Ferguson, Neil M and Laydon, Daniel and Nedjati-Gilani, Gemma and Imai, Natsuko and Ainslie, Kylie and Baguelin, Marc and Bhatia, Sangeeta and Boonyasiri, Adhiratha and Cucunubá, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Dorigatti, Ilaria and Fu, Han and Gaythorpe, Katy and Green, Will and Hamlet, Arran and Hinsley, Wes and Okell, Lucy C and Van Elsland, Sabine and Thompson, Hayley and Verity, Robert and Volz, Erik and Wang, Haowei and Wang, Yuanrong and Gt Walker, Patrick and Walters, Caroline and Winskill, Peter and Whittaker, Charles and Donnelly, Christl A and Riley, Steven and Ghani, Azra C},
	year = {2020},
}

@article{may_simple_1976,
	title = {Simple mathematical models with very complicated dynamics},
	doi = {10.1038/261459a0},
	abstract = {First-order difference equations arise in many contexts in the biological, economic and social sciences. Such equations, even though simple and deterministic, can exhibit a surprising array of dynamical behaviour, from stable points, to a bifurcating hierarchy of stable cycles, to apparently random fluctuations. There are consequently many fascinating problems, some concerned with delicate mathematical aspects of the fine structure of the trajectories, and some concerned with the practical implications and applications. This is an interpretive review of them. © 1976 Nature Publishing Group.},
	journal = {Nature},
	author = {May, Robert M.},
	year = {1976},
}

@article{thompson_introduction_1985,
	title = {An {Introduction} to {Stochastic} {Modeling}.},
	doi = {10.2307/2287941},
	abstract = {Serving as the foundation for a one-semester course in stochastic processes for students familiar with elementary probability theory and calculus, Introduction to Stochastic Modeling, Third Edition, bridges the gap between basic probability and an intermediate level course in stochastic processes. The objectives of the text are to introduce students to the standard concepts and methods of stochastic modeling, to illustrate the rich diversity of applications of stochastic processes in the applied sciences, and to provide exercises in the application of simple stochastic analysis to realistic problems. * Realistic applications from a variety of disciplines integrated throughout the text* Plentiful, updated and more rigorous problems, including computer "challenges"* Revised end-of-chapter exercises sets-in all, 250 exercises with answers* New chapter on Brownian motion and related processes* Additional sections on Matingales and Poisson process* Solutions manual available to adopting instructors},
	journal = {Journal of the American Statistical Association},
	author = {Thompson, W. A. and Taylor, Howard M. and Karlin, Samuel},
	year = {1985},
}

@article{boelle_r0_2015,
	title = {R0: {Estimation} of {R0} and {Real}-{Time} {Reproduction} {Number} from {Epidemics}},
	url = {https://cran.r-project.org/package=R0},
	author = {Boelle, Pierre-Yves and Obadia, Thomas},
	year = {2015},
	annote = {R package version 1.2-6},
}

@article{cori_epiestim_2020,
	title = {{EpiEstim}: {Estimate} {Time} {Varying} {Reproduction} {Numbers} from {Epidemic} {Curves}},
	url = {https://cran.r-project.org/package=EpiEstim},
	author = {Cori, Anne},
	year = {2020},
	annote = {R package version 2.2-3},
}

@article{scott_state-dependent_2020,
	title = {State-{Dependent} {Kernel} {Selection} for {Conditional} {Sampling} of {Graphs}},
	volume = {0},
	url = {https://doi.org/10.1080/10618600.2020.1753529},
	doi = {10.1080/10618600.2020.1753529},
	number = {0},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Scott, James A and Gandy, Axel},
	year = {2020},
	note = {Publisher: Taylor \& Francis},
	pages = {1--12},
}

@article{carissimo_validation_2018,
	title = {Validation of community robustness},
	doi = {10.1016/j.csda.2017.10.006},
	abstract = {The large amount of work on community detection and its applications leaves unaddressed one important question: the statistical validation of the results. A methodology is presented that is able to clearly detect if the community structure found by some algorithms is statistically significant or is a result of chance, merely due to edge positions in the network. Given a community detection method and a network of interest, the proposal examines the stability of the partition recovered against random perturbations of the original graph structure. To address this issue, a perturbation strategy and a null model graph, which matches the original in some of its structural properties, but is otherwise a random graph, is specified. A set of procedures is built based on a special measure of clustering distance, namely Variation of Information, using tools set up for functional data analysis. The procedures determine whether the obtained clustering departs significantly from the null model. This strongly supports the robustness against perturbation of the algorithm used to identify the community structure. Results obtained with the proposed technique on simulated and real datasets are shown and discussed.},
	journal = {Computational Statistics and Data Analysis},
	author = {Carissimo, Annamaria and Cutillo, Luisa and Feis, Italia De},
	year = {2018},
	keywords = {Community, Multiple testing, Network, Variation of information},
}

@article{sales-pardo_extracting_2007,
	title = {Extracting the hierarchical organization of complex systems},
	doi = {10.1073/pnas.0703740104},
	abstract = {Extracting understanding from the growing "sea" of biological and socioeconomic data is one of the most pressing scientific challenges facing us. Here, we introduce and validate an unsupervised method for extracting the hierarchical organization of complex biological, social, and technological networks. We define an ensemble of hierarchically nested random graphs, which we use to validate the method. We then apply our method to real-world networks, including the air-transportation network, an electronic circuit an e-mail exchange network, and metabolic networks. Our analysis of model and real networks demonstrates that our method extracts an accurate multiscale representation of a complex system. © 2007 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sales-Pardo, Marta and Guimerà, Roger and Moreira, André A. and Nunes Amaral, Luís A.},
	year = {2007},
	keywords = {Cellular metabolism, Complex networks, Multiscale representation},
}

@inproceedings{chang_assessing_2012,
	title = {Assessing statistical significance when partitioning large-scale brain networks},
	isbn = {978-1-4577-1858-8},
	doi = {10.1109/ISBI.2012.6235921},
	abstract = {Multivariate analysis of structural and functional brain imaging data can be used to produce network models of interaction or similarity between different brain structures. Graph partitioning methods can then be used to identify distinct subnetworks that may provide insight into the organization of the human brain. Although several efficient partitioning algorithms have been proposed, and their properties studied thoroughly, there has been limited work addressing the statistical significance of the resulting partitions. We present a new method to estimate the statistical significance of a network structure based on modularity. We derive a numerical approximation of the distribution of modularity on random graphs, and use this distribution to calculate a threshold that controls the type I error rate in partitioning graphs. We demonstrate the technique in application to brain subnetworks identified from diffusion-based fiber tracking data and from resting state fMRI data. © 2012 IEEE.},
	booktitle = {Proceedings - {International} {Symposium} on {Biomedical} {Imaging}},
	author = {Chang, Yu Teng and Pantazis, Dimitrios and Leahy, Richard M.},
	year = {2012},
	keywords = {community structure, graph partitioning, modularity, significance testing},
}

@article{karrer_robustness_2008,
	title = {Robustness of community structure in networks},
	doi = {10.1103/PhysRevE.77.046119},
	abstract = {The discovery of community structure is a common challenge in the analysis of network data. Many methods have been proposed for finding community structure, but few have been proposed for determining whether the structure found is statistically significant or whether, conversely, it could have arisen purely as a result of chance. In this paper we show that the significance of community structure can be effectively quantified by measuring its robustness to small perturbations in network structure. We propose a suitable method for perturbing networks and a measure of the resulting change in community structure and use them to assess the significance of community structure in a variety of networks, both real and computer generated. © 2008 The American Physical Society.},
	journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
	author = {Karrer, Brian and Levina, Elizaveta and Newman, M. E.J.},
	year = {2008},
}

@article{sales-pardo_extracting_2007-1,
	title = {Extracting the hierarchical organization of complex systems},
	doi = {10.1073/pnas.0703740104},
	abstract = {Extracting understanding from the growing "sea" of biological and socioeconomic data is one of the most pressing scientific challenges facing us. Here, we introduce and validate an unsupervised method for extracting the hierarchical organization of complex biological, social, and technological networks. We define an ensemble of hierarchically nested random graphs, which we use to validate the method. We then apply our method to real-world networks, including the air-transportation network, an electronic circuit an e-mail exchange network, and metabolic networks. Our analysis of model and real networks demonstrates that our method extracts an accurate multiscale representation of a complex system. © 2007 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sales-Pardo, Marta and Guimerà, Roger and Moreira, André A. and Nunes Amaral, Luís A.},
	year = {2007},
	keywords = {Cellular metabolism, Complex networks, Multiscale representation},
}

@article{reichardt_when_2006,
	title = {When are networks truly modular?},
	doi = {10.1016/j.physd.2006.09.009},
	abstract = {The study of cluster or community structure of complex networks contributes to the understanding of networks at a functional level. In many networks, latent classes of nodes are suspected which manifest themselves as communities, i.e. groups of nodes with a high link density among the nodes of the same class and low link density between nodes of different classes. Community detection algorithms are used to infer these classes, e.g. by finding a partition of the network which maximizes a quality function such as the network modularity Q [M. Newman, M. Girvan, Finding and evaluating community structure in networks, Phys. Rev. E 69 (2004) 026113]. However, it is known from numerical experiments that even purely random networks display intrinsic modularity and may be partitioned yielding high values of Q. Extending on our earlier results [J. Reichardt, S. Bornholdt, Statistical mechanics of community detection, Phys. Rev. E 74 (2006) 016110], the mapping of the community detection problem onto finding the ground state of a spin glass is exploited in order to derive analytical expressions for the expected modularity in random graphs and assess the theoretical limits to community detection. The results are independent of any specific community detection algorithm and allow for differentiation between modularity arising purely due to the search process in the large configuration space of possible partitionings on the one hand, or due to the actual presence of different classes of nodes on the other hand. © 2006 Elsevier Ltd. All rights reserved.},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Reichardt, Jörg and Bornholdt, Stefan},
	year = {2006},
	keywords = {Community detection, Graph clustering, Spin models},
}

@article{hu_measuring_2010,
	title = {Measuring the significance of community structure in complex networks},
	doi = {10.1103/PhysRevE.82.066106},
	abstract = {Many complex systems can be represented as networks, and separating a network into communities could simplify functional analysis considerably. Many approaches have recently been proposed to detect communities, but a method to determine whether the detected communities are significant is still lacking. In this paper, an index to evaluate the significance of communities in networks is proposed based on perturbation of the network. In contrast to previous approaches, the network is disturbed gradually, and the index is defined by integrating all of the similarities between the community structures before and after perturbation. Moreover, by taking the null model into account, the index eliminates scale effects. Thus, it can evaluate and compare the significance of communities in different networks. The method has been tested in many artificial and real-world networks. The results show that the index is in fact independent of the size of the network and the number of communities. With this approach, clear communities are found to always exist in social networks, but significant communities cannot be found in protein interactions and metabolic networks. © 2010 The American Physical Society.},
	journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
	author = {Hu, Yanqing and Nie, Yuchao and Yang, Hua and Cheng, Jie and Fan, Ying and Di, Zengru},
	year = {2010},
}

@article{arnau_iterative_2005,
	title = {Iterative cluster analysis of protein interaction data},
	doi = {10.1093/bioinformatics/bti021},
	abstract = {Motivation: Generation of fast tools of hierarchical clustering to be applied when distances among elements of a set are constrained, causing frequent distance ties, as happens in protein interaction data. Results: We present in this work the program UVCLUSTER, that iteratively explores distance datasets using hierarchical clustering. Once the user selects a group of proteins, UVCLUSTER converts the set of primary distances among them (i.e. the minimum number of steps, or interactions, required to connect two proteins) into secondary distances that measure the strength of the connection between each pair of proteins when the interactions for all the proteins in the group are considered. We show that this novel strategy has advantages over conventional clustering methods to explore protein-protein interaction dam. UVCLUSTER easily incorporates the information of the largest available interaction datasets to generate comprehensive primary distance tables. The versatility, simplicity of use and high speed of UVCLUSTER on standard personal computers suggest that it can be a benchmark analytical tool for interactome data analysis. © Oxford University Press 2004; all rights reserved.},
	journal = {Bioinformatics},
	author = {Arnau, Vicente and Mars, Sergio and Marín, Ignacio},
	year = {2005},
}

@article{aldecoa_deciphering_2011,
	title = {Deciphering network community structure by surprise},
	doi = {10.1371/journal.pone.0024195},
	abstract = {The analysis of complex networks permeates all sciences, from biology to sociology. A fundamental, unsolved problem is how to characterize the community structure of a network. Here, using both standard and novel benchmarks, we show that maximization of a simple global parameter, which we call Surprise (S), leads to a very efficient characterization of the community structure of complex synthetic networks. Particularly, S qualitatively outperforms the most commonly used criterion to define communities, Newman and Girvan's modularity (Q). Applying S maximization to real networks often provides natural, well-supported partitions, but also sometimes counterintuitive solutions that expose the limitations of our previous knowledge. These results indicate that it is possible to define an effective global criterion for community structure and open new routes for the understanding of complex networks. © 2011 Aldecoa, Marín.},
	journal = {PLoS ONE},
	author = {Aldecoa, Rodrigo and Marín, Ignacio},
	year = {2011},
}

@article{aldecoa_deciphering_2011-1,
	title = {Deciphering network community structure by surprise},
	doi = {10.1371/journal.pone.0024195},
	abstract = {The analysis of complex networks permeates all sciences, from biology to sociology. A fundamental, unsolved problem is how to characterize the community structure of a network. Here, using both standard and novel benchmarks, we show that maximization of a simple global parameter, which we call Surprise (S), leads to a very efficient characterization of the community structure of complex synthetic networks. Particularly, S qualitatively outperforms the most commonly used criterion to define communities, Newman and Girvan's modularity (Q). Applying S maximization to real networks often provides natural, well-supported partitions, but also sometimes counterintuitive solutions that expose the limitations of our previous knowledge. These results indicate that it is possible to define an effective global criterion for community structure and open new routes for the understanding of complex networks. © 2011 Aldecoa, Marín.},
	journal = {PLoS ONE},
	author = {Aldecoa, Rodrigo and Marín, Ignacio},
	year = {2011},
}

@article{miyauchi_z-score-based_2016,
	title = {Z-score-based modularity for community detection in networks},
	doi = {10.1371/journal.pone.0147805},
	abstract = {Identifying community structure in networks is an issue of particular interest in network science. The modularity introduced by Newman and Girvan is the most popular quality function for community detection in networks. In this study, we identify a problem in the concept of modularity and suggest a solution to overcome this problem. Specifically, we obtain a new quality function for community detection. We refer to the function as Z-modularity because it measures the Z-score of a given partition with respect to the fraction of the number of edges within communities. Our theoretical analysis shows that Z-modularity mitigates the resolution limit of the original modularity in certain cases. Computational experiments using both artificial networks and well-known real-world networks demonstrate the validity and reliability of the proposed quality function.},
	journal = {PLoS ONE},
	author = {Miyauchi, Atsushi and Kawase, Yasushi},
	year = {2016},
}

@article{miyauchi_z-score-based_2016-1,
	title = {Z-score-based modularity for community detection in networks},
	doi = {10.1371/journal.pone.0147805},
	abstract = {Identifying community structure in networks is an issue of particular interest in network science. The modularity introduced by Newman and Girvan is the most popular quality function for community detection in networks. In this study, we identify a problem in the concept of modularity and suggest a solution to overcome this problem. Specifically, we obtain a new quality function for community detection. We refer to the function as Z-modularity because it measures the Z-score of a given partition with respect to the fraction of the number of edges within communities. Our theoretical analysis shows that Z-modularity mitigates the resolution limit of the original modularity in certain cases. Computational experiments using both artificial networks and well-known real-world networks demonstrate the validity and reliability of the proposed quality function.},
	journal = {PLoS ONE},
	author = {Miyauchi, Atsushi and Kawase, Yasushi},
	year = {2016},
}

@article{kumpula_limited_2007,
	title = {Limited resolution in complex network community detection with {Potts} model approach},
	doi = {10.1140/epjb/e2007-00088-4},
	abstract = {According to Fortunato and Barthélemy, modularity-based community detection algorithms have a resolution threshold such that small communities in a large network are invisible. Here we generalize their work and show that the q-state Potts community detection method introduced by Reichardt and Bornholdt also has a resolution threshold. The model contains a parameter by which this threshold can be tuned, but no a priori principle is known to select the proper value. Single global optimization criteria do not seem capable for detecting all communities if their size distribution is broad. © EDP Sciences/Società Italiana di Fisica/Springer-Verlag 2007.},
	journal = {European Physical Journal B},
	author = {Kumpula, J. M. and Saramäki, J. and Kaski, K. and Kertész, J.},
	year = {2007},
}

@article{fortunato_resolution_2007,
	title = {Resolution limit in community detection},
	doi = {10.1073/pnas.0605965104},
	abstract = {Detecting community structure is fundamental for uncovering the links between structure and function in complex networks and for practical applications in many disciplines such as biology and sociology. A popular method now widely used relies on the optimization of a quantity called modularity, which is a quality index for a partition of a network into communities. We find that modularity optimization may fail to identify modules smaller than a scale which depends on the total size of the network and on the degree of inter-connectedness of the modules, even in cases where modules are unambiguously defined. This finding is confirmed through several examples, both in artificial and in real social, biological, and technological networks, where we show that modularity optimization indeed does not resolve a large number of modules. A check of the modules obtained through modularity optimization is thus necessary, and we provide here key elements for the assessment of the reliability of this community detection method. © 2006 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Fortunato, Santo and Barthélemy, Marc},
	year = {2007},
	keywords = {Complex networks, Metabolic networks, Modular structure, Social networks},
}

@article{wilson_testing_2014,
	title = {A testing based extraction algorithm for identifying significant communities in networks},
	doi = {10.1214/14-AOAS760},
	abstract = {A common and important problem arising in the study of networks is how to divide the vertices of a given network into one or more groups, called communities, in such a way that vertices of the same community are more interconnected than vertices belonging to different ones. We propose and investigate a testing based community detection procedure called Extraction of Statistically Significant Communities (ESSC). The ESSC procedure is based on p-values for the strength of connection between a single vertex and a set of vertices under a reference distribution derived from a conditional configuration network model. The procedure automatically selects both the number of communities in the network and their size. Moreover, ESSC can handle overlapping communities and, unlike the majority of existing methods, identifies “background” vertices that do not belong to a well-defined community. The method has only one parameter, which controls the stringency of the hypothesis tests. We investigate the performance and potential use of ESSC and compare it with a number of existing methods, through a validation study using four real network data sets. In addition, we carry out a simulation study to assess the effectiveness of ESSC in networks with various types of community structure, including networks with overlapping communities and those with background vertices. These results suggest that ESSC is an effective exploratory tool for the discovery of relevant community structure in complex network systems. Data and software are available at http://www.unc.edu/∼jameswd/research.html.},
	journal = {Annals of Applied Statistics},
	author = {Wilson, James D. and Wang, Simi and Mucha, Peter J. and Bhamidi, Shankar and Nobel, Andrew B.},
	year = {2014},
	keywords = {Multiple testing, Community detection, Background, Extraction, Networks},
}

@article{wilson_testing_2014-1,
	title = {A testing based extraction algorithm for identifying significant communities in networks},
	doi = {10.1214/14-AOAS760},
	abstract = {A common and important problem arising in the study of networks is how to divide the vertices of a given network into one or more groups, called communities, in such a way that vertices of the same community are more interconnected than vertices belonging to different ones. We propose and investigate a testing based community detection procedure called Extraction of Statistically Significant Communities (ESSC). The ESSC procedure is based on p-values for the strength of connection between a single vertex and a set of vertices under a reference distribution derived from a conditional configuration network model. The procedure automatically selects both the number of communities in the network and their size. Moreover, ESSC can handle overlapping communities and, unlike the majority of existing methods, identifies “background” vertices that do not belong to a well-defined community. The method has only one parameter, which controls the stringency of the hypothesis tests. We investigate the performance and potential use of ESSC and compare it with a number of existing methods, through a validation study using four real network data sets. In addition, we carry out a simulation study to assess the effectiveness of ESSC in networks with various types of community structure, including networks with overlapping communities and those with background vertices. These results suggest that ESSC is an effective exploratory tool for the discovery of relevant community structure in complex network systems. Data and software are available at http://www.unc.edu/∼jameswd/research.html.},
	journal = {Annals of Applied Statistics},
	author = {Wilson, James D. and Wang, Simi and Mucha, Peter J. and Bhamidi, Shankar and Nobel, Andrew B.},
	year = {2014},
	keywords = {Multiple testing, Community detection, Background, Extraction, Networks},
}

@article{bianconia_assessing_2009,
	title = {Assessing the relevance of node features for network structure},
	doi = {10.1073/pnas.0811511106},
	abstract = {Networks describe a variety of interacting complex systems in social science, biology, and information technology. Usually the nodes of real networks are identified not only by their connections but also by some other characteristics. Examples of characteristics of nodes can be age, gender, or nationality of a person in a social network, the abundance of proteins in the cell taking part in protein-interaction networks, or the geographical position of airports that are connected by directed flights. Integrating the information on the connections of each node with the information about its characteristics is crucial to discriminating between the essential and negligible characteristics of nodes for the structure of the network. In this paper we propose a general indicator Θ, based on entropy measures, to quantify the dependence of a network's structure on a given set of features. We apply this method to social networks of friendships in U.S. schools, to the protein-interaction network of Saccharomyces cerevisiae and to the U.S. airport network, showing that the proposed measure provides information that complements other known measures.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Bianconia, Ginestra and Pinb, Paolo and Marsilia, Matteo},
	year = {2009},
	keywords = {Social networks, Communities, Entropy, Inference},
}

@article{traag_significant_2013,
	title = {Significant scales in community structure},
	doi = {10.1038/srep02930},
	abstract = {Many complex networks show signs of modular structure, uncovered by community detection. Although many methods succeed in revealing various partitions, it remains difficult to detect at what scale some partition is significant. This problem shows foremost in multi-resolution methods. We here introduce an efficient method for scanning for resolutions in one such method. Additionally, we introduce the notion of "significance" of a partition, based on subgraph probabilities. Significance is independent of the exact method used, so could also be applied in other methods, and can be interpreted as the gain in encoding a graph by making use of a partition. Using significance, we can determine "good" resolution parameters, which we demonstrate on benchmark networks. Moreover, optimizing significance itself also shows excellent performance. We demonstrate our method on voting data from the European Parliament. Our analysis suggests the European Parliament has become increasingly ideologically divided and that nationality plays no role.},
	journal = {Scientific Reports},
	author = {Traag, V. A. and Krings, G. and Van Dooren, P.},
	year = {2013},
}

@inproceedings{yang_defining_2012,
	title = {Defining and evaluating network communities based on ground-truth},
	isbn = {978-1-4503-1546-3},
	doi = {10.1145/2350190.2350193},
	abstract = {Nodes in real-world networks, such as social, information or technological networks, organize into communities where edges appear with high concentration among the members of the community. Identifying communities in networks has proven to be a challenging task mainly due to a plethora of definitions of a community, intractability of algorithms, issues with evaluation and the lack of a reliable gold-standard ground-truth. We study a set of 230 large social, collaboration and information networks where nodes explicitly define group memberships. We use these groups to define the notion of ground-truth communities. We then propose a methodology which allows us to compare and quantitatively evaluate different definitions of network communities on a large scale. We choose 13 commonly used definitions of network communities and examine their quality, sensitivity and robustness. We show that the 13 definitions naturally group into four classes. We find that two of these definitions, Conductance and Triad-participation-ratio, consistently give the best performance in identifying ground-truth communities. Copyright © 2012 ACM.},
	booktitle = {Proceedings of the {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	author = {Yang, Jaewon and Leskovec, Jure},
	year = {2012},
	keywords = {Community scores, Network communities, Social and information networks},
}

@article{zhang_scalable_2014,
	title = {Scalable detection of statistically significant communities and hierarchies, using message passing for modularity},
	doi = {10.1073/pnas.1409770111},
	abstract = {Modularity is a popular measure of community structure. However, maximizing the modularity can lead to many competing partitions, with almost the same modularity, that are poorly correlated with each other. It can also produce illusory "communities" in random graphs where none exist. We address this problem by using the modularity as a Hamiltonian at finite temperature and using an efficient belief propagation algorithm to obtain the consensus of many partitions with high modularity, rather than looking for a single partition that maximizes it. We show analytically and numerically that the proposed algorithm works all of the way down to the detectability transition in networks generated by the stochastic block model. It also performs well on real-world networks, revealing large communities in some networks where previous work has claimed no communities exist. Finally we show that by applying our algorithm recursively, subdividing communities until no statistically significant subcommunities can be found, we can detect hierarchical structure in real-world networks more efficiently than previous methods.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Zhang, Pan and Moore, Cristopher},
	year = {2014},
	keywords = {Community detection, Networks, Message-passing algorithms, Phase transitions, Statistical significance},
}

@article{peixoto_model_2015,
	title = {Model selection and hypothesis testing for large-scale network models with overlapping groups},
	doi = {10.1103/PhysRevX.5.011033},
	abstract = {The effort to understand network systems in increasing detail has resulted in a diversity of methods designed to extract their large-scale structure from data. Unfortunately, many of these methods yield diverging descriptions of the same network, making both the comparison and understanding of their results a difficult challenge. A possible solution to this outstanding issue is to shift the focus away from ad hoc methods and move towards more principled approaches based on statistical inference of generative models. As a result, we face instead the more well-defined task of selecting between competing generative processes, which can be done under a unified probabilistic framework. Here, we consider the comparison between a variety of generative models including features such as degree correction, where nodes with arbitrary degrees can belong to the same group, and community overlap, where nodes are allowed to belong to more than one group. Because such model variants possess an increasing number of parameters, they become prone to overfitting. In this work, we present a method of model selection based on the minimum description length criterion and posterior odds ratios that is capable of fully accounting for the increased degrees of freedom of the larger models and selects the best one according to the statistical evidence available in the data. In applying this method to many empirical unweighted networks from different fields, we observe that community overlap is very often not supported by statistical evidence and is selected as a better model only for a minority of them. On the other hand, we find that degree correction tends to be almost universally favored by the available data, implying that intrinsic node proprieties (as opposed to group properties) are often an essential ingredient of network formation.},
	journal = {Physical Review X},
	author = {Peixoto, Tiago P.},
	year = {2015},
	keywords = {Complex systems, Interdisciplinary physics, Statistical physics},
}

@article{lambiotte_random_2014,
	title = {Random walks, {Markov} processes and the multiscale modular organization of complex networks},
	doi = {10.1109/TNSE.2015.2391998},
	abstract = {Most methods proposed to uncover communities in complex networks rely on combinatorial graph properties. Usually an edge-counting quality function, such as modularity, is optimized over all partitions of the graph compared against a null random graph model. Here we introduce a systematic dynamical framework to design and analyze a wide variety of quality functions for community detection. The quality of a partition is measured by its Markov Stability, a time-parametrized function defined in terms of the statistical properties of a Markov process taking place on the graph. The Markov process provides a dynamical sweeping across all scales in the graph, and the time scale is an intrinsic parameter that uncovers communities at different resolutions. This dynamic-based community detection leads to a compound optimization, which favours communities of comparable centrality (as defined by the stationary distribution), and provides a unifying framework for spectral algorithms, as well as different heuristics for community detection, including versions of modularity and Potts model. Our dynamic framework creates a systematic link between different stochastic dynamics and their corresponding notions of optimal communities under distinct (node and edge) centralities. We show that the Markov Stability can be computed efficiently to find multi-scale community structure in large networks.},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Lambiotte, Renaud and Delvenne, Jean Charles and Barahona, Mauricio},
	year = {2014},
	keywords = {Complex networks, Communities, centrality, community detection, graph theory, Graph theory, multiscale structure, Multiscale structures, optimization, Optimization, partition stability, random walks},
}

@article{kojaku_generalised_2018,
	title = {A generalised significance test for individual communities in networks},
	doi = {10.1038/s41598-018-25560-z},
	abstract = {Many empirical networks have community structure, in which nodes are densely interconnected within each community (i.e., a group of nodes) and sparsely across different communities. Like other local and meso-scale structure of networks, communities are generally heterogeneous in various aspects such as the size, density of edges, connectivity to other communities and significance. In the present study, we propose a method to statistically test the significance of individual communities in a given network. Compared to the previous methods, the present algorithm is unique in that it accepts different community-detection algorithms and the corresponding quality function for single communities. The present method requires that a quality of each community can be quantified and that community detection is performed as optimisation of such a quality function summed over the communities. Various community detection algorithms including modularity maximisation and graph partitioning meet this criterion. Our method estimates a distribution of the quality function for randomised networks to calculate a likelihood of each community in the given network. We illustrate our algorithm by synthetic and empirical networks.},
	journal = {Scientific Reports},
	author = {Kojaku, Sadamori and Masuda, Naoki},
	year = {2018},
}

@article{aldecoa_deciphering_2011-2,
	title = {Deciphering network community structure by surprise},
	doi = {10.1371/journal.pone.0024195},
	abstract = {The analysis of complex networks permeates all sciences, from biology to sociology. A fundamental, unsolved problem is how to characterize the community structure of a network. Here, using both standard and novel benchmarks, we show that maximization of a simple global parameter, which we call Surprise (S), leads to a very efficient characterization of the community structure of complex synthetic networks. Particularly, S qualitatively outperforms the most commonly used criterion to define communities, Newman and Girvan's modularity (Q). Applying S maximization to real networks often provides natural, well-supported partitions, but also sometimes counterintuitive solutions that expose the limitations of our previous knowledge. These results indicate that it is possible to define an effective global criterion for community structure and open new routes for the understanding of complex networks. © 2011 Aldecoa, Marín.},
	journal = {PLoS ONE},
	author = {Aldecoa, Rodrigo and Marín, Ignacio},
	year = {2011},
}

@article{traag_significant_2013-1,
	title = {Significant scales in community structure},
	doi = {10.1038/srep02930},
	abstract = {Many complex networks show signs of modular structure, uncovered by community detection. Although many methods succeed in revealing various partitions, it remains difficult to detect at what scale some partition is significant. This problem shows foremost in multi-resolution methods. We here introduce an efficient method for scanning for resolutions in one such method. Additionally, we introduce the notion of "significance" of a partition, based on subgraph probabilities. Significance is independent of the exact method used, so could also be applied in other methods, and can be interpreted as the gain in encoding a graph by making use of a partition. Using significance, we can determine "good" resolution parameters, which we demonstrate on benchmark networks. Moreover, optimizing significance itself also shows excellent performance. We demonstrate our method on voting data from the European Parliament. Our analysis suggests the European Parliament has become increasingly ideologically divided and that nationality plays no role.},
	journal = {Scientific Reports},
	author = {Traag, V. A. and Krings, G. and Van Dooren, P.},
	year = {2013},
}

@article{carissimo_validation_2018-1,
	title = {Validation of community robustness},
	doi = {10.1016/j.csda.2017.10.006},
	abstract = {The large amount of work on community detection and its applications leaves unaddressed one important question: the statistical validation of the results. A methodology is presented that is able to clearly detect if the community structure found by some algorithms is statistically significant or is a result of chance, merely due to edge positions in the network. Given a community detection method and a network of interest, the proposal examines the stability of the partition recovered against random perturbations of the original graph structure. To address this issue, a perturbation strategy and a null model graph, which matches the original in some of its structural properties, but is otherwise a random graph, is specified. A set of procedures is built based on a special measure of clustering distance, namely Variation of Information, using tools set up for functional data analysis. The procedures determine whether the obtained clustering departs significantly from the null model. This strongly supports the robustness against perturbation of the algorithm used to identify the community structure. Results obtained with the proposed technique on simulated and real datasets are shown and discussed.},
	journal = {Computational Statistics and Data Analysis},
	author = {Carissimo, Annamaria and Cutillo, Luisa and Feis, Italia De},
	year = {2018},
	keywords = {Community, Multiple testing, Network, Variation of information},
}

@article{rosvall_mapping_2010,
	title = {Mapping change in large networks},
	doi = {10.1371/journal.pone.0008694},
	abstract = {Change is a fundamental ingredient of interaction patterns in biology, technology, the economy, and science itself: Interactions within and between organisms change; transportation patterns by air, land, and sea all change; the global financial flow changes; and the frontiers of scientific research change. Networks and clustering methods have become important tools to comprehend instances of these large-scale structures, but without methods to distinguish between real trends and noisy data, these approaches are not useful for studying how networks change. Only if we can assign significance to the partitioning of single networks can we distinguish meaningful structural changes from random fluctuations. Here we show that bootstrap resampling accompanied by significance clustering provides a solution to this problem. To connect changing structures with the changing function of networks, we highlight and summarize the significant structural changes with alluvial diagrams and realize de Solla Price's vision of mapping change in science: studying the citation pattern between about 7000 scientific journals over the past decade, we find that neuroscience has transformed from an interdisciplinary specialty to a mature and stand-alone discipline. © 2010 Rosvall, Bergstrom.},
	journal = {PLoS ONE},
	author = {Rosvall, Martin and Bergstrom, Carl T.},
	year = {2010},
}

@article{clauset_hierarchical_2008,
	title = {Hierarchical structure and the prediction of missing links in networks},
	doi = {10.1038/nature06830},
	abstract = {Networks have in recent years emerged as an invaluable tool for describing and quantifying complex systems in many branches of science. Recent studies suggest that networks often exhibit hierarchical organization, in which vertices divide into groups that further subdivide into groups of groups, and so forth over multiple scales. In many cases the groups are found to correspond to known functional units, such as ecological niches in food webs, modules in biochemical networks (protein interaction networks, metabolic networks or genetic regulatory networks) or communities in social networks. Here we present a general technique for inferring hierarchical structure from network data and show that the existence of hierarchy can simultaneously explain and quantitatively reproduce many commonly observed topological properties of networks, such as right-skewed degree distributions, high clustering coefficients and short path lengths. We further show that knowledge of hierarchical structure can be used to predict missing connections in partly known networks with high accuracy, and for more general network structures than competing techniques. Taken together, our results suggest that hierarchy is a central organizing principle of complex networks, capable of offering insight into many network phenomena. ©2008 Nature Publishing Group.},
	journal = {Nature},
	author = {Clauset, Aaron and Moore, Cristopher and Newman, M. E.J.},
	year = {2008},
}

@article{goldenberg_survey_2009,
	title = {A survey of statistical network models},
	doi = {10.1561/2200000005},
	abstract = {Networks are ubiquitous in science and have become a focal point for discussion in everyday life. Formal statistical models for the analysis of network data have emerged as a major topic of interest in diverse areas of study, and most of these involve a form of graphical representation. Probability models on graphs date back to 1959. Along with empirical studies in social psychology and sociology from the 1960s, these early works generated an active "network community" and a substantial literature in the 1970s. This effort moved into the statistical literature in the late 1970s and 1980s, and the past decade has seen a burgeoning network literature in statistical physics and computer science. The growth of the World Wide Web and the emergence of online "networking communities" such as Facebook, MySpace, and LinkedIn, and a host of more specialized professional network communities has intensified interest in the study of networks and network data. Our goal in this review is to provide the reader with an entry point to this burgeoning literature. We begin with an overview of the historical development of statistical network modeling and then we introduce a number of examples that have been studied in the network literature. Our subsequent discussion focuses on a number of prominent static and dynamic network models and their interconnections. We emphasize formal model descriptions, and pay special attention to the interpretation of parameters and their estimation. We end with a description of some open problems and challenges for machine learning and statistics. © 2010 A. Goldenberg, A. X. Zheng, S. E. Fienberg and E. M. Airoldi.},
	journal = {Foundations and Trends in Machine Learning},
	author = {Goldenberg, Anna and Zheng, Alice X. and Fienberg, Stephen E. and Airoldi, Edoardo M.},
	year = {2009},
}

@article{zhao_community_2011,
	title = {Community extraction for social networks},
	doi = {10.1073/pnas.1006642108},
	abstract = {Analysis of networks and in particular discovering communities within networks has been a focus of recent work in several fields and has diverse applications. Most community detection methods focus on partitioning the entire network into communities, with the expectation of many ties within communities and few ties between. However, many networks contain nodes that do not fit in with any of the communities, and forcing every node into a community can distort results. Here we propose a new framework that extracts one community at a time, allowing for arbitrary structure in the remainder of the network, which can include weakly connected nodes. The main idea is that the strength of a community should depend on ties between its members and ties to the outside world, but not on ties between nonmembers. The proposed extraction criterion has a natural probabilistic interpretation in a wide class of models and performs well on simulated and real networks. For the case of the block model, we establish asymptotic consistency of estimated node labels and propose a hypothesis test for determining the number of communities.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Zhao, Yunpeng and Levina, Elizaveta and Zhu, Ji},
	year = {2011},
}

@article{mucha_community_2010,
	title = {Community structure in time-dependent, multiscale, and multiplex networks},
	doi = {10.1126/science.1184819},
	abstract = {Network science is an interdisciplinary endeavor, with methods and applications drawn from across the natural, social, and information sciences. A prominent problem in network science is the algorithmic detection of tightly connected groups of nodes known as communities. We developed a generalized framework of network quality functions that allowed us to study the community structure of arbitrary multislice networks, which are combinations of individual networks coupled through links that connect each node in one network slice to itself in other slices. This framework allows studies of community structure in a general setting encompassing networks that evolve over time, have multiple types of links (multiplexity), and have multiple scales.},
	journal = {Science},
	author = {Mucha, Peter J. and Richardson, Thomas and Macon, Kevin and Porter, Mason A. and Onnela, Jukka Pekka},
	year = {2010},
}

@article{blondel_fast_2008,
	title = {Fast unfolding of communities in large networks},
	doi = {10.1088/1742-5468/2008/10/P10008},
	abstract = {We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad hoc modular networks. © 2008 IOP Publishing Ltd.},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Blondel, Vincent D. and Guillaume, Jean Loup and Lambiotte, Renaud and Lefebvre, Etienne},
	year = {2008},
	keywords = {Networks, New applications of statistical mechanics, Random graphs},
}

@article{clauset_finding_2004,
	title = {Finding community structure in very large networks},
	doi = {10.1103/PhysRevE.70.066111},
	abstract = {The discovery and analysis of community structure in networks is a topic of considerable recent interest within the physics community, but most methods proposed so far are unsuitable for very large networks because of their computational cost. Here we present a hierarchical agglomeration algorithm for detecting community structure which is faster than many competing algorithms: its running time on a network with [Formula presented] vertices and [Formula presented] edges is [Formula presented] where [Formula presented] is the depth of the dendrogram describing the community structure. Many real-world networks are sparse and hierarchical, with [Formula presented] and [Formula presented], in which case our algorithm runs in essentially linear time, [Formula presented]. As an example of the application of this algorithm we use it to analyze a network of items for sale on the web site of a large on-line retailer, items in the network being linked if they are frequently purchased by the same buyer. The network has more than 400?000 vertices and [Formula presented] edges. We show that our algorithm can extract meaningful communities from this network, revealing large-scale patterns present in the purchasing habits of customers. © 2004 The American Physical Society.},
	journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
	author = {Clauset, Aaron and Newman, M. E.J. and Moore, Cristopher},
	year = {2004},
}

@article{newman_fast_2004,
	title = {Fast algorithm for detecting community structure in networks},
	doi = {10.1103/PhysRevE.69.066133},
	abstract = {Many networks display community structure—groups of vertices within which connections are dense but between which they are sparser—and sensitive computer algorithms have in recent years been developed for detecting this structure. These algorithms, however, are computationally demanding, which limits their application to small networks. Here we describe an algorithm which gives excellent results when tested on both computer-generated and real-world networks and is much faster, typically thousands of times faster, than previous algorithms. We give several example applications, including one to a collaboration network of more than 50?000 physicists. © 2004 The American Physical Society.},
	journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
	author = {Newman, M. E.J.},
	year = {2004},
}

@article{bianconia_assessing_2009-1,
	title = {Assessing the relevance of node features for network structure},
	doi = {10.1073/pnas.0811511106},
	abstract = {Networks describe a variety of interacting complex systems in social science, biology, and information technology. Usually the nodes of real networks are identified not only by their connections but also by some other characteristics. Examples of characteristics of nodes can be age, gender, or nationality of a person in a social network, the abundance of proteins in the cell taking part in protein-interaction networks, or the geographical position of airports that are connected by directed flights. Integrating the information on the connections of each node with the information about its characteristics is crucial to discriminating between the essential and negligible characteristics of nodes for the structure of the network. In this paper we propose a general indicator Θ, based on entropy measures, to quantify the dependence of a network's structure on a given set of features. We apply this method to social networks of friendships in U.S. schools, to the protein-interaction network of Saccharomyces cerevisiae and to the U.S. airport network, showing that the proposed measure provides information that complements other known measures.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Bianconia, Ginestra and Pinb, Paolo and Marsilia, Matteo},
	year = {2009},
	keywords = {Social networks, Communities, Entropy, Inference},
}

@article{lancichinetti_statistical_2010,
	title = {Statistical significance of communities in networks},
	doi = {10.1103/PhysRevE.81.046110},
	abstract = {Nodes in real-world networks are usually organized in local modules. These groups, called communities, are intuitively defined as subgraphs with a larger density of internal connections than of external links. In this work, we define a measure aimed at quantifying the statistical significance of single communities. Extreme and order statistics are used to predict the statistics associated with individual clusters in random graphs. These distributions allows us to define one community significance as the probability that a generic clustering algorithm finds such a group in a random graph. The method is successfully applied in the case of real-world networks for the evaluation of the significance of their communities. © 2010 The American Physical Society.},
	journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
	author = {Lancichinetti, Andrea and Radicchi, Filippo and Ramasco, José J.},
	year = {2010},
}

@article{fortunato_community_2010,
	title = {Community detection in graphs},
	doi = {10.1016/j.physrep.2009.11.002},
	abstract = {The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks. © 2009 Elsevier B.V.},
	journal = {Physics Reports},
	author = {Fortunato, Santo},
	year = {2010},
	keywords = {Clusters, Statistical physics, Graphs},
}

@article{newman_modularity_2006,
	title = {Modularity and community structure in networks},
	doi = {10.1073/pnas.0601602103},
	abstract = {Many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. The problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. One highly effective approach is the optimization of the quality function known as "modularity" over the possible divisions of a network. Here I show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which I call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. I illustrate the method with applications to several published network data sets. © 2006 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Newman, M. E.J.},
	year = {2006},
	keywords = {Clustering, Metabolic network, Modules, Partitioning, Social network},
}

@article{kelly_pandemic_2010,
	title = {Pandemic ({H1N1}) 2009 influenza community transmission was established in one {Australian} state when the virus was first identified in {North} {America}},
	doi = {10.1371/journal.pone.0011341},
	abstract = {Background: In mid-June 2009 the State of Victoria in Australia appeared to have the highest notification rate of pandemic (H1N1) 2009 influenza in the world. We hypothesise that this was because community transmission of pandemic influenza was already well established in Victoria at the time testing for the novel virus commenced. In contrast, this was not true for the pandemic in other parts of Australia, including Western Australia (WA). Methods: We used data from detailed case follow-up of patients with confirmed infection in Victoria and WA to demonstrate the difference in the pandemic curve in two Australian states on opposite sides of the continent. We modelled the pandemic in both states, using a susceptible-infected-removed model with Bayesian inference accounting for imported cases. Results: Epidemic transmission occurred earlier in Victoria and later in WA. Only 5\% of the first 100 Victorian cases were not locally acquired and three of these were brothers in one family. By contrast, 53\% of the first 102 cases in WA were associated with importation from Victoria. Using plausible model input data, estimation of the effective reproductive number for the Victorian epidemic required us to invoke an earlier date for commencement of transmission to explain the observed data. This was not required in modelling the epidemic in WA. Conclusion: Strong circumstantial evidence, supported by modelling, suggests community transmission of pandemic influenza was well established in Victoria, but not in WA, at the time testing for the novel virus commenced in Australia. The virus is likely to have entered Victoria and already become established around the time it was first identified in the US and Mexico. © 2010 Kelly et al.},
	journal = {PLoS ONE},
	author = {Kelly, Heath A. and Mercer, Geoff N. and Fielding, James E. and Dowse, Gary K. and Glass, Kathryn and Carcione, Dale and Grant, Kristina A. and Effler, Paul V. and Lester, Rosemary A.},
	year = {2010},
}

@article{ferguson_transmission_2001,
	title = {Transmission intensity and impact of control policies on the foot and mouth epidemic in {Great} {Britain}},
	doi = {10.1038/35097116},
	abstract = {The foot and mouth disease (FMD) epidemic in British livestock remains an ongoing cause for concern, with new cases still arising in previously unaffected areas. Epidemiological analyses have been vital in delivering scientific advice to government on effective control measures. Using disease, culling and census data on all livestock farms in Great Britain, we analysed the risk factors determining the spatiotemporal evolution of the epidemic and of the impact of control policies on FMD incidence. Here we show that the species mix, animal numbers and the number of distinct land parcels in a farm are central to explaining regional variation in transmission intensity. We use the parameter estimates thus obtained in a dynamical model of disease spread to show that extended culling programmes were essential for controlling the epidemic to the extent achieved, but demonstrate that the epidemic could have been substantially reduced in scale had the most efficient control measures been rigorously applied earlier.},
	journal = {Nature},
	author = {Ferguson, N. M. and Donnelly, C. A. and Anderson, R. M.},
	year = {2001},
}

@article{bettencourt_real_2008,
	title = {Real time bayesian estimation of the epidemic potential of emerging infectious diseases},
	doi = {10.1371/journal.pone.0002185},
	abstract = {Background: Fast changes in human demographics worldwide, coupled with increased mobility, and modified land uses make the threat of emerging infectious diseases increasingly important. Currently there is worldwide alert for H5N1 avian influenza becoming as transmissible in humans as seasonal influenza, and potentially causing a pandemic of unprecedented proportions. Here we show how epidemiological surveillance data for emerging infectious diseases can be interpreted in real time to assess changes in transmissibility with quantified uncertainty, and to perform running time predictions of new cases and guide logistics allocations. Methodology/Principal Findings: We develop an extension of standard epidemiological models, appropriate for emerging infectious diseases, that describes the probabilistic progression of case numbers due to the concurrent effects of (incipient) human transmission and multiple introductions from a reservoir. The model is cast in terms of surveillance observables and immediately suggests a simple graphical estimation procedure for the effective reproductive number R (mean number of cases generated by an infectious individual) of standard epidemics. For emerging infectious diseases, which typically show large relative case number fluctuations over time, we develop a Bayesian scheme for real time estimation of the probability distribution of the effective reproduction number and show how to use such inferences to formulate significance tests on future epidemiological observations. Conclusions/Significance: Violations of these significance tests define statistical anomalies that may signal changes in the epidemiology of emerging diseases and should trigger further field investigation. We apply the methodology to case data from World Health Organization reports to place bounds on the current transmissibility of H5N1 influenza in humans and establish a statistical basis for monitoring its evolution in real time. © 2008 Bettencourt, Ribeiro.},
	journal = {PLoS ONE},
	author = {Bettencourt, Luís M.A. and Ribeiro, Ruy M.},
	year = {2008},
}

@article{riley_transmission_2003,
	title = {Transmission dynamics of the etiological agent of {SARS} in {Hong} {Kong}: {Impact} of public health interventions},
	doi = {10.1126/science.1086478},
	abstract = {We present an analysis of the first 10 weeks of the severe acute respiratory syndrome (SARS) epidemic in Hong Kong. The epidemic to date has been characterized by two large clusters - initiated by two separate "super-spread" events (SSEs) - and by ongoing community transmission. By fitting a stochastic model to data on 1512 cases, including these clusters, we show that the etiological agent of SARS is moderately transmissible. Excluding SSES, we estimate that 2.7 secondary infections were generated per case on average at the start of the epidemic, with a substantial contribution from hospital transmission. Transmission rates fell during the epidemic, primarily as a result of reductions in population contact rates and improved hospital infection control, but also because of more rapid hospital attendance by symptomatic individuals. As a result, the epidemic is now in decline, although continued vigilance is necessary for this to be maintained. Restrictions on longer range population movement are shown to be a potentially useful additional control measure in some contexts. We estimate that most currently infected persons are now hospitalized, which highlights the importance of control of nosocomial transmission.},
	journal = {Science},
	author = {Riley, Steven and Fraser, Christophe and Donnelly, Christl A. and Ghani, Azra C. and Abu-Raddad, Laith J. and Hedley, Anthony J. and Leung, Gabriel M. and Ho, Lai Ming and Lam, Tai Hing and Thach, Thuan Q. and Chau, Patsy and Chan, King Pan and Lo, Su Vui and Leung, Pak Yin and Tsang, Thomas and Ho, William and Lee, Koon Hung and Lau, Edith M.C. and Ferguson, Neil M. and Anderson, Roy M.},
	year = {2003},
}

@article{miller_mobility_2020,
	title = {Mobility trends provide a leading indicator of changes in {SARS}-{CoV}-2 transmission},
	url = {https://www.medrxiv.org/content/early/2020/05/11/2020.05.07.20094441},
	doi = {10.1101/2020.05.07.20094441},
	journal = {medRxiv},
	author = {Miller, Andrew C and Foti, Nicholas J and Lewnard, Joseph A and Jewell, Nicholas P and Guestrin, Carlos and Fox, Emily B},
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
}

@article{fraser_pandemic_2009,
	title = {Pandemic potential of a strain of influenza {A} ({H1N1}): {Early} findings},
	doi = {10.1126/science.1176062},
	abstract = {A novel influenza A (H1N1) virus has spread rapidly across the globe. Judging its pandemic potential is difficult with limited data, but nevertheless essential to inform appropriate health responses. By analyzing the outbreak in Mexico, early data on international spread, and viral genetic diversity, we make an early assessment of transmissibility and severity. Our estimates suggest that 23,000 (range 6000 to 32,000) individuals had been infected in Mexico by late April, giving an estimated case fatality ratio (CFR) of 0.4\% (range: 0.3 to 1.8\%) based on confirmed and suspected deaths reported to that time. In a community outbreak in the small community of La Gloria, Veracruz, no deaths were attributed to infection, giving an upper 95\% bound on CFR of 0.6\%. Thus, although substantial uncertainty remains, clinical severity appears less than that seen in the 1918 influenza pandemic but comparable with that seen in the 1957 pandemic. Clinical attack rates in children in La Gloria were twice that in adults ({\textless}15 years of age: 61\%; =15 years: 29\%). Three different epidemiological analyses gave basic reproduction number (R0) estimates in the range of 1.4 to 1.6, whereas a genetic analysis gave a central estimate of 1.2. This range of values is consistent with 14 to 73 generations of human-to-human transmission having occurred in Mexico to late April. Transmissibility is therefore substantially higher than that of seasonal flu, and comparable with lower estimates of R0 obtained from previous influenza pandemics.},
	journal = {Science},
	author = {Fraser, Christophe and Donnelly, Christl A. and Cauchemez, Simon and Hanage, William P. and Van Kerkhove, Maria D. and Hollingsworth, T. Déirdre and Griffin, Jamie and Baggaley, Rebecca F. and Jenkins, Helen E. and Lyons, Emily J. and Jombart, Thibaut and Hinsley, Wes R. and Grassly, Nicholas C. and Balloux, Francois and Ghani, Azra C. and Ferguson, Neil M. and Rambaut, Andrew and Pybus, Oliver G. and Lopez-Gatell, Hugo and Alpuche-Aranda, Celia M. and Chapela, Ietza Bojorquez and Zavala, Ethel Palacios and Ma. Espejo Guevara, Dulce and Checchi, Francesco and Garcia, Erika and Hugonnet, Stephane and Roth, Cathy},
	year = {2009},
}

@book{kreft_introducing_2011,
	title = {Introducing {Multilevel} {Modeling}},
	abstract = {This is a user-oriented guide to the practicalities of multilevel modeling in social research. The authors introduce the researcher to the practical issues and problems of doing multilevel analyses. On the basis of genuine data sets, they illustrate the technique through worked examples, using the leading computer package for multilevel modeling, MLn. This book will be useful for students and researchers who need to know how to apply multilevel models appropriately and effectively. (PsycINFO Database Record (c) 2003 APA, all rights reserved)},
	author = {Kreft, Ita and de Leeuw, Jan},
	year = {2011},
	doi = {10.4135/9781849209366},
	note = {Publication Title: Introducing Multilevel Modeling},
}

@article{cowling_impact_2020,
	title = {Impact assessment of non-pharmaceutical interventions against coronavirus disease 2019 and influenza in {Hong} {Kong}: an observational study},
	doi = {10.1016/S2468-2667(20)30090-6},
	abstract = {Background: A range of public health measures have been implemented to suppress local transmission of coronavirus disease 2019 (COVID-19) in Hong Kong. We examined the effect of these interventions and behavioural changes of the public on the incidence of COVID-19, as well as on influenza virus infections, which might share some aspects of transmission dynamics with COVID-19. Methods: We analysed data on laboratory-confirmed COVID-19 cases, influenza surveillance data in outpatients of all ages, and influenza hospitalisations in children. We estimated the daily effective reproduction number (Rt) for COVID-19 and influenza A H1N1 to estimate changes in transmissibility over time. Attitudes towards COVID-19 and changes in population behaviours were reviewed through three telephone surveys done on Jan 20–23, Feb 11–14, and March 10–13, 2020. Findings: COVID-19 transmissibility measured by Rt has remained at approximately 1 for 8 weeks in Hong Kong. Influenza transmission declined substantially after the implementation of social distancing measures and changes in population behaviours in late January, with a 44\% (95\% CI 34–53\%) reduction in transmissibility in the community, from an estimated Rt of 1·28 (95\% CI 1·26–1·30) before the start of the school closures to 0·72 (0·70–0·74) during the closure weeks. Similarly, a 33\% (24–43\%) reduction in transmissibility was seen based on paediatric hospitalisation rates, from an Rt of 1·10 (1·06–1·12) before the start of the school closures to 0·73 (0·68–0·77) after school closures. Among respondents to the surveys, 74·5\%, 97·5\%, and 98·8\% reported wearing masks when going out, and 61·3\%, 90·2\%, and 85·1\% reported avoiding crowded places in surveys 1 (n=1008), 2 (n=1000), and 3 (n=1005), respectively. Interpretation: Our study shows that non-pharmaceutical interventions (including border restrictions, quarantine and isolation, distancing, and changes in population behaviour) were associated with reduced transmission of COVID-19 in Hong Kong, and are also likely to have substantially reduced influenza transmission in early February, 2020. Funding: Health and Medical Research Fund, Hong Kong.},
	journal = {The Lancet Public Health},
	author = {Cowling, Benjamin J. and Ali, Sheikh Taslim and Ng, Tiffany W.Y. and Tsang, Tim K. and Li, Julian C.M. and Fong, Min Whui and Liao, Qiuyan and Kwan, Mike YW and Lee, So Lun and Chiu, Susan S. and Wu, Joseph T. and Wu, Peng and Leung, Gabriel M.},
	year = {2020},
}

@book{gelman_data_2006,
	title = {Data {Analysis} {Using} {Regression} and {Multilevel}/{Hierarchical} {Models}},
	abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout. Author resource page: http://www.stat.columbia.edu/{\textasciitilde}gelman/arm/},
	author = {Gelman, Andrew and Hill, Jennifer},
	year = {2006},
	doi = {10.1017/cbo9780511790942},
	note = {Publication Title: Data Analysis Using Regression and Multilevel/Hierarchical Models},
}

@book{hox_multilevel_2010,
	title = {Multilevel analysis: {Techniques} and applications},
	publisher = {Routledge},
	author = {Hox, Joop J and Moerbeek, Mirjam and de Schoot, Rens},
	year = {2010},
}

@article{badr_association_2020,
	title = {Association between mobility patterns and {COVID}-19 transmission in the {USA}: a mathematical modelling study},
	doi = {10.1016/S1473-3099(20)30553-3},
	abstract = {Background: Within 4 months of COVID-19 first being reported in the USA, it spread to every state and to more than 90\% of all counties. During this period, the US COVID-19 response was highly decentralised, with stay-at-home directives issued by state and local officials, subject to varying levels of enforcement. The absence of a centralised policy and timeline combined with the complex dynamics of human mobility and the variable intensity of local outbreaks makes assessing the effect of large-scale social distancing on COVID-19 transmission in the USA a challenge. Methods: We used daily mobility data derived from aggregated and anonymised cell (mobile) phone data, provided by Teralytics (Zürich, Switzerland) from Jan 1 to April 20, 2020, to capture real-time trends in movement patterns for each US county, and used these data to generate a social distancing metric. We used epidemiological data to compute the COVID-19 growth rate ratio for a given county on a given day. Using these metrics, we evaluated how social distancing, measured by the relative change in mobility, affected the rate of new infections in the 25 counties in the USA with the highest number of confirmed cases on April 16, 2020, by fitting a statistical model for each county. Findings: Our analysis revealed that mobility patterns are strongly correlated with decreased COVID-19 case growth rates for the most affected counties in the USA, with Pearson correlation coefficients above 0·7 for 20 of the 25 counties evaluated. Additionally, the effect of changes in mobility patterns, which dropped by 35–63\% relative to the normal conditions, on COVID-19 transmission are not likely to be perceptible for 9–12 days, and potentially up to 3 weeks, which is consistent with the incubation time of severe acute respiratory syndrome coronavirus 2 plus additional time for reporting. We also show evidence that behavioural changes were already underway in many US counties days to weeks before state-level or local-level stay-at-home policies were implemented, implying that individuals anticipated public health directives where social distancing was adopted, despite a mixed political message. Interpretation: This study strongly supports a role of social distancing as an effective way to mitigate COVID-19 transmission in the USA. Until a COVID-19 vaccine is widely available, social distancing will remain one of the primary measures to combat disease spread, and these findings should serve to support more timely policy making around social distancing in the USA in the future. Funding: None.},
	journal = {The Lancet Infectious Diseases},
	author = {Badr, Hamada S. and Du, Hongru and Marshall, Maximilian and Dong, Ensheng and Squire, Marietta M. and Gardner, Lauren M.},
	year = {2020},
}

@article{bates_fitting_2015-1,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} \{lme4\}},
	volume = {67},
	doi = {10.18637/jss.v067.i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	year = {2015},
	pages = {1--48},
}

@article{goodrich_rstanarm_2020,
	title = {rstanarm: \{{Bayesian}\} applied regression modeling via \{{Stan}\}.},
	url = {https://mc-stan.org/rstanarm},
	author = {Goodrich, Ben and Gabry, Jonah and Ali, Imad and Brilleman, Sam},
	year = {2020},
	annote = {R package version 2.21.1},
}

@article{stan_development_team_rstan_2020,
	title = {\{{RStan}\}: the \{{R}\} interface to \{{Stan}\}},
	url = {http://mc-stan.org/},
	author = {{Stan Development Team}},
	year = {2020},
	annote = {R package version 2.21.2},
}

@book{r_development_core_team_r_2011,
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	isbn = {3-900051-07-0},
	abstract = {R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL http://www.R-project.org/.},
	author = {R Development Core Team, R},
	year = {2011},
	doi = {10.1007/978-3-540-74686-7},
	note = {Publication Title: R Foundation for Statistical Computing},
}

@article{scott_epidemia_2020,
	title = {epidemia: {Modeling} of {Epidemics} using {Hierarchical} {Bayesian} {Models}},
	url = {https://imperialcollegelondon.github.io/epidemia/},
	author = {Scott, James A and Gandy, Axel and Mishra, Swapnil and Unwin, Juliette and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
	annote = {R package version 0.6.0},
}

@article{stan_development_team_stan_2018,
	title = {The \{{Stan}\} {Core} {Library}},
	url = {http://mc-stan.org/},
	author = {{Stan Development Team}},
	year = {2018},
	annote = {Version 2.18.0},
}

@article{bartoszynski_branching_1967,
	title = {Branching {Processes} and the {Theory} of {Epidemics}},
	abstract = {1. Introduction In the present paper we shall discuss the extinction problem for certain branching processes. Our main purpose is to study those branching processes which can serve as models of epidemics; that is, spreads of an infectious disease. The phenomenon of epidemics is fairly complex, and all models necessarily have to be based on a certain compromise. This compromise consists of taking into account some of the (presumably important) factors governiing the spread of the disease at the cost of neglecting others. Our main idealization will consist of assuming such mechanisms of infection which yield a brailching process. Using informal language, it means that all infectives present in the population at a given time infect the susceptibles independently of each other. More precisely, if there are 7c infectives in the nth generation of the epidemics, then the distri-bution of the next (n + 1)st generation can be represented as the distribution of a sum of k independent, identically distributed random variables, with a specified distribution. These random variables represent the "progeny" of k infectives of nth generation. It is debatable whether the above assumption is justifiedlin the sense that},
	journal = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability},
	author = {Bartoszynski, Robert},
	year = {1967},
}

@incollection{getz_basic_2006,
	title = {Basic methods for modeling the invasion and spread of contagious diseases},
	abstract = {The evolution of disease requires a firm understanding of hetero-geneity among pathogen strains and hosts with regard to the processes of transmission, movement, recovery, and pathobiology. In this and a companion chapter (Getz et al. this volume), we focus on the question of how to model the invasion and spread of diseases in heterogeneous environments, without making an explicit link to natural selection-the topic of other chapters in this volume. We begin in this chapter by providing an overview of current methods used to model epidemics in homogeneous populations, covering continuous and discrete time formulations in both deterministic and stochastic frameworks. In particular, we introduce Kermack and McKendricks SIR (susceptible, infected, removed) formulation for the case where the removed (R) disease class is partitioned into immune (V class) and dead (D class) individuals. We also focus on transmission, contrasting mass-action and frequency-dependent formulations and results. This is followed by a presentation of various extensions including the consideration of the latent period of infection, the staging of disease classes, and the addition of vital and demographic processes. We then discuss the relative merits of continuous versus discrete time formulations to model real systems, particularly in the context of stochastic analyses. The overview is completed with a presentation of basic branching process theory as a sto-chastic generation-based model for the invasion of disease into populations of infinite size, with numerical extensions generalizing results to populations of finite size. In framework of branching process theory, we explore the question of minor versus major stochastic epidemics and illuminate the relationship between minor epidemics and a deterministic theory of disease invasion, as well as major epidemics and the deterministic theory of disease establishment. We conclude this chapter with a demonstration of how the basic ideas can be used to model containment policies associated with the outbreak of SARS in Asia in the early part of 2003.},
	author = {Getz, Wayne and Lloyd-Smith, James},
	year = {2006},
	doi = {10.1090/dimacs/071/05},
}

@article{champredon_equivalence_2018,
	title = {Equivalence of the {Erlang}-distributed {SEIR} epidemic model and the renewal equation},
	doi = {10.1137/18M1186411},
	abstract = {Most compartmental epidemic models can be represented using the renewal equation. The value of the renewal equation is not widely appreciated in the epidemiological modelling community, perhaps because its equivalence to standard models has not been presented rigorously in nontrivial cases. Here, we provide analytical expressions for the intrinsic generation-interval distribution that must be used in the renewal equation in order to yield epidemic dynamics that are identical to those of the susceptible-exposed-infectious-recovered (SEIR) compartmental model with Erlang-distributed latent and infectious periods. This class of models includes the standard (exponentially distributed) SIR and SEIR models as special cases.},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Champredon, David and Dushoff, Jonathan and Earn, David J.D.},
	year = {2018},
	keywords = {Differential equations, Epidemic models, Erlang distribution, Generation-interval distribution, Renewal equation, SEIR},
}

@techreport{government_chronology_2003,
	address = {Hong Kong},
	title = {Chronology of the {SARS} epidemic in {Hong} {Kong}.},
	author = {Government., SARS Expert Committee of HKSAR},
	year = {2003},
}

@techreport{organization_sars_2003,
	title = {{SARS}: chronology of a serial killer.},
	author = {Organization., World Health},
	year = {2003},
}

@article{wallinga_different_2004,
	title = {Different epidemic curves for severe acute respiratory syndrome reveal similar impacts of control measures},
	doi = {10.1093/aje/kwh255},
	abstract = {Severe acute respiratory syndrome (SARS) has been the first severe contagious disease to emerge in the 21st century. The available epidemic curves for SARS show marked differences between the affected regions with respect to the total number of cases and epidemic duration, even for those regions in which outbreaks started almost simultaneously and similar control measures were implemented at the same time. The authors developed a likelihood-based estimation procedure that infers the temporal pattern of effective reproduction numbers from an observed epidemic curve. Precise estimates for the effective reproduction numbers were obtained by applying this estimation procedure to available data for SARS outbreaks that occurred in Hong Kong, Vietnam, Singapore, and Canada in 2003. The effective reproduction numbers revealed that epidemics in the various affected regions were characterized by markedly similar disease transmission potentials and similar levels of effectiveness of control measures. In controlling SARS outbreaks, timely alerts have been essential: Delaying the institution of control measures by 1 week would have nearly tripled the epidemic size and would have increased the expected epidemic duration by 4 weeks.},
	journal = {American Journal of Epidemiology},
	author = {Wallinga, Jacco and Teunis, Peter},
	year = {2004},
	keywords = {Disease outbreaks, Estimation, Infection, Models, SARS virus, Severe acute respiratory syndrome, statistical, Statistics},
}

@article{kermack_contribution_1927,
	title = {A contribution to the mathematical theory of epidemics},
	doi = {10.1098/rspa.1927.0118},
	abstract = {(1) One of the most striking features in the study of epidemics is the difficulty of finding a causal factor which appears to be adequate to account for the magnitude of the frequent epidemics of disease which visit almost every population. It was with a view to obtaining more insight regarding the effects of the various factors which govern the spread of contagious epidemics that the present investigation was undertaken. Reference may here be made to the work of Ross and Hudson (1915-17) in which the same problem is attacked. The problem is here carried to a further stage, and it is considered from a point of view which is in one sense more general. The problem may be summarised as follows: One (or more) infected person is introduced into a community of individuals, more or less susceptible to the disease in question. The disease spreads from the affected to the unaffected by contact infection. Each infected person runs through the course of his sickness, and finally is removed from the number of those who are sick, by recovery or by death. The chances of recovery or death vary from day to day during the course of his illness. The chances that the affected may convey infection to the unaffected are likewise dependent upon the stage of the sickness. As the epidemic spreads, the number of unaffected members of the community becomes reduced. Since the course of an epidemic is short compared with the life of an individual, the population may be considered as remaining constant, except in as far as it is modified by deaths due to the epidemic disease itself. In the course of time the epidemic may come to an end. One of the most important probems in epidemiology is to ascertain whether this termination occurs only when no susceptible individuals are left, or whether the interplay of the various factors of infectivity, recovery and mortality, may result in termination, whilst many susceptible individuals are still present in the unaffected population. It is difficult to treat this problem in its most general aspect. In the present communication discussion will be limited to the case in which all members of the community are initially equally susceptible to the disease, and it will be further assumed that complete immunity is conferred by a single infection.},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	author = {Kermack, A. G., William Ogilvy {and} McKendrick},
	year = {1927},
}

@book{anderson_infectious_1992,
	title = {Infectious diseases of humans: dynamics and control},
	publisher = {Oxford university press},
	author = {Anderson, B {and} May, Robert M, Roy M {and} Anderson},
	year = {1992},
}

@article{anderson_directly_1982,
	title = {Directly transmitted infectious diseases: {Control} by vaccination},
	doi = {10.1126/science.7063839},
	abstract = {Mathematical models for the dynamics of directly transmitted viral and bacterial infections are guides to the understanding of observed patterns in the age-specific incidence of some common childhood diseases of humans, before and after the advent of vaccination programs. For those infections that show recurrent epidemic behavior, the interepidemic period can be related to parameters characterizing the infection (such as latent and infectious periods and the average age of first infection); this relation agrees with the data for a variety of childhood diseases. Criteria for the eradication of a disease are given, in terms of the proportion of the population to be vaccinated and the age-specific vaccination schedule. These criteria are compared with a detailed analysis of the vaccination programs against measles and whooping cough in Britain, and estimates are made of the levels of protection that would be needed to eradicate these diseases.},
	journal = {Science},
	author = {Anderson, Roy M. and May, Robert M.},
	year = {1982},
}

@article{fraser_factors_2004,
	title = {Factors that make an infectious disease outbreak controllable},
	doi = {10.1073/pnas.0307506101},
	abstract = {The aim of this study is to identify general properties of emerging infectious agents that determine the likely success of two simple public health measures in controlling outbreaks, namely (i) isolating symptomatic individuals and (ii) tracing and quarantining their contacts. Because these measures depend on the recognition of specific disease symptoms, we investigate the relative timing of infectiousness and the appearance of symptoms by using a mathematical model. We show that the success of these control measures is determined as much by the proportion of transmission occurring prior to the onset of overt clinical symptoms (or via asymptomatic infection) as the inherent transmissibility of the etiological agent (measured by the reproductive number R0). From published studies, we estimate these quantities for two moderately transmissible viruses, severe acute respiratory syndrome coronavirus and HIV, and for two highly transmissible viruses, smallpox and pandemic influenza. We conclude that severe acute respiratory syndrome and smallpox are easier to control using these simple public health measures. Direct estimation of the proportion of asymptomatic and presymptomatic infections is achievable by contact tracing and should be a priority during an outbreak of a novel infectious agent.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Fraser, Christophe and Riley, Steven and Anderson, Roy M. and Ferguson, Neil M.},
	year = {2004},
	keywords = {Epidemiology, Influenza, Severe acute respiratory syndrome, HIV, Smallpox},
}

@article{ferguson_strategies_2006,
	title = {Strategies for mitigating an influenza pandemic},
	doi = {10.1038/nature04795},
	abstract = {Development of strategies for mitigating the severity of a new influenza pandemic is now a top global public health priority. Influenza prevention and containment strategies can be considered under the broad categories of antiviral, vaccine and non-pharmaceutical (case isolation, household quarantine, school or workplace closure, restrictions on travel) measures. Mathematical models are powerful tools for exploring this complex landscape of intervention strategies and quantifying the potential costs and benefits of different options. Here we use a large-scale epidemic simulation to examine intervention options should initial containment of a novel influenza outbreak fail, using Great Britain and the United States as examples. We find that border restrictions and/or internal travel restrictions are unlikely to delay spread by more than 2-3 weeks unless more than 99\% effective. School closure during the peak of a pandemic can reduce peak attack rates by up to 40\%, but has little impact on overall attack rates, whereas case isolation or household quarantine could have a significant impact, if feasible. Treatment of clinical cases can reduce transmission, but only if antivirals are given within a day of symptoms starting. Given enough drugs for 50\% of the population, household-based prophylaxis coupled with reactive school closure could reduce clinical attack rates by 40-50\%. More widespread prophylaxis would be even more logistically challenging but might reduce attack rates by over 75\%. Vaccine stockpiled in advance of a pandemic could significantly reduce attack rates even if of low efficacy. Estimates of policy effectiveness will change if the characteristics of a future pandemic strain differ substantially from those seen in past pandemics. © 2006 Nature Publishing Group.},
	journal = {Nature},
	author = {Ferguson, Neil M. and Cummings, Derek A.T. and Fraser, Christophe and Cajka, James C. and Cooley, Philip C. and Burke, Donald S.},
	year = {2006},
}

@article{bellman_theory_1948,
	title = {On the {Theory} of {Age}-{Dependent} {Stochastic} {Branching} {Processes}},
	doi = {10.1073/pnas.34.12.601},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bellman, R. and Harris, T. E.},
	year = {1948},
}

@article{bellman_age-dependent_1952,
	title = {On {Age}-{Dependent} {Binary} {Branching} {Processes}},
	doi = {10.2307/1969779},
	journal = {The Annals of Mathematics},
	author = {Bellman, Richard and Harris, Theodore},
	year = {1952},
}

@article{cauchemez_estimating_2008,
	title = {Estimating the impact of school closure on influenza transmission from {Sentinel} data},
	doi = {10.1038/nature06732},
	abstract = {The threat posed by the highly pathogenic H5N1 influenza virus requires public health authorities to prepare for a human pandemic. Although pre-pandemic vaccines and antiviral drugs might significantly reduce illness rates, their stockpiling is too expensive to be practical for many countries. Consequently, alternative control strategies, based on non-pharmaceutical interventions, are a potentially attractive policy option. School closure is the measure most often considered. The high social and economic costs of closing schools for months make it an expensive and therefore controversial policy, and the current absence of quantitative data on the role of schools during influenza epidemics means there is little consensus on the probable effectiveness of school closure in reducing the impact of a pandemic. Here, from the joint analysis of surveillance data and holiday timing in France, we quantify the role of schools in influenza epidemics and predict the effect of school closure during a pandemic. We show that holidays lead to a 20-29\% reduction in the rate at which influenza is transmitted to children, but that they have no detectable effect on the contact patterns of adults. Holidays prevent 16-18\% of seasonal influenza cases (18-21\% in children). By extrapolation, we find that prolonged school closure during a pandemic might reduce the cumulative number of cases by 13-17\% (18-23\% in children) and peak attack rates by up to 39-45\% (47-52\% in children). The impact of school closure would be reduced if it proved difficult to maintain low contact rates among children for a prolonged period. ©2008 Nature Publishing Group.},
	journal = {Nature},
	author = {Cauchemez, Simon and Valleron, Alain Jacques and Boëlle, Pierre Yves and Flahault, Antoine and Ferguson, Neil M.},
	year = {2008},
}

@article{fraser_estimating_2007,
	title = {Estimating individual and household reproduction numbers in an emerging epidemic},
	doi = {10.1371/journal.pone.0000758},
	abstract = {Reproduction numbers, defined as averages of the number of people infected by a typical case, play a central role in tracking infectious disease outbreaks. The aim of this paper is to develop methods for estimating reproduction numbers which are simple enough that they could be applied with limited data or in real time during an outbreak. I present a new estimator for the individual reproduction number, which describes the state of the epidemic at a point in time rather than tracking individuals over time, and discuss some potential benefits. Then, to capture more of the detail that micro-simulations have shown is important in outbreak dynamics, I analyse a model of transmission within and between households, and develop a method to estimate the household reproduction number, defined as the number of households infected by each infected household. This method is validated by numerical simulations of the spread of influenza and measles using historical data, and estimates are obtained for would-be emerging epidemics of these viruses. I argue that the household reproduction number is useful in assessing the impact of measures that target the household for isolation, quarantine, vaccination or prophylactic treatment, and measures such as social distancing and school or workplace closures which limit between-household transmission, all of which play a key role in current thinking on future infectious disease mitigation. © 2007 Christophe Fraser.},
	journal = {PLoS ONE},
	author = {Fraser, Christophe},
	year = {2007},
}

@article{nouvellet_simple_2018,
	title = {A simple approach to measure transmissibility and forecast incidence},
	doi = {10.1016/j.epidem.2017.02.012},
	abstract = {Outbreaks of novel pathogens such as SARS, pandemic influenza and Ebola require substantial investments in reactive interventions, with consequent implementation plans sometimes revised on a weekly basis. Therefore, short-term forecasts of incidence are often of high priority. In light of the recent Ebola epidemic in West Africa, a forecasting exercise was convened by a network of infectious disease modellers. The challenge was to forecast unseen “future” simulated data for four different scenarios at five different time points. In a similar method to that used during the recent Ebola epidemic, we estimated current levels of transmissibility, over variable time-windows chosen in an ad hoc way. Current estimated transmissibility was then used to forecast near-future incidence. We performed well within the challenge and often produced accurate forecasts. A retrospective analysis showed that our subjective method for deciding on the window of time with which to estimate transmissibility often resulted in the optimal choice. However, when near-future trends deviated substantially from exponential patterns, the accuracy of our forecasts was reduced. This exercise highlights the urgent need for infectious disease modellers to develop more robust descriptions of processes – other than the widespread depletion of susceptible individuals – that produce non-exponential patterns of incidence.},
	journal = {Epidemics},
	author = {Nouvellet, Pierre and Cori, Anne and Garske, Tini and Blake, Isobel M. and Dorigatti, Ilaria and Hinsley, Wes and Jombart, Thibaut and Mills, Harriet L. and Nedjati-Gilani, Gemma and Van Kerkhove, Maria D. and Fraser, Christophe and Donnelly, Christl A. and Ferguson, Neil M. and Riley, Steven},
	year = {2018},
	keywords = {Forecasting, Renewal equation, Branching process, MCMC, Rapid response},
}

@article{cori_new_2013,
	title = {A new framework and software to estimate time-varying reproduction numbers during epidemics},
	doi = {10.1093/aje/kwt133},
	abstract = {The quantification of transmissibility during epidemics is essential to designing and adjusting public health responses. Transmissibility can be measured by the reproduction number R, the average number of secondary cases caused by an infected individual. Several methods have been proposed to estimate R over the course of an epidemic; however, they are usually difficult to implement for people without a strong background in statistical modeling. Here, we present a ready-to-use tool for estimating R from incidence time series, which is implemented in popular software including Microsoft Excel (Microsoft Corporation, Redmond, Washington). This tool produces novel, statistically robust analytical estimates of R and incorporates uncertainty in the distribution of the serial interval (the time between the onset of symptoms in a primary case and the onset of symptoms in secondary cases). We applied the method to 5 historical outbreaks; the resulting estimates of R are consistent with those presented in the literature. This tool should help epidemiologists quantify temporal changes in the transmission intensity of future epidemics by using surveillance data. © The Author 2013.},
	journal = {American Journal of Epidemiology},
	author = {Cori, Anne and Ferguson, Neil M. and Fraser, Christophe and Cauchemez, Simon},
	year = {2013},
	keywords = {Influenza, Smallpox, Incidence, Measles, Reproduction number, SARS, Software},
}

@article{jombart_inferring_2020,
	title = {Inferring the number of {COVID}-19 cases from recently reported deaths},
	doi = {10.12688/wellcomeopenres.15786.1},
	abstract = {We estimate the number of COVID-19 cases from newly reported deaths in a population without previous reports. Our results suggest that by the time a single death occurs, hundreds to thousands of cases are likely to be present in that population. This suggests containment via contact tracing will be challenging at this point, and other response strategies should be considered. Our approach is implemented in a publicly available, user-friendly, online tool.},
	journal = {Wellcome Open Research},
	author = {Jombart, Thibaut and van Zandvoort, Kevin and Russell, Timothy W. and Jarvis, Christopher I. and Gimma, Amy and Abbott, Sam and Clifford, Sam and Funk, Sebastian and Gibbs, Hamish and Liu, Yang and Pearson, Carl A.B. and Bosse, Nikos I. and Eggo, Rosalind M. and Kucharski, Adam J. and Edmunds, W. John},
	year = {2020},
	keywords = {Epidemics, Outbreak, Estimation, Statistics, Covid-19, Modelling, SARS-CoV-2},
}

@article{zhao_antibody_2020,
	title = {Antibody responses to {SARS}-{CoV}-2 in patients of novel coronavirus disease 2019},
	doi = {10.1093/cid/ciaa344},
	abstract = {BACKGROUND: The novel coronavirus SARS-CoV-2 is a newly emerging virus. The antibody response in infected patient remains largely unknown, and the clinical values of antibody testing have not been fully demonstrated. METHODS: A total of 173 patients with SARS-CoV-2 infection were enrolled. Their serial plasma samples (n=535) collected during the hospitalization were tested for total antibodies (Ab), IgM and IgG against SARS-CoV-2. The dynamics of antibodies with the disease progress was analyzed. RESULTS: Among 173 patients, the seroconversion rate for Ab, IgM and IgG was 93.1\%, 82.7\% and 64.7\%, respectively. The reason for the negative antibody findings in 12 patients might due to the lack of blood samples at the later stage of illness. The median seroconversion time for Ab, IgM and then IgG were day-11, day-12 and day-14, separately. The presence of antibodies was {\textless}40\% among patients within 1-week since onset, and rapidly increased to 100.0\% (Ab), 94.3\% (IgM) and 79.8\% (IgG) since day-15 after onset. In contrast, RNA detectability decreased from 66.7\% (58/87) in samples collected before day-7 to 45.5\% (25/55) during day 15-39. Combining RNA and antibody detections significantly improved the sensitivity of pathogenic diagnosis for COVID-19 (p{\textless}0.001), even in early phase of 1-week since onset (p=0.007). Moreover, a higher titer of Ab was independently associated with a worse clinical classification (p=0.006). CONCLUSIONS: The antibody detection offers vital clinical information during the course of SARS-CoV-2 infection. The findings provide strong empirical support for the routine application of serological testing in the diagnosis and management of COVID-19 patients.},
	journal = {Clinical infectious diseases : an official publication of the Infectious Diseases Society of America},
	author = {Zhao, Juanjuan and Yuan, Quan and Wang, Haiyan and Liu, Wei and Liao, Xuejiao and Su, Yingying and Wang, Xin and Yuan, Jing and Li, Tingdong and Li, Jinxiu and Qian, Shen and Hong, Congming and Wang, Fuxiang and Liu, Yingxia and Wang, Zhaoqin and He, Qing and Li, Zhiyong and He, Bin and Zhang, Tianying and Fu, Yang and Ge, Shengxiang and Liu, Lei and Zhang, Jun and Xia, Ningshao and Zhang, Zheng},
	year = {2020},
	keywords = {SARS-CoV-2, antibody, COVID-19},
}

@article{zhang_patterns_2019,
	title = {Patterns of human social contact and contact with animals in {Shanghai}, {China}},
	doi = {10.1038/s41598-019-51609-8},
	abstract = {East Asia is as a principal hotspot for emerging zoonotic infections. Understanding the likely pathways for their emergence and spread requires knowledge on human-human and human-animal contacts, but such studies are rare. We used self-completed and interviewer-completed contact diaries to quantify patterns of these contacts for 965 individuals in 2017/2018 in a high-income densely-populated area of China, Shanghai City. Interviewer-completed diaries recorded more social contacts (19.3 vs. 18.0) and longer social contact duration (35.0 vs. 29.1 hours) than self-reporting. Strong age-assortativity was observed in all age groups especially among young participants (aged 7–20) and middle aged participants (25–55 years). 17.7\% of participants reported touching animals (15.3\% (pets), 0.0\% (poultry) and 0.1\% (livestock)). Human-human contact was very frequent but contact with animals (especially poultry) was rare although associated with frequent human-human contact. Hence, this densely populated area is more likely to act as an accelerator for human-human spread but less likely to be at the source of a zoonosis outbreak. We also propose that telephone interview at the end of reporting day is a potential improvement of the design of future contact surveys.},
	journal = {Scientific Reports},
	author = {Zhang, Juanjuan and Klepac, Petra and Read, Jonathan M. and Rosello, Alicia and Wang, Xiling and Lai, Shengjie and Li, Meng and Song, Yujian and Wei, Qingzhen and Jiang, Hao and Yang, Juan and Lynn, Henry and Flasche, Stefan and Jit, Mark and Yu, Hongjie},
	year = {2019},
}

@article{li_substantial_2020,
	title = {Substantial undocumented infection facilitates the rapid dissemination of novel coronavirus ({SARS}-{CoV}-2)},
	doi = {10.1126/science.abb3221},
	abstract = {Estimation of the prevalence and contagiousness of undocumented novel coronavirus [severe acute respiratory syndrome–coronavirus 2 (SARS-CoV-2)] infections is critical for understanding the overall prevalence and pandemic potential of this disease. Here, we use observations of reported infection within China, in conjunction with mobility data, a networked dynamic metapopulation model, and Bayesian inference, to infer critical epidemiological characteristics associated with SARS-CoV-2, including the fraction of undocumented infections and their contagiousness. We estimate that 86\% of all infections were undocumented [95\% credible interval (CI): 82–90\%] before the 23 January 2020 travel restrictions. The transmission rate of undocumented infections per person was 55\% the transmission rate of documented infections (95\% CI: 46–62\%), yet, because of their greater numbers, undocumented infections were the source of 79\% of the documented cases. These findings explain the rapid geographic spread of SARS-CoV-2 and indicate that containment of this virus will be particularly challenging.},
	journal = {Science},
	author = {Li, Ruiyun and Pei, Sen and Chen, Bin and Song, Yimeng and Zhang, Tao and Yang, Wan and Shaman, Jeffrey},
	year = {2020},
}

@article{flaxman_estimating_2020,
	title = {Estimating the effects of non-pharmaceutical interventions on {COVID}-19 in {Europe}},
	url = {https://doi.org/10.1038/s41586-020-2405-7},
	doi = {10.1038/s41586-020-2405-7},
	abstract = {Following the emergence of a novel coronavirus1 (SARS-CoV-2) and its spread outside of China, Europe has experienced large epidemics. In response, many European countries have implemented unprecedented non-pharmaceutical interventions such as closure of schools and national lockdowns. We study the impact of major interventions across 11 European countries for the period from the start of COVID-19 until the 4th of May 2020 when lockdowns started to be lifted. Our model calculates backwards from observed deaths to estimate transmission that occurred several weeks prior, allowing for the time lag between infection and death. We use partial pooling of information between countries with both individual and shared effects on the reproduction number. Pooling allows more information to be used, helps overcome data idiosyncrasies, and enables more timely estimates. Our model relies on fixed estimates of some epidemiological parameters such as the infection fatality rate, does not include importation or subnational variation and assumes that changes in the reproduction number are an immediate response to interventions rather than gradual changes in behavior. Amidst the ongoing pandemic, we rely on death data that is incomplete, with systematic biases in reporting, and subject to future consolidation. We estimate that, for all the countries we consider, current interventions have been sufficient to drive the reproduction number \$\$\{R\}\_\{t\}\$\$Rt below 1 (probability \$\$\{R\}\_\{t\}{\textbackslash},\$\$Rt{\textless} 1.0 is 99.9\%) and achieve epidemic control. We estimate that, across all 11 countries, between 12 and 15 million individuals have been infected with SARS-CoV-2 up to 4th May, representing between 3.2\% and 4.0\% of the population. Our results show that major non-pharmaceutical interventions and lockdown in particular have had a large effect on reducing transmission. Continued intervention should be considered to keep transmission of SARS-CoV-2 under control.},
	journal = {Nature},
	author = {Flaxman, Seth and Mishra, Swapnil and Gandy, Axel and Unwin, H Juliette T and Mellan, Thomas A and Coupland, Helen and Whittaker, Charles and Zhu, Harrison and Berah, Tresnia and Eaton, Jeffrey W and Monod, Mélodie and Perez-Guzman, Pablo N and Schmit, Nora and Cilloni, Lucia and Ainslie, Kylie E C and Baguelin, Marc and Boonyasiri, Adhiratha and Boyd, Olivia and Cattarino, Lorenzo and Cooper, Laura V and Cucunubá, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Djaafara, Bimandra and Dorigatti, Ilaria and van Elsland, Sabine L and FitzJohn, Richard G and Gaythorpe, Katy A M and Geidelberg, Lily and Grassly, Nicholas C and Green, William D and Hallett, Timothy and Hamlet, Arran and Hinsley, Wes and Jeffrey, Ben and Knock, Edward and Laydon, Daniel J and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Parag, Kris V and Siveroni, Igor and Thompson, Hayley A and Verity, Robert and Volz, Erik and Walters, Caroline E and Wang, Haowei and Wang, Yuanrong and Watson, Oliver J and Winskill, Peter and Xi, Xiaoyue and Walker, Patrick G T and Ghani, Azra C and Donnelly, Christl A and Riley, Steven M and Vollmer, Michaela A C and Ferguson, Neil M and Okell, Lucy C and Bhatt, Samir and Team, Imperial College COVID-19 Response},
	year = {2020},
}

@book{meyn_markov_2009,
	edition = {2},
	series = {Cambridge {Mathematical} {Library}},
	title = {Markov {Chains} and {Stochastic} {Stability}},
	publisher = {Cambridge University Press},
	author = {Meyn, Sean and Tweedie, Richard L and Glynn, Peter W},
	year = {2009},
	doi = {10.1017/CBO9780511626630},
}

@article{gandy_compound_2019,
	title = {Compound {Poisson} {Models} for {Financial} {Networks}},
	doi = {10.2139/ssrn.3401059},
	journal = {SSRN Electronic Journal},
	author = {Gandy, Axel and Veraart, Luitgard A. M.},
	month = jun,
	year = {2019},
	note = {Publisher: Elsevier BV},
}

@article{anderson_distribution_1962,
	title = {On the {Distribution} of the {Two}-{Sample} {Cramer}-von {Mises} {Criterion}},
	doi = {10.1214/aoms/1177704477},
	abstract = {An s stage k name snowball sampling procedure is defined as follows: A random sample of individuals is drawn from a given finite population. (The kind of random sample will be discussed later in this section.) Each individual in the sample is asked to name k different individuals in the population, where k is a specified integer; for example, each individual may be asked to name his "k best friends," or the "k individuals with whom he most frequently associates," or the "k individuals whose opinions he most frequently seeks," etc. (For the sake of simplicity, we assume throughout that an individual cannot include himself in his list of k individuals.) The individuals who were not in the random sample but were named by individuals in it form the first stage. Each of the individuals in the first stage is then asked to name k different individuals. (We assume that the question asked of the individuals in the random sample and of those in each stage is the same and that k is the same.) The individuals who were not in the random sample nor in the first stage but were named by individuals who were in the first stage form the second stage. Each of the individuals in the second stage is then asked to name k different individuals. The individuals who were not in the random sample nor in the first or second stages but were named by individuals who were in the second stage form the third stage. Each of the individuals in the third stage is then asked to name k different individuals. This procedure is continued until each of the individuals in the sth stage has been asked to name k different individuals. The data obtained using an s stage k name snowball sampling procedure can be utilized to make statistical inferences about various aspects of the relationships present in the population. The relationships present, in the hypothetical situation where each individual in the population is asked to name k different individuals, can be described by a matrix with rows and columns corresponding to the members of the population, rows for the individuals naming and columns for the individuals named, where the entry thetaij in the ith row and jth column is 1 if the ith individual in the population includes the jth individual among the k individuals he would name, and it is 0 otherwise. While the matrix of the theta's cannot be known in general unless every individual in the population is interviewed (i.e., asked to name k different individuals), it will be possible to make statistical inferences about various aspects of this matrix from the data obtained using an s stage k name snowball sampling procedure. For example, when s = k = 1, the number, M11, of mutual relationships present in the population (i.e., the number of values i with thetaij = thetaji = 1 for some value of j {\textgreater} i) can be estimated. The methods of statistical inference applied to the data obtained from an s stage k name snowball sample will of course depend on the kind of random sample drawn as the initial step. In most of the present paper, we shall suppose that a random sample (i.e., the "zero stage" in snowball sample) is drawn so that the probability, p, that a given individual in the population will be in the sample is independent of whether a different given individual has appeared. This kind of sampling has been called binomial sampling; the specified value of p (assumed known) has been called the sampling fraction 4. This sampling scheme might also be described by saying that a given individual is included in the sample just when a coin, which has a probability p of "heads," comes up "heads," where the tosses of the coin from individual to individual are independent. (To each individual there corresponds an independent Bernoulli trial determining whether he will or will not be included in the sample.) This sampling scheme differs in some respects from the more usual models where the sample size is fixed in advance or where the ratio of the sample size to the population size (i.e., the sample size-population size ratio) is fixed. For binomial sampling, this ratio is a random variable whose expected value is p. (The variance of this ratio approaches zero as the population becomes infinite.) In some situations (where, for example, the variance of this ratio is near zero), mathematical results obtained for binomial sampling are sometimes quite similar to results obtained using some of the more usual sampling models (see 4, 7; compare the variance formulas in 3 and 5); in such cases it will often not make much difference, from a practical point of view, which sampling model is utilized. (In Section 6 of the present paper some results for snowball sampling based on an initial sample of the more usual kind are obtained and compared with results presented in the earlier sections of this paper obtained for snowball sampling based on an initial binomial sample.) For snowball sampling based on an initial binomial sample, and with s = k = 1, so that each individual asked names just one other individual and there is just one stage beyond the initial sample, Section 2 of this paper discusses unbiased estimation of M11, the number of pairs of individuals in the population who would name each other. One of the unbiased estimators considered (among a certain specified class of estimators) has uniformly smallest variance when the population characteristics are unknown; this one is based on a sufficient statistic for a simplified summary of the data and is the only unbiased estimator of M11 based on that sufficient statistic (when the population characteristics are unknown). This estimator (when s = k = 1) has a smaller variance than a comparable minimum variance unbiased estimator computed from a larger random sample when s = 0 and k = 1 (i.e., where only the individuals in the random sample are interviewed) even where the expected number of individuals in the larger random sample (s = 0, k = 1) is equal to the maximum expected number of individuals studied when s = k = 1 (i.e., the sum of the expected number of individuals in the initial sample and the maximum expected number of individuals in the first stage). In fact, the variance of the estimator when s = 0 and k = 1 is at least twice as large as the variance of the comparable estimator when s = k = 1 even where the expected number of individuals studied when s = 0 and k = 1 is as large as the maximum expected number of individuals studied when s = k = 1. Thus, for estimating M11, the sampling scheme with s = k = 1 is preferable to the sampling scheme with s = 0 and k = 1. Furthermore, we observe that when s = k = 1 the unbiased estimator based on the simplified summary of the data having minimum variance when the population characteristics are unknown can be improved upon in cases where certain population characteristics are known, or where additional data not included in the simplified summary are available. Several improved estimators are derived and discussed. Some of the results for the special case of s = k = 1 are generalized in Sections 3 and 4 to deal with cases where s and k are any specified positive integers. In Section 5, results are presented about s stage k name snowball sampling procedures, where each individual asked to name k different individuals chooses k individuals at random from the population. (Except in Section 5, the numbers thetaij, which form the matrix referred to earlier, are assumed to be fixed (i.e., to be population parameters); in Section 5, they are random variables. A variable response error is not considered except in so far as Section 5 deals with an extreme case of this.) For social science literature that discusses problems related to snowball sampling, see 2, 8, and the articles they cite. This literature indicates, among other things, the importance of studying "social structure and...the relations among individuals" 2.},
	journal = {The Annals of Mathematical Statistics},
	author = {Anderson, T. W.},
	year = {1962},
}

@article{cowles_markov_1996,
	title = {Markov {Chain} {Monte} {Carlo} {Convergence} {Diagnostics}: {A} {Comparative} {Review}},
	volume = {91},
	url = {https://www.tandfonline.com/action/journalInformation?journalCode=uasa20},
	doi = {10.1080/01621459.1996.10476956},
	journal = {Journal of the American Statistical Association},
	author = {Cowles, Mary Kathryn and Carlin, Bradley P},
	year = {1996},
	pages = {883--904},
	file = {Cowles, Carlin - 1996 - Markov Chain Monte Carlo Convergence Diagnostics A Comparative Review:/Users/jamesscott/Zotero/storage/86VG4QJY/Cowles, Carlin - 1996 - Markov Chain Monte Carlo Convergence Diagnostics A Comparative Review.pdf:application/pdf},
}

@incollection{sokal_monte_1997,
	title = {Monte {Carlo} {Methods} in {Statistical} {Mechanics}: {Foundations} and {New} {Algorithms}},
	abstract = {Abstract These notes are an updated version of lectures given at the Cours de Troisième Cycle de la Physique en Suisse Romande (Lausanne, Switzerland) in June 1989. We thank the Troisième Cycle de la Physique en Suisse Romande and Professor Michel Droz for ...},
	author = {Sokal, A.},
	year = {1997},
	doi = {10.1007/978-1-4899-0319-8_6},
}

@article{gelman_correction_2017,
	title = {Correction to: {Validation} of {Software} for {Bayesian} {Models} using {Posterior} {Quantiles}},
	volume = {26},
	doi = {10.1080/10618600.2017.1377082},
	abstract = {We thank Sean Talts and Michael Betancourt for sharing an example that made us realize the incorrectness of the following statement in Cook, Gelman, and Rubin 2006):Let, the empirical quantile for the ith replication. For any generic function h, we can determine the distribution of h(q) for correctly working software. In particular, if the software works properly and therefore the posterior quantiles are uniformly distributed, then h(q) = Φ− 1(q) should have a standard normal distribution, where Φ represents the standard normal CDF.The above claim is false, for two reasons. First, the relevant reference distribution is discrete uniform, not continuous uniform, so the normal CDF is at best just an approximation. Second, with Markov chain simulation, the draws θ(ℓ) are dependent, so for any finite L, the distribution of qi will not even be discrete uniform. The error wasn't noticed in the original paper because the method happened to work out on the examples. In general, however, any claim of the statistical properties of any statement about the distribution of draws from iterative simulation should account for the dependence of these simulation draws.},
	number = {4},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gelman, Andrew},
	month = oct,
	year = {2017},
	note = {Publisher: American Statistical Association},
	pages = {940--940},
	file = {Gelman - 2017 - Correction to Validation of Software for Bayesian Models using Posterior Quantiles:/Users/jamesscott/Zotero/storage/BULL6ADM/Gelman - 2017 - Correction to Validation of Software for Bayesian Models using Posterior Quantiles.pdf:application/pdf},
}

@article{geman_stochastic_1984,
	title = {Stochastic {Relaxation}, {Gibbs} {Distributions}, and the {Bayesian} {Restoration} of {Images}},
	doi = {10.1109/TPAMI.1984.4767596},
	abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (“annealing”) or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel “relaxation” algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios. © 1984, IEEE.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Geman, Stuart and Geman, Donald},
	year = {1984},
	keywords = {Annealing, Gibbs distribution, image restoration, line process, MAP estimate, Markov random field, relaxation scene modeling, spatial degradation},
}

@article{duane_hybrid_1987,
	title = {Hybrid {Monte} {Carlo}},
	doi = {10.1016/0370-2693(87)91197-X},
	abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons. © 1987.},
	journal = {Physics Letters B},
	author = {Duane, Simon and Kennedy, A. D. and Pendleton, Brian J. and Roweth, Duncan},
	year = {1987},
}

@article{roberts_langevin_2002,
	title = {Langevin diffusions and {Metropolis}-{Hastings} algorithms},
	abstract = {We consider a class of Langevin diffusions with state-dependent volatility. The volatility of the diffusion is chosen so as to make the stationary distribution of the diffusion with respect to its natural clock, a heated version of the stationary density of interest. The motivation behind this construction is the desire to construct uniformly ergodic diffusions with required stationary densities. Discrete time algorithms constructed by Hastings accept reject mechanisms are constructed from discretisations of the algorithms, and the properties of these algorithms are investigated.},
	journal = {Methodology And Computing In Applied Probability},
	author = {Roberts, GO and Stramer, O},
	year = {2002},
	keywords = {65c40, ams 2000 subject classification, langevin diffusions and algorithms, mcmc},
}

@article{girolami_riemann_2011,
	title = {Riemann manifold {Langevin} and {Hamiltonian} {Monte} {Carlo} methods},
	doi = {10.1111/j.1467-9868.2010.00765.x},
	abstract = {The paper proposes Metropolis adjusted Langevin and Hamiltonian Monte Carlo sampling methods defined on the Riemann manifold to resolve the shortcomings of existing Monte Carlo algorithms when sampling from target densities that may be high dimensional and exhibit strong correlations. The methods provide fully automated adaptation mechanisms that circumvent the costly pilot runs that are required to tune proposal densities for Metropolis-Hastings or indeed Hamiltonian Monte Carlo and Metropolis adjusted Langevin algorithms. This allows for highly efficient sampling even in very high dimensions where different scalings may be required for the transient and stationary phases of the Markov chain. The methodology proposed exploits the Riemann geometry of the parameter space of statistical models and thus automatically adapts to the local structure when simulating paths across this manifold, providing highly efficient convergence and exploration of the target density. The performance of these Riemann manifold Monte Carlo methods is rigorously assessed by performing inference on logistic regression models, log-Gaussian Cox point processes, stochastic volatility models and Bayesian estimation of dynamic systems described by non-linear differential equations. Substantial improvements in the time-normalized effective sample size are reported when compared with alternative sampling approaches. MATLAB code that is available from allows replication of all the results reported. © 2011 Royal Statistical Society.},
	journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
	author = {Girolami, Mark and Calderhead, Ben},
	year = {2011},
	keywords = {Bayesian inference, Geometry in statistics, Hamiltonian Monte Carlo methods, Langevin diffusion, Markov chain Monte Carlo methods, Riemann manifolds},
}

@article{cook_validation_2006,
	title = {Validation of software for {Bayesian} models using posterior quantiles},
	doi = {10.1198/106186006X136976},
	abstract = {This article presents a simulation-based method designed to establish the computational correctness of software developed to fit a specific Bayesian model, capitalizing on properties of Bayesian posterior distributions. We illustrate the validation technique with two examples. The validation method is shown to find errors in software when they exist and, moreover, the validation output can be informative about the nature and location of such errors. We also compare our method with that of an earlier approach. © 2006 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cook, Samantha R. and Gelman, Andrew and Rubin, Donald B.},
	year = {2006},
	keywords = {Gibbs sampler, Hierarchical models, Markov chain Monte Carlo, Posterior distribution},
}

@article{geweke_getting_2004,
	title = {Getting it right: {Joint} distribution tests of posterior simulators},
	doi = {10.1198/016214504000001132},
	abstract = {Analytical or coding, errors in posterior simulators can produce reasonable but incorrect approximations of posterior moments. This article develops simple tests of posterior simulators that detect both kinds of errors, and uses them to detect and correct errors in two previously published articles. The tests exploit the fact that a Bayesian model specifies the joint distribution of observables (data) and unobservables (parameters). There are two joint distribution simulators. The marginal-conditional simulator draws unobservables from the prior and then observables conditional on unobservables. The successive-conditional simulator alternates between the posterior simulator and an observables simulator. Formal comparison of moment approximations of the two simulators reveals existing analytical or coding errors in the posterior simulator.},
	journal = {Journal of the American Statistical Association},
	author = {Geweke, John},
	year = {2004},
	keywords = {Software, Markov chain Monte Carlo, Bayesian},
}

@article{talts_validating_2018,
	title = {Validating {Bayesian} {Inference} {Algorithms} with {Simulation}-{Based} {Calibration}},
	url = {http://arxiv.org/abs/1804.06788},
	abstract = {Verifying the correctness of Bayesian computation is challenging. This is especially true for complex models that are common in practice, as these require sophisticated model implementations and algorithms. In this paper we introduce {\textbackslash}emph\{simulation-based calibration\} (SBC), a general procedure for validating inferences from Bayesian algorithms capable of generating posterior samples. This procedure not only identifies inaccurate computation and inconsistencies in model implementations but also provides graphical summaries that can indicate the nature of the problems that arise. We argue that SBC is a critical part of a robust Bayesian workflow, as well as being a useful tool for those developing computational algorithms and statistical software.},
	author = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
	month = apr,
	year = {2018},
	file = {Talts et al. - 2018 - Validating Bayesian Inference Algorithms with Simulation-Based Calibration:/Users/jamesscott/Zotero/storage/54ABHBEU/Talts et al. - 2018 - Validating Bayesian Inference Algorithms with Simulation-Based Calibration.pdf:application/pdf},
}

@article{gandy_bayesian_2017,
	title = {A \{{B}\}ayesian {Methodology} for {Systemic} {Risk} {Assessment} in {Financial} {Networks}},
	volume = {63},
	doi = {10.1287/mnsc.2016.2546},
	number = {12},
	journal = {Management Science},
	author = {Gandy, Axel and Veraart, Luitgard A M},
	year = {2017},
	pages = {4428--4446},
}

@article{smirnov_table_1948,
	title = {Table for {Estimating} the {Goodness} of {Fit} of {Empirical} {Distributions}},
	volume = {19},
	url = {https://doi.org/10.1214/aoms/1177730256},
	doi = {10.1214/aoms/1177730256},
	number = {2},
	journal = {Ann. Math. Statist.},
	author = {Smirnov, N},
	year = {1948},
	note = {Publisher: The Institute of Mathematical Statistics},
	pages = {279--281},
}

@article{eddelbuettel_rcpp_2011,
	title = {Rcpp: {Seamless} {R} and {C}++ integration},
	doi = {10.18637/jss.v040.i08},
	abstract = {The Rcpp package simplies integrating C++ code with R. It provides a consistent C++ class hierarchy that maps various types of R objects (vectors, matrices, functions, environments,.) to dedicated C++ classes. Object interchange between R and C++ is managed by simple, exible and extensible concepts which include broad support for C++ Standard Template Library idioms. C++ code can both be compiled, linked and loaded on the y, or added via packages. Flexible error and exception code handling is provided. Rcpp substantially lowers the barrier for programmers wanting to combine C++ code with R.},
	journal = {Journal of Statistical Software},
	author = {Eddelbuettel, Dirk and François, Romain},
	year = {2011},
	keywords = {Call, Foreign function interface, R},
}

@article{csardi_igraph_2006,
	title = {The igraph software package for complex network research},
	abstract = {The igraph software package provides handy tools for researchers in network science. It is an open source portable library capable of handling huge graphs with millions of vertices and edges and it is also suitable to grid computing. It contains routines for creating, manipulating and visualizing networks, calculating various structural properties, importing from and exporting to various file formats and many more. Via its interfaces to high-level languages like GNU R and Python it supports rapid development and fast prototyping.},
	journal = {InterJournal Complex Systems},
	author = {Csardi, Gabor and Nepusz, Tamas},
	year = {2006},
}

@article{kahle_latte_2017,
	title = {latte: \{{LattE}\} and \{4ti2\} in \{{R}\}},
	url = {https://github.com/dkahle/latte},
	author = {Kahle, David and Garcia-Puente, Luis and Yoshida, Ruriko},
	year = {2017},
	note = {Publisher: R package version 0.2.0},
	annote = {R package version 0.2.0},
}

@article{kahle_algstat_2017,
	title = {algstat: {Algebraic} {Statistics} in \{{R}\}},
	url = {https://github.com/dkahle/algstat},
	author = {Kahle, David and Garcia-Puente, Luis and Yoshida, Ruriko},
	year = {2017},
	annote = {R package version 0.1.1},
}

@article{wickham_stringr_2019,
	title = {stringr: {Simple}, {Consistent} {Wrappers} for {Common} {String} {Operations}},
	url = {https://cran.r-project.org/package=stringr},
	author = {Wickham, Hadley},
	year = {2019},
	annote = {R package version 1.4.0},
}

@article{galeano_weighted-interaction_2009,
	title = {Weighted-{Interaction} {Nestedness} {Estimator} ({WINE}): {A} {New} {Estimator} to {Calculate} over {Frequency} {Matrices}},
	volume = {24},
	doi = {10.1016/j.envsoft.2009.05.014},
	abstract = {We propose a new nestedness estimator that takes into account the weight of the interactions, that is, it runs over frequency matrices. A nestedness measurement is calculated through the average distance from each matrix cell containing a link to the cell with the lowest marginal totals, in the packed matrix, using a weighted Manhattan distance. The significance of this nestedness measure is tested against a null model that constraints matrix fill to observed values and retains the distribution of number of events. This is the first methodological approach that allows for the characterization of weighted nestedness. We have developed a graphical user interface (GUI) running in Matlab to compute all these parameters. The software is also available as a script for R-package and in C++ version. © 2009 Elsevier Ltd. All rights reserved.},
	number = {11},
	journal = {Environmental Modelling and Software},
	author = {Galeano, Javier and Pastor, Juan M. and Iriondo, Jose M.},
	year = {2009},
	keywords = {Ecological complex network, Frequency matrix, Matlab, Nestedness, Weighted-interaction},
	pages = {1342--1346},
}

@article{opsahl_triadic_2013,
	title = {Triadic {Closure} in {Two}-{Mode} {Networks}: {Redefining} the {Global} and {Local} {Clustering} {Coefficients}},
	volume = {35},
	url = {https://www.sciencedirect.com/science/article/pii/S0378873311000360},
	doi = {10.1016/J.SOCNET.2011.07.001},
	abstract = {As the vast majority of network measures are defined for one-mode networks, two-mode networks often have to be projected onto one-mode networks to be analyzed. A number of issues arise in this transformation process, especially when analyzing ties among nodes’ contacts. For example, the values attained by the global and local clustering coefficients on projected random two-mode networks deviate from the expected values in corresponding classical one-mode networks. Moreover, both the local clustering coefficient and constraint (structural holes) are inversely associated to nodes’ two-mode degree. To overcome these issues, this paper proposes redefinitions of the clustering coefficients for two-mode networks.},
	number = {2},
	journal = {Social Networks},
	author = {Opsahl, Tore},
	month = may,
	year = {2013},
	note = {Publisher: North-Holland},
	pages = {159--167},
}

@article{newman_assortative_2002,
	title = {Assortative {Mixing} in {Networks}},
	volume = {89},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12443515},
	doi = {10.1103/PhysRevLett.89.208701},
	abstract = {A network is said to show assortative mixing if the nodes in the network that have many connections tend to be connected to other nodes with many connections. Here we measure mixing patterns in a variety of networks and find that social networks are mostly assortatively mixed, but that technological and biological networks tend to be disassortative. We propose a model of an assortatively mixed network, which we study both analytically and numerically. Within this model we find that networks percolate more easily if they are assortative and that they are also more robust to vertex removal.},
	number = {20},
	journal = {Physical Review Letters},
	author = {Newman, M. E. J.},
	month = oct,
	year = {2002},
	pages = {208701--208701},
}

@incollection{allatta_structural_2003,
	address = {Dordrecht},
	title = {Structural {Analysis} of {Communities} of {Practice}: {An} {Investigation} of {Job} title, {Location}, and {Management} {Intention}},
	url = {http://link.springer.com/10.1007/978-94-017-0115-0_2},
	booktitle = {Communities and {Technologies}},
	publisher = {Springer Netherlands},
	author = {Allatta, Joan T.},
	year = {2003},
	doi = {10.1007/978-94-017-0115-0_2},
	pages = {23--42},
}

@article{mizruchi_who_1983,
	title = {Who {Controls} {Whom}? {An} {Examination} of the {Relation} between {Management} and {Boards} of {Directors} in {Large} {American} {Corporations}},
	volume = {8},
	url = {http://www.jstor.org/stable/257831?origin=crossref},
	doi = {10.2307/257831},
	abstract = {Most organization theorists believe that boards of directors in large American corporations are dominated by management. This paper argues that this view is based on a problematic definition of control. Several distinctions between long run and short run control are presented, and a framework in which boards of directors have control over managers is suggested. Case examples are given and possible objections are confronted. Finally, an agenda for further research on board-management relations is offered.},
	number = {3},
	journal = {The Academy of Management Review},
	author = {Mizruchi, Mark S.},
	month = jul,
	year = {1983},
	note = {Publisher: Academy of Management},
	pages = {426--435},
}

@article{agresti_survey_1992,
	title = {A {Survey} of {Exact} {Inference} for {Contingency} {Tables}},
	volume = {7},
	url = {http://projecteuclid.org/euclid.ss/1177011454},
	doi = {10.1214/ss/1177011454},
	number = {1},
	journal = {Statistical Science},
	author = {Agresti, Alan},
	month = feb,
	year = {1992},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {131--153},
}

@article{wasserman_random_1977,
	title = {Random directed graph distributions and the triad census in social networks†},
	volume = {5},
	url = {http://www.tandfonline.com/doi/abs/10.1080/0022250X.1977.9989865},
	doi = {10.1080/0022250X.1977.9989865},
	abstract = {This paper uses the concept of the triad census as, developed by Holland and Leinhardt, and describes several distributions on directed graphs. Methods are presented for calculating the mean and the covariance matrix of the triad census for the uniform distribution that conditions on the number of choices made by each individual in the social network. Several complex distributions on digraphs are approximated, and an application of these methods to a sociogram is given.},
	number = {1},
	journal = {The Journal of Mathematical Sociology},
	author = {Wasserman, Stanley S.},
	month = jan,
	year = {1977},
	note = {Publisher: Taylor \& Francis Group},
	pages = {61--86},
}

@book{pollard_users_2002,
	title = {A user's guide to measure theoretic probability},
	isbn = {978-0-511-81155-5},
	abstract = {This text is not just a presentation of mathematical theory, but also a discussion of why that theory takes its current form. It will be a secure starting point for anyone who needs to invoke rigorous probabilistic arguements and understand what they mean. Chapter 1. Motivation -- Ch. 2. A modicum of measure theory -- Ch. 3. Densities and derivatives -- Ch. 4. Product spaces and independence -- Ch. 5. Conditioning -- Ch. 6. Martingale et al. -- Ch. 7. Convergence in distribution -- Ch. 8. Fourier transforms -- Ch. 9. Brownian motion -- Ch. 10. Representations and couplings -- Ch. 11. Exponential tails and the law of the iterated logarithm -- Ch. 12. Multivariate normal distributions -- App. A. Measures and integrals -- App. B. Hilbert spaces -- App. C. Convexity -- App. D. Binomial and normal distributions -- App. E. Martingales in continuous time -- App. F. Disintegration of measures.},
	publisher = {Cambridge University Press},
	author = {Pollard, David},
	year = {2002},
	note = {Pages: 351},
}

@book{pollard_users_2001,
	address = {Cambridge},
	title = {A {User}'s {Guide} to {Measure} {Theoretic} {Probability}},
	isbn = {978-0-511-81155-5},
	url = {http://ebooks.cambridge.org/ref/id/CBO9780511811555},
	publisher = {Cambridge University Press},
	author = {Pollard, David},
	year = {2001},
	doi = {10.1017/CBO9780511811555},
}

@article{rapallo_algebraic_nodate,
	title = {Algebraic {Markov} {Bases} and {MCMC} for {Two}-{Way} {Contingency} {Tables}},
	volume = {30},
	url = {https://www.jstor.org/stable/4616770},
	doi = {10.2307/4616770},
	abstract = {The Diaconis-Sturmfels algorithm is a method for sampling from conditional distributions, based on the algebraic theory of toric ideals. This algorithm is applied to categorical data analysis through the notion of Markov basis. An application of this algorithm is a non-parametric Monte Carlo approach to the goodness of fit tests for contingency tables. In this paper, we characterize or compute the Markov bases for some log-linear models for two-way contingency tables using techniques from Computational Commutative Algebra, namely Gröbner bases. This applies to a large set of cases including independence, quasi-independence, symmetry, quasi-symmetry. Three examples of quasi-symmetry and quasi-independence from Fingleton (Models of category counts, Cambridge University Press, Cambridge, 1984) and Agresti (An Introduction to categorical data analysis, Wiley, New York, 1996) illustrate the practical applicability and the relevance of this algebraic methodology.},
	journal = {Scandinavian Journal of Statistics},
	author = {Rapallo, Fabio},
	note = {Publisher: WileyBoard of the Foundation of the Scandinavian Journal of Statistics},
	pages = {385--397},
}

@techreport{hoff_additive_2018,
	title = {Additive and multiplicative effects network models},
	url = {https://arxiv.org/pdf/1807.08038.pdf},
	abstract = {Network datasets typically exhibit certain types of statistical dependencies, such as within-dyad correlation, row and column heterogeneity, and third-order dependence patterns such as transitivity and clustering. The first two of these can be well-represented statistically with a social relations model, a type of additive random effects model originally developed for continuous dyadic data. Third-order patterns can be represented with multiplicative random effects models, which are related to matrix decompositions commonly used for matrix-variate data analysis. Additionally, these multiplicative random effects models generalize other popular latent variable network models, such as the stochastic blockmodel and the latent space model. In this article we review a general regression framework for the analysis of network data that combines these two types of random effects and accommodates a variety of network data types, including continuous, binary and ordinal network relations.},
	author = {Hoff, Peter D},
	year = {2018},
	keywords = {Bayesian, factor model, generalized linear model, latent variable, matrix decomposi-tion, mixed effects model},
	file = {Hoff - 2018 - Additive and multiplicative effects network models:/Users/jamesscott/Zotero/storage/NCRYQCCD/Hoff - 2018 - Additive and multiplicative effects network models.pdf:application/pdf},
}

@techreport{hoff_modeling_nodate,
	title = {Modeling homophily and stochastic equivalence in symmetric relational data},
	url = {https://papers.nips.cc/paper/3294-modeling-homophily-and-stochastic-equivalence-in-symmetric-relational-data.pdf},
	abstract = {This article discusses a latent variable model for inference and prediction of symmetric relational data. The model, based on the idea of the eigenvalue decomposition , represents the relationship between two nodes as the weighted inner-product of node-specific vectors of latent characteristics. This "eigenmodel" generalizes other popular latent variable models, such as latent class and distance models: It is shown mathematically that any latent class or distance model has a representation as an eigenmodel, but not vice-versa. The practical implications of this are examined in the context of three real datasets, for which the eigenmodel has as good or better out-of-sample predictive performance than the other two models.},
	author = {Hoff, Peter D},
	file = {Hoff - Unknown - Modeling homophily and stochastic equivalence in symmetric relational data:/Users/jamesscott/Zotero/storage/GS2AVFIC/Hoff - Unknown - Modeling homophily and stochastic equivalence in symmetric relational data.pdf:application/pdf},
}

@article{li_variable_2010,
	title = {{VARIABLE} {SELECTION} {AND} {REGRESSION} {ANALYSIS} {FOR} {GRAPH}-{STRUCTURED} {COVARIATES} {WITH} {AN} {APPLICATION} {TO} {GENOMICS} 1},
	volume = {4},
	url = {https://arxiv.org/pdf/1011.3360.pdf},
	doi = {10.1214/10-AOAS332},
	abstract = {Graphs and networks are common ways of depicting biological information. In biology, many different biological processes are represented by graphs, such as regulatory networks, metabolic pathways and protein-protein interaction networks. This kind of a priori use of graphs is a useful supplement to the standard numerical data such as microarray gene expression data. In this paper we consider the problem of regression analysis and variable selection when the covariates are linked on a graph. We study a graph-constrained regularization procedure and its theoretical properties for regression analysis to take into account the neighborhood information of the variables measured on a graph. This procedure involves a smoothness penalty on the coefficients that is defined as a quadratic form of the Laplacian matrix associated with the graph. We establish estimation and model selection consistency results and provide estimation bounds for both fixed and diverging numbers of parameters in regression models. We demonstrate by simulations and a real data set that the proposed procedure can lead to better variable selection and prediction than existing methods that ignore the graph information associated with the covariates. 1. Introduction. There has been a growing interest in penalized least squares problems via L 1 or other types of regularization, especially in high-dimensional settings. Important penalty functions that can lead to sparse variable selection in regression include Lasso [Tibshirani (1996)] and SCAD [Fan and Li (2001)]. In particular, Lasso has the crucial advantage of being a convex problem, which leads to efficient computational algorithms by coordinate descent [Efron et al. (2004); Friedman et al. (2007); Wu and Lange (2008)] and sparse solutions. Zou (2006) proposed a novel adaptive Lasso},
	number = {3},
	author = {Li, Caiyan and Li, Hongzhe},
	year = {2010},
	pages = {1498--1516},
	file = {Li, Li - 2010 - VARIABLE SELECTION AND REGRESSION ANALYSIS FOR GRAPH-STRUCTURED COVARIATES WITH AN APPLICATION TO GENOMICS 1:/Users/jamesscott/Zotero/storage/45NREIGZ/Li, Li - 2010 - VARIABLE SELECTION AND REGRESSION ANALYSIS FOR GRAPH-STRUCTURED COVARIATES WITH AN APPLICATION TO GENOMICS 1.pdf:application/pdf},
}

@article{muller_model_2013,
	title = {Model {Selection} in {Linear} {Mixed} {Models}},
	volume = {28},
	url = {https://arxiv.org/pdf/1306.2427.pdf},
	doi = {10.1214/12-STS410},
	abstract = {Linear mixed effects models are highly flexible in handling a broad range of data types and are therefore widely used in applications. A key part in the analysis of data is model selection, which often aims to choose a parsimonious model with other desirable properties from a possibly very large set of candidate statistical models. Over the last 5-10 years the literature on model selection in linear mixed models has grown extremely rapidly. The problem is much more complicated than in linear regression because selection on the covariance structure is not straightforward due to computational issues and boundary problems arising from positive semidefinite constraints on covariance matrices. To obtain a better understanding of the available methods, their properties and the relationships between them, we review a large body of literature on linear mixed model selection. We arrange, implement, discuss and compare model selection methods based on four major approaches: information criteria such as AIC or BIC, shrinkage methods based on penalized loss functions such as LASSO, the Fence procedure and Bayesian techniques.},
	number = {2},
	journal = {Statistical Science},
	author = {Müller, Samuel and Scealy, J L and Welsh, A H},
	year = {2013},
	keywords = {Cholesky decomposition, AIC, Bayes factor, BIC, fence, information criteria, LASSO, linear mixed model, model selection, shrinkage methods},
	pages = {135--167},
	file = {Müller, Scealy, Welsh - 2013 - Model Selection in Linear Mixed Models:/Users/jamesscott/Zotero/storage/S9UR7LLQ/Müller, Scealy, Welsh - 2013 - Model Selection in Linear Mixed Models.pdf:application/pdf},
}

@misc{kahle_latte_2017-1,
	title = {latte: {LattE} and 4ti2 in {R}},
	url = {https://github.com/dkahle/latte},
	author = {Kahle, Luis {and} Yoshida Ruriko, David {and} Gracia-Puente},
	year = {2017},
	annote = {R package version 0.2.0},
}

@article{girvan_community_2002,
	title = {Community {Structure} in {Social} and {Biological} {Networks}},
	volume = {99},
	number = {12},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Girvan, Michelle and Newman, Mark E J},
	year = {2002},
	note = {Publisher: National Acad Sciences},
	keywords = {*file-import-18-07-12},
	pages = {7821--7826},
}

@article{williams_limits_2004,
	title = {Limits to {Trophic} {Levels} and {Omnivory} in {Complex} {Food} {Webs}: {Theory} and {Data}},
	volume = {163},
	number = {3},
	journal = {The American Naturalist},
	author = {Williams, Richard J and Martinez, Neo D},
	year = {2004},
	note = {Publisher: The University of Chicago Press},
	keywords = {*file-import-18-07-12},
	pages = {458--468},
}

@article{rezende_compartments_2009,
	title = {Compartments in a {Marine} {Food} {Web} {Associated} with {Phylogeny}, {Body} {Mass}, and {Habitat} {Structure}},
	volume = {12},
	number = {8},
	journal = {Ecology Letters},
	author = {Rezende, Enrico L and Albert, Eva M and Fortuna, Miguel A and Bascompte, Jordi},
	year = {2009},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {779--788},
}

@article{roberts_island-sharing_1990,
	title = {Island-sharing by archipelago species},
	volume = {83},
	url = {http://dx.doi.org/10.1007/bf00317210},
	doi = {10.1007/bf00317210},
	number = {4},
	journal = {Oecologia},
	author = {Roberts, Alan and Stone, Lewis},
	year = {1990},
	note = {Publisher: Springer-Verlag},
	pages = {560--567},
}

@article{in_t_veld_finding_2014,
	title = {Finding the core: {Network} structure in interbank markets},
	volume = {49},
	url = {http://www.sciencedirect.com/science/article/pii/S0378426614002738},
	doi = {10.1016/j.jbankfin.2014.08.006},
	journal = {Journal of Banking \& Finance},
	author = {in 't Veld, Daan and van Lelyveld, Iman},
	year = {2014},
	keywords = {*file-import-18-01-19, interbank, networks},
	pages = {27--40},
}

@book{cormen_introduction_2009,
	address = {Cambridge, Massachusetts},
	edition = {3},
	title = {Introduction to {Algorithms}},
	publisher = {MIT press},
	author = {Cormen, Charles E {and} Rivest, Ronald L {and} Stein, Clifford, Thomas H {and} Leiserson},
	year = {2009},
	keywords = {*file-import-18-01-17},
}

@article{kannan_simple_1999,
	title = {Simple {Markov}‐chain algorithms for generating bipartite graphs and tournaments},
	volume = {14},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-2418%28199907%2914%3A4%3C293%3A%3AAID-RSA1%3E3.0.CO%3B2-G},
	doi = {10.1002/(SICI)1098-2418(199907)14:4%3C293::AID-RSA1%3E3.0.CO;2-G},
	abstract = {Abstract We consider two problems: randomly generating labeled bipartite graphs with a given degree sequence and randomly generating labeled tournaments with a given score sequence. We analyze simple Markov chains for both problems. For the first problem, we cannot prove that our chain is rapidly mixing in general, but in the near‐regular case, i.e., when all the degrees are almost equal, we give a proof of rapid mixing. Our methods also apply to the corresponding problem for general (nonbipartite) regular graphs, which was studied earlier by several researchers. One significant difference in our approach is that our chain has one state for every graph (or bipartite graph) with the given degree sequence; in particular, there are no auxiliary states as in the chain used by Jerrum and Sinclair. For the problem of generating tournaments, we are able to prove that our Markov chain on tournaments is rapidly mixing, if the score sequence is near‐regular. The proof techniques we use for the two problems are similar. \{{\textbackslash}copyright\}1999 John Wiley \& Sons, Inc. Random Struct. Alg., 14: 293–308, 1999},
	number = {4},
	journal = {Random Structures \& Algorithms},
	author = {Kannan, Ravi and Tetali, Prasad and Vempala, Santosh},
	year = {1999},
	keywords = {*file-import-18-04-18},
	pages = {293--308},
}

@techreport{cont_network_2013,
	title = {Network structure and systemic risk in banking systems},
	url = {https://ideas.repec.org/p/hal/journl/hal-00912018.html},
	abstract = {We present a quantitative methodology for analyzing the potential for contagion and systemic risk in a network of interlinked financial institutions, using a metric for the systemic importance of institutions: the Contagion Index. We apply this methodology to a data set of mutual exposures and capital levels of financial institutions in Brazil in 2007 and 2008, and analyze the role of balance sheet size and network structure in each institution's contribution to systemic risk. Our results emphasize the contribution of heterogeneity in network structure and concentration of counterparty exposures to a given institution in explaining its systemic importance. These observations plead for capital requirements which depend on exposures, rather than aggregate balance sheet size, and which target systemically important institutions.},
	author = {Cont, Rama and Moussa, Amal and Santos, Edson B},
	month = jul,
	year = {2013},
	doi = {10.1016/j.jebo.2010.07.00},
	note = {Issue: hal-00912018},
	keywords = {*file-import-18-10-04},
}

@article{albert_internet_1999,
	title = {Internet: {Diameter} of the {World}-{Wide} {Web}},
	volume = {401},
	url = {http://dx.doi.org/10.1038/43601},
	doi = {10.1038/43601},
	number = {6749},
	journal = {Nature},
	author = {Albert, Reka and Jeong, Hawoong and Barabasi, Albert-Laszlo},
	year = {1999},
	keywords = {*file-import-18-01-19},
	pages = {130--131},
	annote = {10.1038/43601},
}

@article{anand_filling_2015,
	title = {Filling in the blanks: {Network} structure and interbank contagion},
	volume = {15},
	number = {4},
	journal = {Quantitative Finance},
	author = {Anand, Kartik and Craig, Ben and Von Peter, Goetz},
	year = {2015},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-10-01},
	pages = {625--636},
}

@article{craig_interbank_2014,
	title = {Interbank tiering and money center banks},
	volume = {23},
	number = {3},
	journal = {Journal of Financial Intermediation},
	author = {Craig, Ben and Von Peter, Goetz},
	year = {2014},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-01},
	pages = {322--347},
}

@article{allen_financial_2000,
	title = {Financial contagion},
	volume = {108},
	number = {1},
	journal = {Journal of political economy},
	author = {Allen, Franklin and Gale, Douglas},
	year = {2000},
	note = {Publisher: The University of Chicago Press},
	keywords = {*file-import-18-10-04},
	pages = {1--33},
}

@article{mastromatteo_reconstruction_2012,
	title = {Reconstruction of financial networks for robust estimation of systemic risk},
	volume = {2012},
	number = {03},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Mastromatteo, Iacopo and Zarinelli, Elia and Marsili, Matteo},
	year = {2012},
	note = {Publisher: IOP Publishing},
	keywords = {*file-import-18-10-01},
}

@article{goodman_statistical_1963,
	title = {Statistical {Methods} for the {Preliminary} {Analysis} of {Transaction} {Flows}},
	volume = {31},
	number = {1},
	journal = {Econometrica},
	author = {Goodman, Leo A},
	year = {1963},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {197--208},
}

@article{wasserman_random_1977-1,
	title = {Random directed graph distributions and the triad census in social networks},
	volume = {5},
	url = {http://dx.doi.org/10.1080/0022250x.1977.9989865},
	doi = {10.1080/0022250x.1977.9989865},
	abstract = {This paper uses the concept of the triad census as, developed by Holland and Leinhardt, and describes several distributions on directed graphs. Methods are presented for calculating the mean and the covariance matrix of the triad census for the uniform distribution that conditions on the number of choices made by each individual in the social network. Several complex distributions on digraphs are approximated, and an application of these methods to a sociogram is given.},
	number = {1},
	journal = {The Journal of Mathematical Sociology},
	author = {Wasserman, Stanley S},
	month = jan,
	year = {1977},
	note = {Publisher: Routledge},
	pages = {61--86},
}

@article{barrat_architecture_2004,
	title = {The architecture of complex weighted networks},
	volume = {101},
	url = {http://www.pnas.org/content/101/11/3747},
	doi = {10.1073/pnas.0400087101},
	abstract = {Networked structures arise in a wide array of different contexts such as technological and transportation infrastructures, social phenomena, and biological systems. These highly interconnected systems have recently been the focus of a great deal of attention that has uncovered and characterized their topological complexity. Along with a complex topological structure, real networks display a large heterogeneity in the capacity and intensity of the connections. These features, however, have mainly not been considered in past studies where links are usually represented as binary states, i.e., either present or absent. Here, we study the scientific collaboration network and the world-wide air-transportation network, which are representative examples of social and large infrastructure systems, respectively. In both cases it is possible to assign to each edge of the graph a weight proportional to the intensity or capacity of the connections among the various elements of the network. We define appropriate metrics combining weighted and topological observables that enable us to characterize the complex statistical properties and heterogeneity of the actual strength of edges and vertices. This information allows us to investigate the correlations among weighted quantities and the underlying topological structure of the network. These results provide a better description of the hierarchies and organizational principles at the basis of the architecture of weighted networks.},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Barrat, A and Barthélemy, M and Pastor-Satorras, R and Vespignani, A},
	year = {2004},
	note = {Publisher: National Academy of Sciences},
	keywords = {*file-import-18-10-04},
	pages = {3747--3752},
}

@article{maggio_value_2017,
	title = {The value of trading relations in turbulent times},
	volume = {124},
	url = {http://www.sciencedirect.com/science/article/pii/S0304405X1730003X},
	doi = {10.1016/j.jfineco.2017.01.003},
	number = {2},
	journal = {Journal of Financial Economics},
	author = {Maggio, Marco D and Kermani, Amir and Song, Zhaogang},
	year = {2017},
	keywords = {*file-import-18-01-19, bond, corporate},
	pages = {266--284},
}

@article{holland_exponential_1981,
	title = {An {Exponential} {Family} of {Probability} {Distributions} for {Directed} {Graphs}},
	volume = {76},
	url = {http://dx.doi.org/10.1080/01621459.1981.10477598},
	doi = {10.1080/01621459.1981.10477598},
	abstract = {Abstract Directed graph (or digraph) data arise in many fields, especially in contemporary research on structures of social relationships. We describe an exponential family of distributions that can be used for analyzing such data. A substantive rationale for the general model is presented, and several special cases are discussed along with some possible substantive interpretations. A computational algorithm based on iterative scaling procedures for use in fitting data is described, as are the results of a pilot simulation study. An example using previously reported empirical data is worked out in detail. An extension to multiple relationship data is discussed briefly.},
	number = {373},
	journal = {Journal of the American Statistical Association},
	author = {Holland, Paul W and Leinhardt, Samuel},
	month = mar,
	year = {1981},
	note = {Publisher: Taylor \& Francis},
	pages = {33--50},
}

@article{musmeci_bootstrapping_2013,
	title = {Bootstrapping topological properties and systemic risk of complex networks using the fitness model},
	volume = {151},
	number = {3-4},
	journal = {Journal of Statistical Physics},
	author = {Musmeci, Nicolò and Battiston, Stefano and Caldarelli, Guido and Puliga, Michelangelo and Gabrielli, Andrea},
	year = {2013},
	note = {Publisher: Springer},
	keywords = {*file-import-18-10-01},
	pages = {720--734},
}

@article{carvalho_bayesian_2014,
	title = {A {Bayesian} {Statistical} {Approach} for {Inference} on {Static} {Origin} {Destination} {Matrices} in {Transportation} {Studies}},
	volume = {56},
	url = {http://dx.doi.org/10.1080/00401706.2013.826144},
	doi = {10.1080/00401706.2013.826144},
	number = {2},
	journal = {Technometrics},
	author = {Carvalho, Luis},
	month = apr,
	year = {2014},
	note = {Publisher: Taylor \& Francis},
	pages = {225--237},
}

@article{bayati_sequential_2010,
	title = {A {Sequential} {Algorithm} for {Generating} {Random} {Graphs}},
	volume = {58},
	url = {http://dx.doi.org/10.1007/s00453-009-9340-1},
	doi = {10.1007/s00453-009-9340-1},
	abstract = {Abstract We present a nearly-linear time algorithm for counting and randomly generating simple graphs with a given degree sequence in a certain range. For degree sequence (d i ) i=1 n with maximum degree d max =O(m 1/4−τ ), our algorithm generates almost uniform random graphs with that degree sequence in time O(md max ) where is the number of edges in the graph and τ is any positive constant. The fastest known algorithm for uniform generation of these graphs (McKay and Wormald in J. Algorithms 11(1):52–67, 1990) has a running time of O(m 2 d max 2). Our method also gives an independent proof of McKay's estimate (McKay in Ars Combinatoria A 19:15–25, 1985) for the number of such graphs. We also use sequential importance sampling to derive fully Polynomial-time Randomized Approximation Schemes (FPRAS) for counting and uniformly generating random graphs for the same range of d max =O(m 1/4−τ ). Moreover, we show that for d=O(n 1/2−τ ), our algorithm can generate an asymptotically uniform d-regular graph. Our results improve the previous bound of d=O(n 1/3−τ ) due to Kim and Vu (Adv. Math. 188:444–469, 2004) for regular graphs.},
	number = {4},
	journal = {Algorithmica},
	author = {Bayati, Mohsen and Kim, Jeong H and Saberi, Amin},
	year = {2010},
	note = {Publisher: Springer-Verlag},
	pages = {860--910},
}

@article{anand_missing_2018,
	title = {The missing links: {A} global study on uncovering financial network structures from partial data},
	volume = {35},
	journal = {Journal of Financial Stability},
	author = {Anand, Kartik and van Lelyveld, Iman and Banai, Ádám and Friedrich, Soeren and Garratt, Rodney and Hałaj, Grzegorz and Fique, Jose and Hansen, Ib and Jaramillo, Seraf'in M and Lee, Hwayun and {Others}},
	year = {2018},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-04},
	pages = {107--119},
}

@article{chen_conditional_2007,
	title = {Conditional {Inference} on {Tables} {With} {Structural} {Zeros}},
	volume = {16},
	url = {http://dx.doi.org/10.1198/106186007x209226},
	doi = {10.1198/106186007x209226},
	abstract = {We develop a set of sequential importance sampling (SIS) strategies for sampling nearly uniformly from two-way zero-one or contingency tables with fixed marginal sums and a given set of structural zeros. The SIS procedure samples tables column by column or cell by cell by using appropriate proposal distributions, and enables us to approximate closely the null distributions of a number of test statistics involved in such tables. When structural zeros are on the diagonal or follow certain patterns, more efficient SIS algorithms are developed which guarantee that every generated table is valid. Examples show that our methods can be applied to make conditional inference on zero-one and contingency tables, and are more efficient than other existing Monte Carlo algorithms.},
	number = {2},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Chen, Yuguo},
	month = jun,
	year = {2007},
	note = {Publisher: Taylor \& Francis},
	pages = {445--467},
}

@article{cimini_estimating_2015,
	title = {Estimating topological properties of weighted networks from limited information},
	volume = {92},
	number = {4},
	journal = {Physical Review E},
	author = {Cimini, Giulio and Squartini, Tiziano and Gabrielli, Andrea and Garlaschelli, Diego},
	year = {2015},
	note = {Publisher: APS},
	keywords = {*file-import-18-10-01},
	pages = {40802--40802},
}

@book{wasserman_social_1994,
	series = {Structural {Analysis} in the {Social} {Sciences}},
	title = {Social {Network} {Analysis}: {Methods} and {Applications}},
	url = {https://books.google.co.uk/books?id=wsMgAwAAQBAJ},
	publisher = {Cambridge University Press},
	author = {Wasserman, S and Faust, K},
	year = {1994},
	keywords = {*file-import-18-01-14},
}

@article{milo_network_2002,
	title = {Network {Motifs}: {Simple} {Building} {Blocks} of {Complex} {Networks}},
	volume = {298},
	url = {http://dx.doi.org/10.1126/science.298.5594.824},
	doi = {10.1126/science.298.5594.824},
	abstract = {Complex networks are studied across many fields of science. To uncover their structural design principles, we defined ” network motifs,” patterns of interconnections occurring in complex networks at numbers that are significantly higher than those in randomized networks. We found such motifs in networks from biochemistry, neurobiology, ecology, and engineering. The motifs shared by ecological food webs were distinct from the motifs shared by the genetic networks of Escherichia coli and Saccharomyces cerevisiae or from those found in the World Wide Web. Similar motifs were found in networks that perform information processing, even though they describe elements as different as biomolecules within a cell and synaptic connections between neurons in Caenorhabditis elegans. Motifs may thus define universal classes of networks. This approach may uncover the basic building blocks of most networks.},
	number = {5594},
	journal = {Science},
	author = {Milo, R and Shen-Orr, S and Itzkovitz, S and Kashtan, N and Chklovskii, D and Alon, U},
	month = oct,
	year = {2002},
	note = {Place: Departments of Physics of Complex Systems and Molecular Cell Biology, Weizmann Institute of Science, Rehovot, Israel 76100.
Publisher: American Association for the Advancement of Science},
	pages = {824--827},
}

@article{di_gangi_assessing_2018,
	title = {Assessing systemic risk due to fire sales spillover through maximum entropy network reconstruction},
	author = {Di Gangi, Domenico and Lillo, Fabrizio and Pirino, Davide},
	year = {2018},
	keywords = {*file-import-18-10-01},
}

@article{peltonen_network_2014,
	title = {The network structure of the {CDS} market and its determinants},
	volume = {13},
	url = {http://www.sciencedirect.com/science/article/pii/S1572308914000503},
	doi = {10.1016/j.jfs.2014.05.004},
	journal = {Journal of Financial Stability},
	author = {Peltonen, Tuomas A and Scheicher, Martin and Vuillemey, Guillaume},
	year = {2014},
	keywords = {*file-import-18-01-19, cds, credit, default, swap},
	pages = {118--133},
}

@article{rapallo_markov_2006,
	title = {Markov {Bases} and {Structural} {Zeros}},
	volume = {41},
	number = {2},
	journal = {Journal of Symbolic Computation},
	author = {Rapallo, Fabio},
	year = {2006},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-06-05},
	pages = {164--172},
}

@article{hazelton_network_2015,
	title = {Network tomography for integer-valued traffic},
	volume = {9},
	number = {1},
	journal = {The Annals of Applied Statistics},
	author = {Hazelton, Martin L and {Others}},
	year = {2015},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-28},
	pages = {474--506},
}

@article{doreian_structural_1985,
	title = {Structural equivalence in a psychology journal network},
	volume = {36},
	url = {http://dx.doi.org/10.1002/asi.4630360611},
	doi = {10.1002/asi.4630360611},
	number = {6},
	journal = {Journal of the American Society for Information Science},
	author = {Doreian, Patrick},
	year = {1985},
	note = {Publisher: Wiley Subscription Services, Inc., A Wiley Company},
	keywords = {*file-import-18-01-19},
	pages = {411--417},
}

@article{anand_filling_2015-1,
	title = {Filling in the blanks: network structure and interbank contagion},
	volume = {15},
	url = {http://dx.doi.org/10.1080/14697688.2014.968195},
	doi = {10.1080/14697688.2014.968195},
	number = {4},
	journal = {Quantitative Finance},
	author = {Anand, Kartik and Craig, Ben and von Peter, Goetz},
	year = {2015},
	keywords = {*file-import-18-01-19},
	pages = {625--636},
}

@article{gandy_bayesian_2016,
	title = {A {Bayesian} {Methodology} for {Systemic} {Risk} {Assessment} in {Financial} {Networks}},
	volume = {63},
	number = {12},
	journal = {Management Science},
	author = {Gandy, Axel and Veraart, Luitgard A M},
	year = {2016},
	note = {Publisher: INFORMS},
	keywords = {*file-import-18-01-19},
	pages = {4428--4446},
}

@article{boss_network_2004,
	title = {Network topology of the interbank market},
	volume = {4},
	number = {6},
	journal = {Quantitative finance},
	author = {Boss, Michael and Elsinger, Helmut and Summer, Martin and {Thurner}},
	year = {2004},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-10-04},
	pages = {677--684},
}

@article{baird_seasonal_1989,
	title = {The {Seasonal} {Dynamics} of the {Chesapeake} {Bay} {Ecosystem}},
	volume = {59},
	number = {4},
	journal = {Ecological Monographs},
	author = {Baird, Daniel and Ulanowicz, Robert E},
	year = {1989},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {329--364},
}

@article{grayson_macaulay2_nodate,
	title = {Macaulay2, a {Software} {System} for {Research} in {Algebraic} {Geometry}},
	author = {Grayson, Daniel R and Stillman, Michael E},
	keywords = {*file-import-18-07-16},
}

@incollection{barrat_architecture_2007,
	title = {The {Architecture} of {Complex} {Weighted} {Networks}: {Measurements} and {Models}},
	booktitle = {Large {Scale} {Structure} {And} {Dynamics} {Of} {Complex} {Networks}: {From} {Information} {Technology} to {Finance} and {Natural} {Science}},
	publisher = {World Scientific},
	author = {Barrat, Alain and Barthelemy, Marc and Vespignani, Alessandro},
	year = {2007},
	keywords = {*file-import-18-10-04},
	pages = {67--92},
}

@article{roberts_surprising_2015,
	title = {Surprising {Convergence} {Properties} of {Some} {Simple} {Gibbs} {Samplers} under {Various} {Scans}},
	volume = {5},
	url = {http://www.ccsenet.org/journal/index.php/ijsp/article/view/55570},
	doi = {10.5539/ijsp.v5n1p51},
	abstract = {We examine the convergence properties of some simple Gibbs sampler examples under various scans. We find some surprising results, including Gibbs samplers where deterministic-scan is much more efficient than random-scan, and other samplers where the opposite is true. We also present an example where the convergence takes precisely the same time with any fixed deterministic scan, but modifying the scan in any way leads to significantly slower convergence.},
	number = {1},
	journal = {International Journal of Statistics and Probability},
	author = {Roberts, Gareth O and Rosenthal, Jeffrey S},
	year = {2015},
	keywords = {*file-import-18-01-19},
	pages = {51--51},
}

@article{blitzstein_sequential_2011,
	title = {A {Sequential} {Importance} {Sampling} {Algorithm} for {Generating} {Random} {Graphs} with {Prescribed} {Degrees}},
	volume = {6},
	url = {http://dx.doi.org/10.1080/15427951.2010.557277},
	doi = {10.1080/15427951.2010.557277},
	abstract = {Abstract Random graphs with given degrees are a natural next step in complexity beyond the Erd?s?Rényi model, yet the degree constraint greatly complicates simulation and estimation. We use an extension of a combinatorial characterization due to Erd?s and Gallai to develop a sequential algorithm for generating a random labeled graph with a given degree sequence. The algorithm is easy to implement and allows for surprisingly efficient sequential importance sampling. The resulting probabilities are easily computed on the fly, allowing the user to reweight estimators appropriately, in contrast to some ad hoc approaches that generate graphs with the desired degrees but with completely unknown probabilities. Applications are given, including simulating an ecological network and estimating the number of graphs with a given degree sequence.},
	number = {4},
	journal = {Internet Mathematics},
	author = {Blitzstein, Joseph and Diaconis, Persi},
	month = mar,
	year = {2011},
	note = {Publisher: Taylor \& Francis},
	pages = {489--522},
}

@book{levin_markov_2009,
	title = {Markov {Chains} and {Mixing} {Time}},
	publisher = {American Mathematical Society},
	author = {{Levin} and Wilmer, E L},
	year = {2009},
	keywords = {*file-import-18-01-19},
}

@article{gustafsson_solution_1980,
	title = {A {Solution} of the {Conditional} {Estimation} {Problem} for {Long} {Tests} in the {Rasch} model for {Dichotomous} {Items}},
	volume = {40},
	number = {2},
	journal = {Educational and Psychological Measurement},
	author = {Gustafsson, Jan-Eric},
	year = {1980},
	note = {Publisher: Sage Publications Sage CA: Thousand Oaks, CA},
	keywords = {*file-import-18-01-14},
	pages = {377--385},
}

@article{pimm_are_1980,
	title = {Are {Food} {Webs} {Divided} into {Compartments}?},
	volume = {49},
	number = {3},
	journal = {The Journal of Animal Ecology},
	author = {Pimm, Stuart L and Lawton, John H},
	year = {1980},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-12},
	pages = {879--898},
}

@article{li_bayesian_2005,
	title = {Bayesian inference for origin-destination matrices of transport networks using the {EM} algorithm},
	volume = {47},
	number = {4},
	journal = {Technometrics},
	author = {Li, Baibing},
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-01-28},
	pages = {399--408},
}

@incollection{olesen_broadstone_2010,
	title = {From {Broadstone} to {Zackenberg}: {Space}, {Time} and {Hierarchies} in {Ecological} {Networks}},
	volume = {42},
	booktitle = {Advances in ecological research},
	publisher = {Elsevier},
	author = {Olesen, Jens M and Dupont, Yoko L and O'Gorman, Eoin and Ings, Thomas C and Layer, Katrin and Melián, Carlos J and Trøjelsgaard, Kristian and Pichler, Doris E and Rasmussen, Claus and Woodward, Guy},
	year = {2010},
	keywords = {*file-import-18-07-12},
	pages = {1--69},
}

@article{fortunato_community_2010-1,
	title = {Community detection in graphs},
	volume = {486},
	url = {http://www.sciencedirect.com/science/article/pii/S0370157309002841},
	doi = {10.1016/j.physrep.2009.11.002},
	number = {3},
	journal = {Physics Reports},
	author = {Fortunato, Santo},
	year = {2010},
	keywords = {*file-import-18-01-19, graphs},
	pages = {75--174},
}

@article{squartini_network_2017,
	title = {Network reconstruction via density sampling},
	volume = {2},
	number = {1},
	journal = {Applied Network Science},
	author = {Squartini, Tiziano and Cimini, Giulio and Gabrielli, Andrea and Garlaschelli, Diego},
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {*file-import-18-10-01},
	pages = {3--3},
}

@article{diaconis_testing_1985,
	title = {Testing for independence in a two-way table: new interpretations of the chi-square statistic},
	journal = {The Annals of Statistics},
	author = {Diaconis, Persi and Efron, Bradley},
	year = {1985},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-06-05},
	pages = {845--874},
}

@article{cocco_lending_2009,
	title = {Lending relationships in the interbank market},
	volume = {18},
	number = {1},
	journal = {Journal of Financial Intermediation},
	author = {Cocco, Joao F and Gomes, Francisco J and Martins, Nuno C},
	year = {2009},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-04},
	pages = {24--48},
}

@article{savage_statistical_1960,
	title = {A {Statistical} {Model} of the {Gross} {Analysis} of {Transaction} {Flows}},
	journal = {Econometrica: Journal of the Econometric Society},
	author = {Savage, I Richard and Deutsch, Karl W},
	year = {1960},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {551--572},
}

@article{caldarelli_scale-free_2002,
	title = {Scale-free networks from varying vertex intrinsic fitness},
	volume = {89},
	number = {25},
	journal = {Physical review letters},
	author = {Caldarelli, Guido and Capocci, Andrea and De Los Rios, Paolo and Munoz, Miguel A},
	year = {2002},
	note = {Publisher: APS},
	keywords = {*file-import-18-10-01},
	pages = {258702--258702},
}

@article{watson_missing_1956,
	title = {Missing and "mixed-up" {Frequencies} in {Contingency} {Tables}},
	volume = {12},
	number = {1},
	journal = {Biometrics},
	author = {Watson, Geoffrey S},
	year = {1956},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {47--50},
}

@article{conrad_parallel_2018,
	title = {Parallel {Local} {Approximation} {MCMC} for {Expensive} {Models}},
	volume = {6},
	url = {https://doi.org/10.1137/16M1084080},
	doi = {10.1137/16M1084080},
	number = {1},
	journal = {SIAM/ASA Journal on Uncertainty Quantification},
	author = {Conrad, P and Davis, A and Marzouk, Y and Pillai, N and Smith, A},
	year = {2018},
	keywords = {*file-import-18-09-28},
	pages = {339--373},
}

@article{mastrandrea_enhanced_2014,
	title = {Enhanced reconstruction of weighted networks from strengths and degrees},
	volume = {16},
	number = {4},
	journal = {New Journal of Physics},
	author = {Mastrandrea, Rossana and Squartini, Tiziano and Fagiolo, Giorgio and Garlaschelli, Diego},
	year = {2014},
	note = {Publisher: IOP Publishing},
	keywords = {*file-import-18-10-01},
	pages = {43022--43022},
}

@article{bezakova_negative_2012,
	title = {Negative {Examples} for {Sequential} {Importance} {Sampling} of {Binary} {Contingency} {Tables}},
	volume = {64},
	url = {http://dx.doi.org/10.1007/s00453-011-9569-3},
	doi = {10.1007/s00453-011-9569-3},
	abstract = {The sequential importance sampling (SIS) algorithm has gained considerable popularity for its empirical success. One of its noted applications is to the binary contingency tables problem, an important problem in statistics, where the goal is to estimate the number of 0/1 matrices with prescribed row and column sums. We give a family of examples in which the SIS procedure, if run for any subexponential number of trials, will underestimate the number of tables by an exponential factor. This result holds for any of the usual design choices in the SIS algorithm, namely the ordering of the columns and rows. These are apparently the first theoretical results on the efficiency of the SIS algorithm for binary contingency tables. Finally, we present experimental evidence that the SIS algorithm is efficient for row and column sums that are regular. Our work is a first step in determining the class of inputs for which SIS is effective.},
	number = {4},
	journal = {Algorithmica},
	author = {Bezáková, Ivona and Sinclair, Alistair and Štefankovič, Daniel and Vigoda, Eric},
	month = sep,
	year = {2012},
	note = {Publisher: Springer-Verlag},
	pages = {606--620},
}

@article{staum_systemic_2016,
	title = {Systemic risk components in a network model of contagion},
	volume = {48},
	url = {http://dx.doi.org/10.1080/0740817X.2015.1110650},
	doi = {10.1080/0740817X.2015.1110650},
	number = {6},
	journal = {IIE Transactions},
	author = {Staum, Jeremy and Feng, Mingbin and Liu, Ming},
	year = {2016},
	keywords = {*file-import-18-01-28},
	pages = {501--510},
}

@article{connor_assembly_1979,
	title = {The {Assembly} of {Species} {Communities}: {Chance} or {Competition}?},
	volume = {60},
	url = {http://www.jstor.org/stable/1936961},
	abstract = {We challenge Diamond's (1975) idea that island species distributions are determined predominantly by competitions canonized by his @'assembly rules.@' We show that every assembly rule is either tautological, trivial, or a pattern expected were species distributed at random. In order to demonstrate that competition is responsible for the joint distributions of species, one would have to falsify a null hypothesis stating that the distributions are generated by the species randomly and individually colonizing an archipelago.},
	number = {6},
	journal = {Ecology},
	author = {Connor, Edward F and Simberloff, Daniel},
	year = {1979},
	note = {Publisher: Ecological Society of America},
	keywords = {*file-import-18-03-13},
	pages = {1132--1140},
}

@article{zhang_sampling_2013,
	title = {Sampling for {Conditional} {Inference} on {Network} {Data}},
	volume = {108},
	url = {http://dx.doi.org/10.1080/01621459.2012.758587},
	doi = {10.1080/01621459.2012.758587},
	abstract = {Random graphs with given vertex degrees have been widely used as a model for many real-world complex networks. However, both statistical inference and analytic study of such networks present great challenges. In this article, we propose a new sequential importance sampling method for sampling networks with a given degree sequence. These samples can be used to approximate closely the null distributions of a number of test statistics involved in such networks and provide an accurate estimate of the total number of networks with given vertex degrees. We study the asymptotic behavior of the proposed algorithm and prove that the importance weight remains bounded as the size of the graph grows. This property guarantees that the proposed sampling algorithm can still work efficiently even for large sparse graphs. We apply our method to a range of examples to demonstrate its efficiency in real problems.},
	number = {504},
	journal = {Journal of the American Statistical Association},
	author = {Zhang, Jingfei and Chen, Yuguo},
	month = dec,
	year = {2013},
	note = {Publisher: Taylor \& Francis},
	pages = {1295--1307},
}

@book{cody_ecology_1975,
	title = {Ecology and evolution of communities},
	publisher = {Harvard University Press},
	author = {Cody, Martin L and Diamond, Jared M},
	year = {1975},
	keywords = {*file-import-18-04-11},
}

@article{mantel_analyses_1963,
	title = {Analyses of {Birth}-{Rank} {Data}},
	volume = {19},
	number = {2},
	journal = {Biometrics},
	author = {Mantel, Nathan and Halperin, Max},
	year = {1963},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {324--340},
}

@article{gotelli_swap_2001,
	title = {Swap and {Fill} {Algorithms} in {Null} {Model} {Analysis}: {Rethinking} the {Knight}'s {Tour}},
	volume = {129},
	url = {http://dx.doi.org/10.1007/s004420100717},
	doi = {10.1007/s004420100717},
	number = {2},
	journal = {Oecologia},
	author = {Gotelli, NicholasJ and Entsminger, GaryL},
	year = {2001},
	note = {Publisher: Springer Berlin Heidelberg},
	pages = {281--291},
}

@article{miller_exact_2013,
	title = {Exact sampling and counting for fixed-margin matrices},
	volume = {41},
	url = {https://doi.org/10.1214/13-AOS1131},
	doi = {10.1214/13-AOS1131},
	number = {3},
	journal = {Ann. Statist.},
	author = {Miller, Jeffrey W and Harrison, Matthew T},
	year = {2013},
	note = {Publisher: The Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-14},
	pages = {1569--1592},
}

@article{borgatti_models_2000,
	title = {Models of core/periphery structures},
	volume = {21},
	url = {http://www.sciencedirect.com/science/article/pii/S0378873399000192},
	doi = {10.1016/S0378-8733(99)00019-2},
	number = {4},
	journal = {Social Networks},
	author = {Borgatti, Stephen P and Everett, Martin G},
	year = {2000},
	keywords = {*file-import-18-01-19, core},
	pages = {375--395},
}

@book{krugman_self_1996,
	title = {The {Self} {Organising} {Economy}},
	publisher = {Wiley},
	author = {Krugman, Paul},
	month = feb,
	year = {1996},
	keywords = {*file-import-18-01-19},
}

@article{chen_exact_2005,
	title = {Exact tests for the rasch model via sequential importance sampling},
	volume = {70},
	url = {http://dx.doi.org/10.1007/s11336-003-1069-1},
	doi = {10.1007/s11336-003-1069-1},
	abstract = {Rasch proposed an exact conditional inference approach to testing his model but never implemented it because it involves the calculation of a complicated probability. This paper furthers Rasch's approach by (1) providing an efficient Monte Carlo methodology for accurately approximating the required probability and (2) illustrating the usefulness of Rasch's approach for several important testing problems through simulation studies. Our Monte Carlo methodology is shown to compare favorably to other Monte Carlo methods proposed for this problem in two respects: it is considerably faster and it provides more reliable estimates of the Monte Carlo standard error.},
	number = {1},
	journal = {Psychometrika},
	author = {Chen, Yuguo and Small, Dylan},
	month = mar,
	year = {2005},
	note = {Publisher: Springer-Verlag},
	pages = {11--30},
}

@article{mcdonald_markov_2007,
	title = {Markov chain {Monte} {Carlo} {Exact} {Inference} for {Social} {Networks}},
	volume = {29},
	url = {http://www.sciencedirect.com/science/article/pii/S0378873306000141},
	doi = {10.1016/j.socnet.2006.04.003},
	number = {1},
	journal = {Social Networks},
	author = {McDonald, John W and Smith, Peter W F and Forster, Jonathan J},
	year = {2007},
	keywords = {*file-import-18-01-14, adjacency, algorithm, carlo, census, chain, conditional, exact, markov, matrices, metropolishastings, monte, reciprocity, test, triad},
	pages = {127--136},
}

@article{rao_markov_1996,
	title = {A {Markov} {Chain} {Monte} {Carlo} {Method} for {Generating} {Random} (0, 1) {Matrices} with {Given} {Marginals}},
	volume = {58},
	url = {http://www.jstor.org/stable/25051102},
	number = {2},
	journal = {Sankhya: The Indian Journal of Statistics, Series A (1961-2002)},
	author = {Rao, A Ramachandra and Jana, Rabindranath and Bandyopadhyay, Suraj},
	year = {1996},
	note = {Publisher: Springer},
	keywords = {*file-import-18-01-14},
	pages = {225--242},
}

@article{brualdi_matrices_1980,
	title = {Matrices of zeros and ones with fixed row and column sum vectors},
	volume = {33},
	url = {http://www.sciencedirect.com/science/article/pii/0024379580901056},
	doi = {10.1016/0024-3795(80)90105-6},
	journal = {Linear Algebra and its Applications},
	author = {Brualdi, Richard A},
	year = {1980},
	keywords = {*file-import-18-01-14},
	pages = {159--231},
}

@article{diaconis_algebraic_1998,
	title = {Algebraic {Algorithms} for {Sampling} from {Conditional} {Distributions}},
	volume = {26},
	url = {https://doi.org/10.1214/aos/1030563990},
	doi = {10.1214/aos/1030563990},
	number = {1},
	journal = {Annals of Statistics},
	author = {Diaconis, Persi and Sturmfels, Bernd},
	year = {1998},
	note = {Publisher: The Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-14},
	pages = {363--397},
}

@article{ulrich_null_2007,
	title = {Null {Model} {Analysis} of {Species} {Nestedness} {Patterns}},
	volume = {88},
	number = {7},
	journal = {Ecology},
	author = {Ulrich, Werner and Gotelli, Nicholas J},
	year = {2007},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {1824--1831},
}

@article{goodman_analysis_1968,
	title = {The {Analysis} of {Cross}-{Classified} {Data}: {Independence}, {Quasi}-{Independence}, and {Interactions} in {Contingency} {Tables} with or without {Missing} {Entries}},
	volume = {63},
	number = {324},
	journal = {Journal of the American Statistical Association},
	author = {Goodman, Leo A},
	year = {1968},
	note = {Publisher: Taylor \& Francis Group},
	keywords = {*file-import-18-07-13},
	pages = {1091--1131},
}

@article{eisinger_sampling_2017,
	title = {Sampling for {Conditional} {Inference} on {Contingency} {Tables}},
	volume = {26},
	number = {1},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Eisinger, Robert D and Chen, Yuguo},
	year = {2017},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-06-05},
	pages = {79--87},
}

@article{gandy_adjustable_2018,
	title = {Adjustable network reconstruction with applications to {CDS} exposures},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X17306279},
	doi = {10.1016/j.jmva.2018.08.011},
	journal = {Journal of Multivariate Analysis},
	author = {Gandy, Axel and Veraart, Luitgard A},
	year = {2018},
	keywords = {graphs, *file-import-18-10-03, balancing, bayesian, calibration, matrix, methods, random, risk, systemic},
}

@article{ponocny_nonparametric_2001,
	title = {Nonparametric goodness-of-fit tests for the rasch model},
	volume = {66},
	url = {http://dx.doi.org/10.1007/bf02294444},
	doi = {10.1007/bf02294444},
	number = {3},
	journal = {Psychometrika},
	author = {Ponocny, Ivo},
	year = {2001},
	note = {Publisher: Springer-Verlag},
	pages = {437--459},
}

@techreport{acemoglu_systemic_2013,
	title = {Systemic {Risk} and {Stability} in {Financial} {Networks}},
	url = {http://www.nber.org/papers/w18727},
	abstract = {We provide a framework for studying the relationship between the financial network architecture and the likelihood of systemic failures due to contagion of counterparty risk. We show that financial contagion exhibits a form of phase transition as interbank connections increase: as long as the magnitude and the number of negative shocks affecting financial institutions are sufficiently small, more "complete" interbank claims enhance the stability of the system. However, beyond a certain point, such interconnections start to serve as a mechanism for propagation of shocks and lead to a more fragile financial system. We also show that, under natural contracting assumptions, financial networks that emerge in equilibrium may be socially inefficient due to the presence of a network externality: even though banks take the effects of their lending, risk-taking and failure on their immediate creditors into account, they do not internalize the consequences of their actions on the rest of the network.},
	author = {Acemoglu, Daron and Ozdaglar, Asuman and Tahbaz-Salehi, Alireza},
	month = jan,
	year = {2013},
	doi = {10.3386/w18727},
	note = {Issue: 18727},
	keywords = {*file-import-18-01-28},
}

@article{park_statistical_2004,
	title = {Statistical mechanics of networks},
	volume = {70},
	number = {6},
	journal = {Physical Review E},
	author = {Park, Juyong and Newman, Mark E J},
	year = {2004},
	note = {Publisher: APS},
	keywords = {*file-import-18-10-04},
	pages = {66117--66117},
}

@article{hudson_cheddar_2018,
	title = {Cheddar: {Analysis} and {Visualisation} of {Ecological} {Communities}},
	url = {https://github.com/quicklizard99/cheddar/},
	author = {Hudson, Lawrence and Reuman, Daniel and Emerson, Rob},
	year = {2018},
	keywords = {*file-import-18-07-12},
	annote = {R package version 0.1-633},
}

@article{elsinger_using_2006,
	title = {Using {Market} {Information} for {Banking} {System} {Risk} {Assessment}},
	volume = {2},
	url = {https://ideas.repec.org/a/ijc/ijcjou/y2006q1a4.html},
	abstract = {We propose a new method for the analysis of systemic stability of a banking system relying mostly on market data. We model both asset correlations and interlinkages from interbank borrowing so that our analysis gauges two major sources of systemic risk: correlated exposures and mutual credit relations that may cause domino effects of insolvencies. We apply our method to a data set of the ten major UK banks and analyze insolvency risk over a one-year horizon. We also suggest a stress-testing procedure by analyzing the conditional asset return distribution that results from the hypothetical failure of individual institutions in this system. Rather than looking at individual bank defaults ceteris paribus, we take the change in the asset return distribution and the resulting change in the risk of all other banks into account. This takes previous stress tests of interlinkages a substantial step further.},
	number = {1},
	journal = {International Journal of Central Banking},
	author = {Elsinger, Helmut and Lehar, Alfred and Summer, Martin},
	month = mar,
	year = {2006},
	keywords = {*file-import-18-10-03},
}

@article{jeong_lethality_2001,
	title = {Lethality and centrality in protein networks},
	volume = {411},
	url = {http://dx.doi.org/10.1038/35075138},
	doi = {10.1038/35075138},
	number = {6833},
	journal = {Nature},
	author = {Jeong, H and Mason, S P and Barabasi, A L and Oltvai, Z N},
	year = {2001},
	keywords = {*file-import-18-01-19},
	pages = {41--42},
	annote = {10.1038/35075138},
}

@article{verhelst_efficient_2008,
	title = {An {Efficient} {MCMC} {Algorithm} to {Sample} {Binary} {Matrices} with {Fixed} {Marginals}},
	volume = {73},
	url = {http://dx.doi.org/10.1007/s11336-008-9062-3},
	doi = {10.1007/s11336-008-9062-3},
	number = {4},
	journal = {Psychometrika},
	author = {Verhelst, Norman D},
	year = {2008},
	note = {Publisher: Springer-Verlag},
	pages = {705--728},
}

@book{ryser_combinatorial_1963,
	title = {Combinatorial {Mathematics}},
	url = {http://dx.doi.org/10.5948/UPO9781614440147},
	publisher = {Mathematical Association of America},
	author = {Ryser, Herbert J},
	year = {1963},
	doi = {10.5948/UPO9781614440147},
	keywords = {*file-import-18-01-14},
}

@article{erdh_os_random_1959,
	title = {On {Random} {Graphs} {I}.},
	volume = {6},
	journal = {Publicationes Mathematicae (Debrecen)},
	author = {ErdH os, Paul and Rényi, Alfréd},
	year = {1959},
	keywords = {*file-import-18-01-19, graphs, random},
	pages = {290--297},
}

@article{porter_communities_2009,
	title = {Communities in networks},
	volume = {56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349607513&},
	number = {9},
	journal = {Notices of the American Mathematical Society},
	author = {Porter, M A and Onnela, J P and Mucha, P J},
	year = {2009},
	keywords = {*file-import-18-01-19},
	pages = {1082--1097},
	annote = {cited By 421},
}

@article{roberts_simple_2000,
	title = {Simple {Methods} for {Simulating} {Sociomatrices} with {Given} {Marginal} {Totals}},
	volume = {22},
	url = {http://www.sciencedirect.com/science/article/pii/S0378873300000265},
	doi = {10.1016/S0378-8733(00)00026-5},
	number = {3},
	journal = {Social Networks},
	author = {Roberts, John M},
	year = {2000},
	keywords = {*file-import-18-01-14},
	pages = {273--283},
}

@article{haldane_systemic_2011,
	title = {Systemic risk in banking ecosystems},
	volume = {469},
	url = {http://dx.doi.org/10.1038/nature09659},
	doi = {10.1038/nature09659},
	journal = {Nature},
	author = {Haldane, Andrew G and May, Robert M},
	month = jan,
	year = {2011},
	keywords = {*file-import-18-01-28},
	pages = {351--355},
}

@article{mistrulli_assessing_2011,
	title = {Assessing financial contagion in the interbank market: {Maximum} entropy versus observed interbank lending patterns},
	volume = {35},
	number = {5},
	journal = {Journal of Banking \& Finance},
	author = {Mistrulli, Paolo E},
	year = {2011},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-01},
	pages = {1114--1127},
}

@article{jacob_unbiased_2018,
	title = {Unbiased {Markov} chain {Monte} {Carlo} with couplings},
	url = {http://arxiv.org/abs/1708.03625},
	abstract = {Markov chain Monte Carlo (MCMC) methods provide consistent approximations of
integrals as the number of iterations goes to infinity. MCMC estimators are
generally biased after any fixed number of iterations, which complicates both
parallel computation and the construction of confidence intervals. We propose
to remove this bias by using couplings of Markov chains together with a
telescopic sum argument of Glynn \& Rhee (2014). The resulting unbiased
estimators can be computed in parallel, with confidence intervals following
directly from the Central Limit Theorem for i.i.d. variables. We discuss
practical couplings for popular algorithms such as Metropolis-Hastings, Gibbs
samplers, and Hamiltonian Monte Carlo. We establish the theoretical validity of
the proposed estimators and study their efficiency relative to the underlying
MCMC algorithms. Finally, we illustrate the performance and limitations of the
method on toy examples, a variable selection problem, and an approximation of
the cut distribution arising in Bayesian inference for models made of multiple
modules.},
	author = {Jacob, P and O'Leary, J and Atchadé, Yves},
	month = feb,
	year = {2018},
	annote = {arXiv:1708.03625 [stat.ME]},
}

@book{agresti_categorical_2013,
	edition = {3rd},
	title = {Categorical {Data} {Analysis}},
	publisher = {John Wiley \& Sons},
	author = {Agresti, Alan},
	year = {2013},
	keywords = {*file-import-18-06-05},
}

@article{manly_note_1995,
	title = {A {Note} on the {Analysis} of {Species} {Co}-{Occurrences}},
	volume = {76},
	url = {http://dx.doi.org/10.2307/1940919},
	doi = {10.2307/1940919},
	abstract = {The analysis of records of species occurrences on islands in an attempt to detect interactions between species has been an area of controversy in recent years in terms of the validity of some of the statistical methods used. In this note I make two contributions to the continuing debate. First, I advocate a generalized Monte Carlo testing procedure because this is easy to implement, is computationally efficient, and has guaranteed properties when the null hypothesis of no species interactions is correct. Second, I propose a test statistic that can be decomposed into a component for each individual species, and I demonstrate how this makes it possible to isolate species with unusual patterns of co—occurrence with other species, even after an allowance for multiple testing is made.},
	number = {4},
	journal = {Ecology},
	author = {Manly, Bryan F J},
	month = jun,
	year = {1995},
	note = {Publisher: Ecological Society of America},
	pages = {1109--1115},
}

@article{krause_compartments_2003,
	title = {Compartments {Revealed} in {Food}-{Web} {Structure}},
	volume = {426},
	number = {6964},
	journal = {Nature},
	author = {Krause, Ann E and Frank, Kenneth A and Mason, Doran M and Ulanowicz, Robert E and Taylor, William W},
	year = {2003},
	note = {Publisher: Nature Publishing Group},
	keywords = {*file-import-18-07-12},
	pages = {282--285},
}

@article{strona_fast_2014,
	title = {A fast and unbiased procedure to randomize ecological binary matrices with fixed row and column totals},
	volume = {5},
	url = {http://dx.doi.org/http://dx.doi.org/10.1038/ncomms5114},
	doi = {10.1038/ncomms5114},
	journal = {Nature Communications},
	author = {Strona, Giovanni and Nappo, Domenico and Boccacci, Francesco and Fattorini, Simone and San-Miguel-Ayanz, Jesus},
	year = {2014},
	keywords = {*file-import-18-01-14},
}

@article{drehmann_measuring_2013,
	title = {Measuring the systemic importance of interconnected banks},
	volume = {22},
	number = {4},
	journal = {Journal of Financial Intermediation},
	author = {Drehmann, Mathias and Tarashev, Nikola},
	year = {2013},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-01},
	pages = {586--607},
}

@book{rasch_probabilistic_1960,
	title = {Probabilistic {Models} for some {Intelligence} and {Achievement} {Tests}},
	publisher = {University of Chicago Press},
	author = {Rasch, Georg},
	year = {1960},
	note = {Publication Title: Copenhagen: Danish Institute for Educational Research},
	keywords = {*file-import-18-01-14},
}

@article{chen_sequential_2005,
	title = {Sequential {Monte} {Carlo} {Methods} for {Statistical} {Analysis} of {Tables}},
	volume = {100},
	url = {http://dx.doi.org/10.1198/016214504000001303},
	doi = {10.1198/016214504000001303},
	abstract = {We describe a sequential importance sampling (SIS) procedure for analyzing two-way zero?one or contingency tables with fixed marginal sums. An essential feature of the new method is that it samples the columns of the table progressively according to certain special distributions. Our method produces Monte Carlo samples that are remarkably close to the uniform distribution, enabling one to approximate closely the null distributions of various test statistics about these tables. Our method compares favorably with other existing Monte Carlo-based algorithms, and sometimes is a few orders of magnitude more efficient. In particular, compared with Markov chain Monte Carlo (MCMC)-based approaches, our importance sampling method not only is more efficient in terms of absolute running time and frees one from pondering over the mixing issue, but also provides an easy and accurate estimate of the total number of tables with fixed marginal sums, which is far more difficult for an MCMC method to achieve.},
	number = {469},
	journal = {Journal of the American Statistical Association},
	author = {Chen, Yuguo and Diaconis, Persi and Holmes, Susan P and Liu, Jun S},
	month = mar,
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	pages = {109--120},
}

@article{elliott_financial_2014,
	title = {Financial {Networks} and {Contagion}},
	volume = {104},
	url = {http://www.aeaweb.org/articles?id=10.1257/aer.104.10.3115},
	doi = {10.1257/aer.104.10.3115},
	number = {10},
	journal = {American Economic Review},
	author = {Elliott, Matthew and Golub, Benjamin and Jackson, Matthew O},
	month = oct,
	year = {2014},
	keywords = {*file-import-18-01-28},
	pages = {3115--3153},
}

@incollection{mazzarisi_methods_2017,
	title = {Methods for reconstructing interbank networks from limited information: a comparison},
	booktitle = {Econophysics and {Sociophysics}: {Recent} {Progress} and {Future} {Directions}},
	publisher = {Springer},
	author = {Mazzarisi, Piero and Lillo, Fabrizio},
	year = {2017},
	keywords = {*file-import-18-10-01},
	pages = {201--215},
}

@article{aoki_markov_2005,
	title = {Markov {Chain} {Monte} {Carlo} {Exact} {Tests} for {Incomplete} two-way {Contingency} {Tables}},
	volume = {75},
	number = {10},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Aoki, Satoshi and Takemura, Akimichi},
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-06-05},
	pages = {787--812},
}

@incollection{diaconis_rectangular_1995,
	series = {The {IMA} {Volumes} in {Mathematics} and its {Applications}},
	title = {Rectangular {Arrays} with {Fixed} {Margins}},
	volume = {72},
	url = {http://dx.doi.org/10.1007/978-1-4612-0801-3_3},
	abstract = {In a variety of combinatorial and statistical applications, one needs to know the number of rectangular arrays of nonnegative integers with given row and column sums. The combinatorial problems include counting magic squares, enumerating permutations by descent patterns and a variety of problems in representation theory. The statistical problems involve goodness of fit tests for contingency tables. We review these problems along with the available techniques for exact and approximate solution.},
	booktitle = {Discrete {Probability} and {Algorithms}},
	publisher = {Springer New York},
	author = {Diaconis, Persi and Gangolli, Anil},
	editor = {Aldous, David and Diaconis, Persi and Spencer, Joel and {Steele}},
	year = {1995},
	doi = {10.1007/978-1-4612-0801-3_3},
	pages = {15--41},
}

@article{cimini_systemic_2015,
	title = {Systemic risk analysis on reconstructed economic and financial networks},
	volume = {5},
	journal = {Scientific reports},
	author = {Cimini, Giulio and Squartini, Tiziano and Garlaschelli, Diego and Gabrielli, Andrea},
	year = {2015},
	note = {Publisher: Nature Publishing Group},
	keywords = {*file-import-18-10-01},
	pages = {15758--15758},
}

@article{fienberg_preliminary_1969,
	title = {Preliminary {Graphical} {Analysis} and {Quasi}-{Independence} for two-way {Contingency} {Tables}},
	volume = {18},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Fienberg, Stephen E},
	year = {1969},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {153--168},
}

@article{wells_financial_2004,
	title = {Financial interlinkages in the {United} {Kingdom}'s interbank market and the risk of contagion},
	author = {Wells, Simon J},
	year = {2004},
	keywords = {*file-import-18-10-01},
}

@article{snijders_enumeration_1991,
	title = {Enumeration and {Simulation} {Methods} for 0-1 {Matrices} with {Given} {Marginals}},
	volume = {56},
	url = {http://dx.doi.org/10.1007/bf02294482},
	doi = {10.1007/bf02294482},
	number = {3},
	journal = {Psychometrika},
	author = {Snijders, Tom A B},
	year = {1991},
	note = {Publisher: Springer-Verlag},
	pages = {397--417},
}

@article{gai_contagion_2010,
	title = {Contagion in financial networks},
	volume = {466},
	url = {http://rspa.royalsocietypublishing.org/content/466/2120/2401},
	doi = {10.1098/rspa.2009.0410},
	abstract = {This paper develops an analytical model of contagion in financial networks with arbitrary structure. We explore how the probability and potential impact of contagion is influenced by aggregate and idiosyncratic shocks, changes in network structure and asset market liquidity. Our findings suggest that financial systems exhibit a robust-yet-fragile tendency: while the probability of contagion may be low, the effects can be extremely widespread when problems occur. And we suggest why the resilience of the system in withstanding fairly large shocks prior to 2007 should not have been taken as a reliable guide to its future robustness.},
	number = {2120},
	journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
	author = {Gai, Prasanna and Kapadia, Sujit},
	year = {2010},
	note = {Publisher: The Royal Society},
	keywords = {*file-import-18-01-28},
	pages = {2401--2423},
}

@article{goodman_statistical_1965,
	title = {On the {Statistical} {Analysis} of {Mobility} {Tables}},
	volume = {70},
	number = {5},
	journal = {American Journal of Sociology},
	author = {Goodman, Leo A},
	year = {1965},
	note = {Publisher: University of Chicago Press},
	keywords = {*file-import-18-07-16},
	pages = {564--585},
}

@incollection{baral_estimation_2012,
	title = {Estimation of bilateral exposures-a copula approach},
	booktitle = {Technical {Report}},
	publisher = {mimeo},
	author = {Baral, Pallavi and Fique, Jose P},
	year = {2012},
	keywords = {*file-import-18-10-01},
}

@article{blanchet_efficient_2009,
	title = {Efficient importance sampling for binary contingency tables},
	volume = {19},
	url = {https://doi.org/10.1214/08-AAP558},
	doi = {10.1214/08-AAP558},
	number = {3},
	journal = {Ann. Appl. Probab.},
	author = {Blanchet, Jose H},
	year = {2009},
	note = {Publisher: The Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-14},
	pages = {949--982},
}

@article{besag_generalized_1989,
	title = {Generalized {Monte} {Carlo} significance tests},
	volume = {76},
	url = {+},
	doi = {10.1093/biomet/76.4.633},
	number = {4},
	journal = {Biometrika},
	author = {Besag, Julian and Clifford, Peter},
	year = {1989},
	keywords = {*file-import-18-01-14},
	pages = {633--642},
}

@book{moussa_contagion_2011,
	title = {Contagion and systemic risk in financial networks},
	publisher = {Citeseer},
	author = {Moussa, Amal},
	year = {2011},
	keywords = {*file-import-18-10-01},
}

@book{pearson_theory_1904,
	title = {On the {Theory} of {Contingency} and its {Relation} to {Association} and {Normal} {Correlation}; {On} the {General} {Theory} of {Skew} {Correlation} and {Non}-{Linear} {Regression}},
	publisher = {Cambridge University Press},
	author = {Pearson, Karl},
	year = {1904},
	keywords = {*file-import-18-07-16},
}

@article{scott_state-dependent_2018,
	title = {State-{Dependent} {Kernel} {Selection} for {Conditional} {Sampling} of {Graphs}},
	url = {http://arxiv.org/abs/1809.06758},
	abstract = {This paper introduces new efficient algorithms for two problems: sampling
conditional on vertex degrees in unweighted graphs, and sampling conditional on
vertex strengths in weighted graphs. The algorithms can sample conditional on
the presence or absence of an arbitrary number of edges. The resulting
conditional distributions provide the basis for exact tests. Existing samplers
based on MCMC or sequential importance sampling are generally not scalable;
their efficiency degrades in sparse graphs. MCMC methods usually require
explicit computation of a Markov basis to navigate the complex state space;
this is computationally intensive even for small graphs. We use state-dependent
kernel selection to develop new MCMC samplers. These do not require a Markov
basis, and are efficient both in sparse and dense graphs. The key idea is to
intelligently select a Markov kernel on the basis of the current state of the
chain. We apply our methods to testing hypotheses on a real network and
contingency table. The algorithms appear orders of magnitude more efficient
than existing methods in the test cases considered.},
	author = {Scott, J and Gandy, A},
	month = sep,
	year = {2018},
	annote = {arXiv:1809.06758 [stat.ME]},
}

@article{schneider_comparative_1990,
	title = {A comparative study of algorithms for matrix balancing},
	volume = {38},
	number = {3},
	journal = {Operations research},
	author = {Schneider, Michael H and Zenios, Stavros A},
	year = {1990},
	note = {Publisher: INFORMS},
	keywords = {*file-import-18-10-04},
	pages = {439--455},
}

@article{vardi_network_1996,
	title = {Network {Tomography}: {Estimating} {Source}-{Destination} {Traffic} {Intensities} from {Link} {Data}},
	volume = {91},
	url = {http://dx.doi.org/10.1080/01621459.1996.10476697},
	doi = {10.1080/01621459.1996.10476697},
	abstract = {Abstract The problem of estimating the node-to-node traffic intensity from repeated measurements of traffic on the links of a network is formulated and discussed under Poisson assumptions and two types of traffic-routing regimens: deterministic (a fixed known path between each directed pair of nodes) and Markovian (a random path between each directed pair of nodes, determined according to a known Markov chain fixed for that pair). Maximum likelihood estimation and related approximations are discussed, and computational difficulties are pointed out. A detailed methodology is presented for estimates based on the method of moments. The estimates are derived algorithmically, taking advantage of the fact that the first and second moment equations give rise to a linear inverse problem with positivity restrictions that can be approached by an EM algorithm, resulting in a particularly simple solution to a hard problem. A small simulation study is carried out.},
	number = {433},
	journal = {Journal of the American Statistical Association},
	author = {Vardi, Y},
	month = mar,
	year = {1996},
	note = {Publisher: Taylor \& Francis},
	pages = {365--377},
}

@book{gelman_bayesian_2013,
	title = {Bayesian data analysis},
	publisher = {Chapman and Hall/CRC},
	author = {Gelman, Andrew and Stern, Hal S and Carlin, John B and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
	year = {2013},
	keywords = {*file-import-18-10-04},
}

@article{bishop_incomplete_1969,
	title = {Incomplete {Two}-{Dimensional} {Contingency} {Tables}},
	volume = {25},
	number = {1},
	journal = {Biometrics},
	author = {Bishop, Yvonne M M and Fienberg, Stephen E},
	year = {1969},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {119--128},
}

@article{squartini_analytical_2011,
	title = {Analytical maximum-likelihood method to detect patterns in real networks},
	volume = {13},
	number = {8},
	journal = {New Journal of Physics},
	author = {Squartini, Tiziano and Garlaschelli, Diego},
	year = {2011},
	note = {Publisher: IOP Publishing},
	keywords = {*file-import-18-10-01},
	pages = {83001--83001},
}

@article{upper_estimating_2004,
	title = {Estimating bilateral exposures in the {German} interbank market: {Is} there a danger of contagion?},
	volume = {48},
	url = {http://www.sciencedirect.com/science/article/pii/S0014292104000145},
	doi = {10.1016/j.euroecorev.2003.12.009},
	number = {4},
	journal = {European Economic Review},
	author = {Upper, Christian and Worms, Andreas},
	year = {2004},
	keywords = {interbank, *file-import-18-10-01, banks, contagion, market, of, regulation},
	pages = {827--849},
}

@article{jerrum_polynomial-time_2004,
	title = {A {Polynomial}-time {Approximation} {Algorithm} for the {Permanent} of a {Matrix} with {Nonnegative} {Entries}},
	volume = {51},
	url = {http://doi.acm.org/10.1145/1008731.1008738},
	doi = {10.1145/1008731.1008738},
	number = {4},
	journal = {J. ACM},
	author = {Jerrum, Mark and Sinclair, Alistair and Vigoda, Eric},
	month = jul,
	year = {2004},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {carlo, chain, markov, monte, matrix, of, *file-import-18-01-15, a, chains, mixing, permanent, rapidly},
	pages = {671--697},
}

@article{glasserman_contagion_2016,
	title = {Contagion in {Financial} {Networks}},
	volume = {54},
	url = {http://www.aeaweb.org/articles?id=10.1257/jel.20151228},
	doi = {10.1257/jel.20151228},
	number = {3},
	journal = {Journal of Economic Literature},
	author = {Glasserman, Paul and Young, H Peyton},
	month = sep,
	year = {2016},
	keywords = {*file-import-18-01-28},
	pages = {779--831},
}

@article{conrad_accelerating_2016,
	title = {Accelerating {Asymptotically} {Exact} {MCMC} for {Computationally} {Intensive} {Models} via {Local} {Approximations}},
	volume = {111},
	url = {https://doi.org/10.1080/01621459.2015.1096787},
	doi = {10.1080/01621459.2015.1096787},
	number = {516},
	journal = {Journal of the American Statistical Association},
	author = {Conrad, Patrick R and Marzouk, Youssef M and Pillai, Natesh S and Smith, Aaron},
	year = {2016},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-09-27},
	pages = {1591--1607},
}

@article{castro_network_2004,
	title = {Network tomography: {Recent} developments},
	journal = {Statistical science},
	author = {Castro, Rui and Coates, Mark and Liang, Gang and Nowak, Robert and Yu, Bin},
	year = {2004},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-10-04},
	pages = {499--517},
}

@article{faloutsos_power-law_1999,
	title = {On {Power}-law {Relationships} of the {Internet} {Topology}},
	volume = {29},
	url = {http://doi.acm.org/10.1145/316194.316229},
	doi = {10.1145/316194.316229},
	number = {4},
	journal = {SIGCOMM Comput. Commun. Rev.},
	author = {Faloutsos, Michalis and Faloutsos, Petros and Faloutsos, Christos},
	month = aug,
	year = {1999},
	note = {Place: New York, NY, USA
Publisher: ACM},
	keywords = {*file-import-18-01-19},
	pages = {251--262},
}

@article{tebaldi_bayesian_1998,
	title = {Bayesian {Inference} on {Network} {Traffic} {Using} {Link} {Count} {Data}},
	volume = {93},
	url = {http://dx.doi.org/10.1080/01621459.1998.10473707},
	doi = {10.1080/01621459.1998.10473707},
	abstract = {Abstract We study Bayesian models and methods for analysing network traffic counts in problems of inference about the traffic intensity between directed pairs of origins and destinations in networks. This is a class of problems very recently discussed by Vardi in a 1996 JASA article and is of interest in both communication and transportation network studies. The current article develops the theoretical framework of variants of the origin-destination flow problem and introduces Bayesian approaches to analysis and inference. In the first, the so-called fixed routing problem, traffic or messages pass between nodes in a network, with each message originating at a specific source node, and ultimately moving through the network to a predetermined destination node. All nodes are candidate origin and destination points. The framework assumes no travel time complications, considering only the number of messages passing between pairs of nodes in a specified time interval. The route count, or route flow, problem is to infer the set of actual number of messages passed between each directed origin-destination pair in the time interval, based on the observed counts flowing between all directed pairs of adjacent nodes. Based on some development of the theoretical structure of the problem and assumptions about prior distributional forms, we develop posterior distributions for inference on actual origin-destination counts and associated flow rates. This involves iterative simulation methods, or Markov chain Monte Carlo (MCMC), that combine Metropolis?Hastings steps within an overall Gibbs sampling framework. We discuss issues of convergence and related practical matters, and illustrate the approach in a network previously studied in Vardi's article. We explore both methodological and applied aspects much further in a concrete problem of a road network in North Carolina, studied in transportation flow assessment contexts by civil engineers. This investigation generates critical insight into limitations of statistical analysis, and particularly of non-Bayesian approaches, due to inherent structural features of the problem. A truly Bayesian approach, imposing partial stochastic constraints through informed prior distributions, offers a way of resolving these problems and is consistent with prevailing trends in updating traffic flow intensities in this field. Following this, we explore a second version of the problem that introduces elements of uncertainty about routes taken by individual messages in terms of Markov selection of outgoing links for messages at any given node. For specified route choice probabilities, we introduce the concept of a super-network?namely, a fixed routing problem in which the stochastic problem may be embedded. This leads to solution of the stochastic version of the problem using the methods developed for the original formulation of the fixed routing problem. This is also illustrated. Finally, we discuss various related issues and model extensions, including inference on stochastic route choice selection probabilities, questions of missing data and partially observed link counts, and relationships with current research on road traffic network problems in which travel times within links are nonnegligible and may be estimated from additional data.},
	number = {442},
	journal = {Journal of the American Statistical Association},
	author = {Tebaldi, Claudia and West, Mike},
	month = jun,
	year = {1998},
	note = {Publisher: Taylor \& Francis},
	pages = {557--573},
}

@article{heng_unbiased_2018,
	title = {Unbiased {Hamiltonian} {Monte} {Carlo} with couplings},
	url = {http://arxiv.org/abs/1709.00404},
	abstract = {We propose a methodology to parallelize Hamiltonian Monte Carlo estimators.
Our approach constructs a pair of Hamiltonian Monte Carlo chains that are
coupled in such a way that they meet exactly after some random number of
iterations. These chains can then be combined so that resulting estimators are
unbiased. This allows us to produce independent replicates in parallel and
average them to obtain estimators that are consistent in the limit of the
number of replicates, instead of the usual limit of the number of Markov chain
iterations. We investigate the scalability of our coupling in high dimensions
on a toy example. The choice of algorithmic parameters and the efficiency of
our proposed methodology are then illustrated on a logistic regression with 300
covariates, and a log-Gaussian Cox point processes model with low to fine
grained discretizations.},
	author = {Heng, J and Jacob, P},
	month = aug,
	year = {2018},
	annote = {arXiv:1709.00404 [stat.CO]},
}

@article{halaj_assessing_2013,
	title = {Assessing interbank contagion using simulated networks},
	volume = {10},
	number = {2-3},
	journal = {Computational Management Science},
	author = {Hałaj, Grzegorz and Kok, Christoffer},
	year = {2013},
	note = {Publisher: Springer},
	keywords = {*file-import-18-10-01},
	pages = {157--186},
}

@article{guimera_origin_2010,
	title = {Origin of {Compartmentalization} in {Food} {Webs}},
	volume = {91},
	number = {10},
	journal = {Ecology},
	author = {Guimerà, Roger and Stouffer, D B and Sales-Pardo, Marta and Leicht, E A and Newman, M E J and Amaral, Luis A N},
	year = {2010},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {2941--2951},
}

@article{newman_structure_2001,
	title = {The structure of scientific collaboration networks},
	volume = {98},
	url = {http://www.pnas.org/content/98/2/404.abstract},
	doi = {10.1073/pnas.98.2.404},
	abstract = {The structure of scientific collaboration networks is investigated. Two scientists are considered connected if they have authored a paper together and explicit networks of such connections are constructed by using data drawn from a number of databases, including MEDLINE (biomedical research), the Los Alamos e-Print Archive (physics), and NCSTRL (computer science). I show that these collaboration networks form ” small worlds,” in which randomly chosen pairs of scientists are typically separated by only a short path of intermediate acquaintances. I further give results for mean and distribution of numbers of collaborators of authors, demonstrate the presence of clustering in the networks, and highlight a number of apparent differences in the patterns of collaboration between the fields studied.},
	number = {2},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Newman, M E J},
	year = {2001},
	keywords = {*file-import-18-01-19},
	pages = {404--409},
}

@techreport{hoff_additive_2018-1,
	title = {Additive and multiplicative effects network models},
	url = {https://arxiv.org/pdf/1807.08038.pdf},
	abstract = {Network datasets typically exhibit certain types of statistical dependencies, such as within-dyad correlation, row and column heterogeneity, and third-order dependence patterns such as transitivity and clustering. The first two of these can be well-represented statistically with a social relations model, a type of additive random effects model originally developed for continuous dyadic data. Third-order patterns can be represented with multiplicative random effects models, which are related to matrix decompositions commonly used for matrix-variate data analysis. Additionally, these multiplicative random effects models generalize other popular latent variable network models, such as the stochastic blockmodel and the latent space model. In this article we review a general regression framework for the analysis of network data that combines these two types of random effects and accommodates a variety of network data types, including continuous, binary and ordinal network relations.},
	author = {Hoff, Peter D},
	year = {2018},
	keywords = {Bayesian, factor model, generalized linear model, latent variable, matrix decomposi-tion, mixed effects model},
	file = {Hoff - 2018 - Additive and multiplicative effects network models:/Users/jamesscott/Zotero/storage/SA9P6X9I/Hoff - 2018 - Additive and multiplicative effects network models.pdf:application/pdf},
}

@techreport{bierkens_piecewise_2018,
	title = {Piecewise {Deterministic} {Markov} {Processes} for {Scalable} {Monte} {Carlo} on {Restricted} {Domains}},
	url = {https://arxiv.org/pdf/1701.04244.pdf},
	abstract = {Piecewise Deterministic Monte Carlo algorithms enable simulation from a posterior distribution, whilst only needing to access a sub-sample of data at each iteration. We show how they can be implemented in settings where the parameters live on a restricted domain.},
	author = {Bierkens, Joris and Bouchard-Côté, Alexandre and Doucet, Arnaud and Duncan, Andrew B and Fearnhead, Paul and Lienart, Thibaut and Roberts, Gareth and Vollmer, Sebastian J},
	year = {2018},
	file = {Bierkens et al. - 2018 - Piecewise Deterministic Markov Processes for Scalable Monte Carlo on Restricted Domains:/Users/jamesscott/Zotero/storage/WXHAB895/Bierkens et al. - 2018 - Piecewise Deterministic Markov Processes for Scalable Monte Carlo on Restricted Domains.pdf:application/pdf},
}

@techreport{vanetti_piecewise-deterministic_2018,
	title = {Piecewise-{Deterministic} {Markov} {Chain} {Monte} {Carlo}},
	url = {https://arxiv.org/pdf/1707.05296v2.pdf},
	abstract = {A novel class of non-reversible Markov chain Monte Carlo schemes relying on continuous-time piecewise-deterministic Markov Processes has recently emerged. In these algorithms, the state of the Markov process evolves according to a deterministic dynamics which is modified using a Markov transition kernel at random event times. These methods enjoy remarkable features including the ability to update only a subset of the state components while other components implicitly keep evolving and the ability to use an unbiased estimate of the gradient of the log-target while preserving the target as invariant distribution. However, they also suffer from important limitations. The deterministic dynamics used so far do not exploit the structure of the target. Moreover, exact simulation of the event times is feasible for an important yet restricted class of problems and, even when it is, it is application specific. This limits the applicability of these techniques and prevents the development of a generic software implementation of them. We introduce novel MCMC methods addressing these shortcomings. In particular, we introduce novel continuous-time algorithms relying on exact Hamiltonian flows and novel non-reversible discrete-time algorithms which can exploit complex dynamics such as approximate Hamiltonian dynamics arising from symplectic integrators while preserving the attractive features of continuous-time algorithms. We demonstrate the performance of these schemes on a variety of applications.},
	author = {Vanetti, Paul and Bouchard-Côté, Alexandre and Deligiannidis, George and Doucet, Arnaud},
	year = {2018},
	keywords = {generalized Metropolis-Hastings, Hamiltonian dynamics, intractable likelihood, non-reversible Markov chain Monte Carlo, piecewise-deterministic Markov process, weak convergence},
	file = {Vanetti et al. - 2018 - Piecewise-Deterministic Markov Chain Monte Carlo:/Users/jamesscott/Zotero/storage/TFEPAW99/Vanetti et al. - 2018 - Piecewise-Deterministic Markov Chain Monte Carlo.pdf:application/pdf},
}

@article{noauthor_efficient_nodate,
	title = {Efficient {Markovian} {Couplings}: {Examples} and {Counterexamples}},
	url = {https://projecteuclid.org/download/pdf_1/euclid.aoap/1019487348},
}

@article{del_moral_digital_2003,
	title = {Digital {Object} {Identifier} ( {On} contraction properties of {Markov} kernels},
	volume = {126},
	url = {https://perso.math.univ-toulouse.fr/miclo/files/2012/04/contraction.pdf},
	doi = {10.1007/s00440-003-0270-6},
	abstract = {We study Lipschitz contraction properties of general Markov kernels seen as operators on spaces of probability measures equipped with entropy-like "distances". Universal quantitative bounds on the associated ergodic constants are deduced from Dobrushin's ergodic coefficient. Strong contraction properties in Orlicz spaces for relative densities are proved under more restrictive mixing assumptions. We also describe contraction bounds in the entropy sense around arbitrary probability measures by introducing a suitable Dirichlet form and the corresponding modified logarithmic Sobolev constants. The interest in these bounds is illustrated on the example of inhomogeneous Gaussian chains. In particular, the existence of an invariant measure is not required in general.},
	journal = {Probab. Theory Relat. Fields},
	author = {Del Moral, P and Ledoux, · M and Miclo, · L},
	year = {2003},
	pages = {395--420},
	file = {Del Moral, Ledoux, Miclo - 2003 - Digital Object Identifier ( On contraction properties of Markov kernels:/Users/jamesscott/Zotero/storage/9RTBC6UG/Del Moral, Ledoux, Miclo - 2003 - Digital Object Identifier ( On contraction properties of Markov kernels.pdf:application/pdf},
}

@techreport{bou-rabee_coupling_nodate,
	title = {Coupling and {Convergence} for {Hamiltonian} {Monte} {Carlo}},
	url = {https://arxiv.org/pdf/1805.00452.pdf},
	abstract = {Based on a new coupling approach, we prove that the transition step of the Hamiltonian Monte Carlo algorithm is contractive w.r.t. a carefully designed Kantorovich (L 1 Wasserstein) distance. The lower bound for the contraction rate is explicit. Global convexity of the potential is not required, and thus multimodal target distributions are included. Explicit quantitative bounds for the number of steps required to approximate the stationary distribution up to a given error are a direct consequence of con-tractivity. These bounds show that HMC can overcome diffusive behaviour if the duration of the Hamiltonian dynamics is adjusted appropriately. MSC 2010 subject classifications: Primary 60J05; Secondary 65P10, 65C05.},
	author = {Bou-Rabee, Nawaf and Eberle, Andreas and Zimmer, Raphael},
	keywords = {and phrases: coupling, convergence to equilibrium, geo-metric integrator, Hamiltonian Monte Carlo, Hybrid Monte Carlo, Markov Chain Monte Carlo, Metropolis-Hastings},
	file = {Bou-Rabee, Eberle, Zimmer - Unknown - Coupling and Convergence for Hamiltonian Monte Carlo:/Users/jamesscott/Zotero/storage/PY5TLU56/Bou-Rabee, Eberle, Zimmer - Unknown - Coupling and Convergence for Hamiltonian Monte Carlo.pdf:application/pdf},
}

@techreport{glynn_exact_2014,
	title = {{EXACT} {ESTIMATION} {FOR} {MARKOV} {CHAIN} {EQUILIBRIUM} {EXPECTATIONS}},
	url = {https://chrhee.github.io/papers/GlynnRhee14a.pdf},
	abstract = {We introduce a new class of Monte Carlo methods, which we call exact estimation algorithms. Such algorithms provide unbiased estimators for equilibrium expectations associated with real-valued functionals defined on a Markov chain. We provide easily implemented algorithms for the class of positive Harris recurrent Markov chains, and for chains that are contracting on average. We further argue that exact estimation in the Markov chain setting provides a significant theoretical relaxation relative to exact simulation methods.},
	author = {Glynn, Peter W and Rhee, Chang-Han},
	year = {2014},
	keywords = {exact estimation, exact sampling, exact simulation, Markov chain equilibrium expectation, Markov chain stationary expectation, perfect sampling, perfect simulation 2010 Mathematics Subject Classification: Primary 65C05 Secondary 60J05, Unbiased estimation},
	file = {Glynn, Rhee - 2014 - EXACT ESTIMATION FOR MARKOV CHAIN EQUILIBRIUM EXPECTATIONS:/Users/jamesscott/Zotero/storage/7SNWFGF9/Glynn, Rhee - 2014 - EXACT ESTIMATION FOR MARKOV CHAIN EQUILIBRIUM EXPECTATIONS.pdf:application/pdf},
}

@article{noauthor_one-shot_nodate,
	title = {One-shot coupling for certain stochastic recursive sequences},
	url = {https://pdf.sciencedirectassets.com/271499/1-s2.0-S0304414900X02086/1-s2.0-S0304414902000960/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEKb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIFcMm4sRvob6SwqZx1DVrX0zHv%2B915RzvMge31Cai8QAAiB%2Bm2JNHqOa},
}

@techreport{betancourt_nested_2010,
	title = {Nested {Sampling} with {Constrained} {Hamiltonian} {Monte} {Carlo}},
	url = {https://arxiv.org/pdf/1005.0157.pdf},
	abstract = {Nested sampling is a powerful approach to Bayesian inference ultimately limited by the computationally demanding task of sampling from a heavily constrained probability distribution. An effective algorithm in its own right, Hamiltonian Monte Carlo is readily adapted to efficiently sample from any smooth, constrained distribution. Utilizing this constrained Hamiltonian Monte Carlo, I introduce a general implementation of the nested sampling algorithm.},
	author = {Betancourt, Michael},
	year = {2010},
	file = {Betancourt - 2010 - Nested Sampling with Constrained Hamiltonian Monte Carlo:/Users/jamesscott/Zotero/storage/SCDXX9F3/Betancourt - 2010 - Nested Sampling with Constrained Hamiltonian Monte Carlo.pdf:application/pdf},
}

@techreport{brubaker_family_2012,
	title = {A {Family} of {MCMC} {Methods} on {Implicitly} {Defined} {Manifolds}},
	url = {http://www.cs.toronto.edu/~mbrubake/projects/AISTATS12.pdf},
	abstract = {Traditional MCMC methods are only applicable to distributions defined on R n. However , there exist many application domains where the distributions cannot easily be defined on a Euclidean space. To address this limitation, we propose a general constrained version of Hamiltonian Monte Carlo, and give conditions under which the Markov chain is convergent. Based on this general framework we define a family of MCMC methods which can be applied to sample from distributions on non-linear manifolds. We demonstrate the effectiveness of our approach on a variety of problems including sampling from the Bingham-von Mises-Fisher distribution, col-laborative filtering and pose estimation.},
	author = {Brubaker, Marcus A and Salzmann, Mathieu and Urtasun, Raquel},
	year = {2012},
	file = {Brubaker, Salzmann, Urtasun - 2012 - A Family of MCMC Methods on Implicitly Defined Manifolds:/Users/jamesscott/Zotero/storage/NKHV3ZQA/Brubaker, Salzmann, Urtasun - 2012 - A Family of MCMC Methods on Implicitly Defined Manifolds.pdf:application/pdf},
}

@techreport{desalvo_random_2016,
	title = {Random {Sampling} of {Contingency} {Tables} via {Probabilistic} {Divide}-and-{Conquer}},
	url = {https://arxiv.org/pdf/1507.00070.pdf},
	abstract = {We present a new approach for random sampling of contingency tables of any size and constraints based on a recently introduced probabilistic divide-and-conquer technique. A simple exact sampling algorithm is presented for 2 × n tables, as well as a generalization where each entry of the table has a specified marginal distribution. MSC 2010 subject classifications: Primary 62H17; secondary 60C05, 52B99.},
	author = {Desalvo, Stephen and Zhao, James Y},
	year = {2016},
	keywords = {exact sampling, 52B99contingency tables, 60C05, 62H17, probabilistic divide-and-conquer, transportation polytope},
	file = {Desalvo, Zhao - 2016 - Random Sampling of Contingency Tables via Probabilistic Divide-and-Conquer:/Users/jamesscott/Zotero/storage/62JTWBFA/Desalvo, Zhao - 2016 - Random Sampling of Contingency Tables via Probabilistic Divide-and-Conquer.pdf:application/pdf},
}

@techreport{cappello_sequential_2019,
	title = {Sequential importance sampling for multi-resolution {Kingman}-{Tajima} coalescent counting},
	url = {https://arxiv.org/pdf/1902.05527.pdf},
	abstract = {Statistical inference of evolutionary parameters from molecular sequence data relies on coalescent models to account for the shared genealogical ancestry of the samples. However , inferential algorithms do not scale to available data sets. A strategy to improve computational efficiency is to rely on simpler coalescent and mutation models, resulting in smaller hidden state spaces. An estimate of the cardinality of the state-space of genealogi-cal trees at different resolutions is essential to decide the best modeling strategy for a given dataset. To our knowledge, there is neither an exact nor approximate method to determine these cardinalities. We propose a sequential importance sampling algorithm to estimate the cardinality of the space of genealogical trees under different coalescent resolutions. Our sampling scheme proceeds sequentially across the set of combinatorial constraints imposed by the data. We analyse the cardinality of different genealogical tree spaces on simulations to study the settings that favor coarser resolutions. We estimate the cardinality of genealogical tree spaces from mtDNA data from the 1000 genomes and a sample from a Melanesian population to illustrate the settings in which it is advantageous to employ coarser resolutions.},
	author = {Cappello, Lorenzo and Palacios, Julia A},
	year = {2019},
	file = {Cappello, Palacios - 2019 - Sequential importance sampling for multi-resolution Kingman-Tajima coalescent counting:/Users/jamesscott/Zotero/storage/DHCZ7N6B/Cappello, Palacios - 2019 - Sequential importance sampling for multi-resolution Kingman-Tajima coalescent counting.pdf:application/pdf},
}

@article{smith_gibbs_2014,
	title = {A {GIBBS} {SAMPLER} {ON} {THE} n-{SIMPLEX}},
	volume = {24},
	url = {https://arxiv.org/pdf/1107.5829.pdf},
	doi = {10.1214/12-AAP916},
	abstract = {We determine the mixing time of a simple Gibbs sampler on the unit simplex, confirming a conjecture of Aldous. The upper bound is based on a two-step coupling, where the first step is a simple contraction argument and the second step is a non-Markovian coupling. We also present a MCMC-based perfect sampling algorithm based on our proof which can be applied with Gibbs samplers that are harder to analyze.},
	number = {1},
	journal = {The Annals of Applied Probability},
	author = {Smith, Aaron},
	year = {2014},
	keywords = {Gibbs sampler, perfect sampling, 60J10, 65C04, Markov chain},
	pages = {114--130},
	file = {Smith - 2014 - A GIBBS SAMPLER ON THE n-SIMPLEX:/Users/jamesscott/Zotero/storage/P2HK9A9J/Smith - 2014 - A GIBBS SAMPLER ON THE n-SIMPLEX.pdf:application/pdf},
}

@techreport{hayes_variable_2006,
	title = {Variable {Length} {Path} {Coupling}},
	url = {https://www.cs.unm.edu/~hayes/papers/VariableLengthPathCoupling/hayes-vigoda-VLPC.pdf},
	abstract = {We present a new technique for constructing and analyzing couplings to bound the convergence rate of finite Markov chains. Our main theorem is a generalization of the path coupling theorem of Bub-ley and Dyer, allowing the defining partial couplings to have length determined by a random stopping time. Unlike the original path coupling theorem, our version can produce multi-step (non-Markovian) couplings. Using our variable length path coupling theorem, we improve the upper bound on the mixing time of the Glauber dynamics for randomly sampling colorings.},
	author = {Hayes, Thomas P and Vigoda, Eric},
	year = {2006},
	file = {Hayes, Vigoda - 2006 - Variable Length Path Coupling:/Users/jamesscott/Zotero/storage/ETHMETIH/Hayes, Vigoda - 2006 - Variable Length Path Coupling.pdf:application/pdf},
}

@inproceedings{hayes_non-markovian_nodate,
	title = {A non-{Markovian} coupling for randomly sampling colorings},
	isbn = {0-7695-2040-5},
	url = {http://ieeexplore.ieee.org/document/1238234/},
	doi = {10.1109/SFCS.2003.1238234},
	booktitle = {44th {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science}, 2003. {Proceedings}.},
	publisher = {IEEE Computer. Soc},
	author = {Hayes, T.P. and Vigoda, E.},
	pages = {618--627},
}

@techreport{pakman_auxiliary-variable_nodate,
	title = {Auxiliary-variable {Exact} {Hamiltonian} {Monte} {Carlo} {Samplers} for {Binary} {Distributions}},
	url = {http://www.stat.columbia.edu/~liam/research/pubs/pakman-exact-binary-hmc.pdf},
	abstract = {We present a new approach to sample from generic binary distributions, based on an exact Hamiltonian Monte Carlo algorithm applied to a piecewise continuous augmentation of the binary distribution of interest. An extension of this idea to distributions over mixtures of binary and possibly-truncated Gaussian or exponential variables allows us to sample from posteriors of linear and probit regression models with spike-and-slab priors and truncated parameters. We illustrate the advantages of these algorithms in several examples in which they outperform the Metropolis or Gibbs samplers.},
	author = {Pakman, Ari and Paninski, Liam},
	file = {Pakman, Paninski - Unknown - Auxiliary-variable Exact Hamiltonian Monte Carlo Samplers for Binary Distributions:/Users/jamesscott/Zotero/storage/GDLSTYB7/Pakman, Paninski - Unknown - Auxiliary-variable Exact Hamiltonian Monte Carlo Samplers for Binary Distributions.pdf:application/pdf},
}

@techreport{nishimura_discontinuous_nodate,
	title = {Discontinuous {Hamiltonian} {Monte} {Carlo} for discrete parameters and discontinuous likelihoods},
	url = {https://arxiv.org/pdf/1705.08510.pdf},
	abstract = {Hamiltonian Monte Carlo has emerged as a standard tool for posterior computation. In this article , we present an extension that can efficiently explore target distributions with discontinuous densities, which in turn enables efficient sampling from ordinal parameters though embedding of probability mass functions into continuous spaces. We motivate our approach through a theory of discontinuous Hamiltonian dynamics and develop a corresponding numerical solver. The proposed solver is the first of its kind, with a remarkable ability to exactly preserve the Hamiltonian and thus yield a type of rejection-free proposal. We apply our algorithm to challenging posterior inference problems to demonstrate its wide applicability and competitive performance.},
	author = {Nishimura, Akihiko and Dunson, David B and Lu, Jianfeng},
	keywords = {Markov chain Monte Carlo, geometric numerical integration, measure-valued differential equation, rejection-free, Some key words: Bayesian inference},
	file = {Nishimura, Dunson, Lu - Unknown - Discontinuous Hamiltonian Monte Carlo for discrete parameters and discontinuous likelihoods:/Users/jamesscott/Zotero/storage/I9HWZYEK/Nishimura, Dunson, Lu - Unknown - Discontinuous Hamiltonian Monte Carlo for discrete parameters and discontinuous likelihoods.pdf:application/pdf},
}

@techreport{zhang_continuous_nodate,
	title = {Continuous {Relaxations} for {Discrete} {Hamiltonian} {Monte} {Carlo}},
	url = {https://papers.nips.cc/paper/4652-continuous-relaxations-for-discrete-hamiltonian-monte-carlo.pdf},
	abstract = {Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difficult discrete systems. We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems.},
	author = {Zhang, Yichuan and Sutton, Charles and Storkey, Amos and Ghahramani, Zoubin},
	file = {Zhang et al. - Unknown - Continuous Relaxations for Discrete Hamiltonian Monte Carlo:/Users/jamesscott/Zotero/storage/DPYXP9RF/Zhang et al. - Unknown - Continuous Relaxations for Discrete Hamiltonian Monte Carlo.pdf:application/pdf},
}

@techreport{zanella_informed_2017,
	title = {Informed proposals for local {MCMC} in discrete spaces},
	url = {https://arxiv.org/pdf/1711.07424.pdf},
	abstract = {There is a lack of methodological results to design efficient Markov chain Monte Carlo (MCMC) algorithms for statistical models with discrete-valued high-dimensional parameters. Motivated by this consideration, we propose a simple framework for the design of informed MCMC proposals (i.e. Metropolis-Hastings proposal distributions that appropriately incorporate local information about the target) which is naturally applicable to both discrete and continuous spaces. We explicitly characterize the class of optimal proposal distributions under this framework, which we refer to as locally-balanced proposals, and prove their Peskun-optimality in high-dimensional regimes. The resulting algorithms are straightforward to implement in discrete spaces and provide orders of magnitude improvements in efficiency compared to alternative MCMC schemes, including discrete versions of Hamiltonian Monte Carlo. Simulations are performed with both simulated and real datasets, including a detailed application to Bayesian record linkage. A direct connection with gradient-based MCMC suggests that locally-balanced proposals may be seen as a natural way to extend the latter to discrete spaces.},
	number = {1711.07424v1},
	author = {Zanella, Giacomo},
	year = {2017},
	file = {Zanella - 2017 - Informed proposals for local MCMC in discrete spaces:/Users/jamesscott/Zotero/storage/M6IIWW2L/Zanella - 2017 - Informed proposals for local MCMC in discrete spaces.pdf:application/pdf},
}

@article{titsias_hamming_2017,
	title = {The {Hamming} {Ball} {Sampler}},
	volume = {112},
	url = {https://amstat.tandfonline.com/action/journalInformation?journalCode=uasa20http://dx.doi.org/./..},
	doi = {10.1080/01621459.2016.1222288},
	abstract = {We introduce the Hamming ball sampler, a novel Markov chain Monte Carlo algorithm, for efficient inference in statistical models involving high-dimensional discrete state spaces. The sampling scheme uses an auxiliary variable construction that adaptively truncates the model space allowing iterative exploration of the full model space. The approach generalizes conventional Gibbs sampling schemes for discrete spaces and provides an intuitive means for user-controlled balance between statistical efficiency and computational tractability. We illustrate the generic utility of our sampling algorithm through application to a range of statistical models. Supplementary materials for this article are available online.},
	number = {520},
	journal = {JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION YEAR},
	author = {Titsias, Michalis K and Yau, Christopher},
	year = {2017},
	keywords = {Markov chain Monte Carlo, Bayesian, Discrete state spaces},
	pages = {1598--1611},
	file = {Titsias, Yau - 2017 - The Hamming Ball Sampler:/Users/jamesscott/Zotero/storage/TYI8AS34/Titsias, Yau - 2017 - The Hamming Ball Sampler.pdf:application/pdf},
}

@techreport{eberle_quantitative_2018,
	title = {{QUANTITATIVE} {CONTRACTION} {RATES} {FOR} {MARKOV} {CHAINS} {ON} {GENERAL} {STATE} {SPACES}},
	url = {https://arxiv.org/pdf/1808.07033.pdf},
	abstract = {We investigate the problem of quantifying contraction coefficients of Markov transition kernels in Kantorovich (L 1 Wasserstein) distances. For diffusion processes, relatively precise quantitative bounds on contraction rates have recently been derived by combining appropriate couplings with carefully designed Kantorovich distances. In this paper, we partially carry over this approach from diffusions to Markov chains. We derive quantitative lower bounds on contraction rates for Markov chains on general state spaces that are powerful if the dynamics is dominated by small local moves. For Markov chains on R d with isotropic transition kernels, the general bounds can be used efficiently together with a coupling that combines maximal and reflection coupling. The results are applied to Euler discretizations of stochastic differential equations with non-globally contractive drifts, and to the Metropolis adjusted Langevin algorithm for sampling from a class of probability measures on high dimensional state spaces that are not globally log-concave.},
	author = {Eberle, Andreas and Majka, Mateusz B},
	year = {2018},
	file = {Eberle, Majka - 2018 - QUANTITATIVE CONTRACTION RATES FOR MARKOV CHAINS ON GENERAL STATE SPACES:/Users/jamesscott/Zotero/storage/TM62SB2P/Eberle, Majka - 2018 - QUANTITATIVE CONTRACTION RATES FOR MARKOV CHAINS ON GENERAL STATE SPACES.pdf:application/pdf},
}

@techreport{heng_unbiased_2018-1,
	title = {Unbiased {Hamiltonian} {Monte} {Carlo} with couplings},
	url = {https://arxiv.org/pdf/1709.00404.pdf},
	abstract = {We propose a methodology to parallelize Hamiltonian Monte Carlo estimators. Our approach constructs a pair of Hamiltonian Monte Carlo chains that are coupled in such a way that they meet exactly after some random number of iterations. These chains can then be combined so that resulting estimators are unbiased. This allows us to produce independent replicates in parallel and average them to obtain estimators that are consistent in the limit of the number of replicates, instead of the usual limit of the number of Markov chain iterations. We investigate the scalability of our coupling in high dimensions on a toy example. The choice of algorithmic parameters and the efficiency of our proposed methodology are then illustrated on a logistic regression with 300 covariates, and a log-Gaussian Cox point processes model with low to fine grained discretizations.},
	author = {Heng, Jeremy and Jacob, Pierre E},
	year = {2018},
	keywords = {Hamiltonian Monte Carlo, Unbiased estimation, Coupling, Parallel computing},
	file = {Heng, Jacob - 2018 - Unbiased Hamiltonian Monte Carlo with couplings:/Users/jamesscott/Zotero/storage/4HZLKPPF/Heng, Jacob - 2018 - Unbiased Hamiltonian Monte Carlo with couplings.pdf:application/pdf},
}

@techreport{jacob_unbiased_2018-1,
	title = {Unbiased {Markov} chain {Monte} {Carlo} with couplings},
	url = {https://arxiv.org/pdf/1708.03625.pdf},
	abstract = {Markov chain Monte Carlo (MCMC) methods provide consistent approximations of integrals as the number of iterations goes to infinity. MCMC estimators are generally biased after any fixed number of iterations, which complicates both parallel computation and the construction of confidence intervals. We propose to remove this bias by using couplings of Markov chains together with a telescopic sum argument of Glynn and Rhee (2014). The resulting unbiased estimators can be computed independently on parallel processors. We discuss practical couplings for popular MCMC algorithms. We establish the theoretical validity of the proposed estimators and study their efficiency relative to the underlying MCMC algorithms. Finally, we illustrate the performance and limitations of the method on toy examples, on an Ising model around its critical temperature, on a high-dimensional variable selection problem, and on an approximation of the cut distribution arising in Bayesian inference for models made of multiple modules.},
	author = {Jacob, Pierre E and O'leary, John and Atchadé, Yves F},
	year = {2018},
	file = {Jacob, O'leary, Atchadé - 2018 - Unbiased Markov chain Monte Carlo with couplings:/Users/jamesscott/Zotero/storage/HP9NKIVS/Jacob, O'leary, Atchadé - 2018 - Unbiased Markov chain Monte Carlo with couplings.pdf:application/pdf},
}

@techreport{ben-ari_efficient_nodate,
	title = {Efficient {Coupling} for {Random} {Walk} with {Redistribution}},
	url = {https://arxiv.org/pdf/1410.8234.pdf},
	abstract = {What can one say on convergence to stationarity of a finite state Markov chain that behaves "locally" like a nearest neighbor random walk on Z ? The model we consider is a version of nearest neighbor lazy random walk on the state space \{0,. .. , N \}: the probability for staying put at each site is 1 2 , the transition to the nearest neighbors, one on the right and one on the left, occurs with probability 1 4 each, where we identify two sites, J 0 and J N as, respectively, the neighbor of 0 from the left and the neighbor of N from the right (but 0 is not a neighbor of J 0 and N is not neighbor of J N). This model is a discrete version of diffusion with redistribution on an interval studied by several authors in the recent past, and for which the exponential rates of convergence to stationarity was computed analytically, but had no intuitive or probabilis-tic interpretation, except for case where the jumps from the endpoints are identical (or more generally have the same distribution). We study convergence to stationarity probabilistically, by finding an efficient coupling. The coupling identifies the "bottlenecks" responsible for the rates of convergence and also gives tight computable bounds on the total variation norm of the process between two starting points. The adaptation to the diffusion case is straightforward.},
	author = {Ben-Ari, Iddo and Panzo, Hugo and Tripp, Elizabeth},
	file = {Ben-Ari, Panzo, Tripp - Unknown - Efficient Coupling for Random Walk with Redistribution:/Users/jamesscott/Zotero/storage/Z45SX2EJ/Ben-Ari, Panzo, Tripp - Unknown - Efficient Coupling for Random Walk with Redistribution.pdf:application/pdf},
}

@techreport{burdzy_efficient_2005,
	title = {Efficient {Markovian} couplings: examples and counterexamples},
	url = {https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/2199/burdzy.pdf?sequence=1},
	abstract = {In this paper we study the notion of an efficient coupling of Markov processes. Informally, an efficient coupling is one which couples at the maximum possible exponential rate, as given by the spectral gap. This notion is of interest not only for its own sake, but also of growing importance arising from the recent advent of methods of "perfect simulation": it helps to establish the "price of perfection" for such methods. In general one can always achieve efficient coupling if the coupling is allowed to "cheat" (if each component's behaviour is affected by future behaviour of the other component), but the situation is more interesting if the coupling is required to be co-adapted. We present an informal heuristic for the existence of an efficient coupling, and justify the heuristic by proving rigorous results and examples in the contexts of finite reversible Markov chains and of reflecting Brownian motion in planar domains.},
	author = {Burdzy, Krzysztof and Kendall, Wilfrid S},
	year = {2005},
	keywords = {exact simulation, Markov chain, 60H30, 65U05, Chen-optimal coupling, co-adapted coupling, coupling exponent, diffusion, efficient coupling, efficient coupling heuris-tic, mirror coupling, monotonic-ity, perfect simulation, price of perfection, reflecting Brownian motion, spectral gap, synchronous coupling AMS Subject Classification: 60J27},
	file = {Burdzy, Kendall - 2005 - Efficient Markovian couplings examples and counterexamples:/Users/jamesscott/Zotero/storage/XJASK8DY/Burdzy, Kendall - 2005 - Efficient Markovian couplings examples and counterexamples.pdf:application/pdf},
}

@article{noauthor_parallel_nodate,
	title = {Parallel {MCMCMC} for {Bayesian} {Phylogenetic} {Inference}},
	url = {https://watermark.silverchair.com/btg427.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAlkwggJVBgkqhkiG9w0BBwagggJGMIICQgIBADCCAjsGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMBavIjCu_Ff5yMgR2AgEQgIICDLq5EjT0z9764_lGBaW-ClLIxf3Vl_s2mU8jdiAFyJpBOYJN},
}

@techreport{hsu_maximal_nodate,
	title = {{MAXIMAL} {COUPLING} {OF} {EUCLIDEAN} {BROWNIAN} {MOTIONS}},
	url = {https://sites.math.northwestern.edu/~ehsu/CouplingNewVersion.pdf},
	abstract = {We prove that the mirror coupling is the unique maximal Markovian coupling of two Euclidean Brownian motions starting from single points and discuss the connection between the uniqueness problems of Brownian coupling and mass transportation.},
	author = {Hsu, Elton P and Sturm, Karl-Theodor},
	file = {Hsu, Sturm - Unknown - MAXIMAL COUPLING OF EUCLIDEAN BROWNIAN MOTIONS:/Users/jamesscott/Zotero/storage/U6UECWTA/Hsu, Sturm - Unknown - MAXIMAL COUPLING OF EUCLIDEAN BROWNIAN MOTIONS.pdf:application/pdf},
}

@techreport{neal_annealed_1998,
	title = {Annealed {Importance} {Sampling}},
	url = {http://www.cs.utoronto.ca/∼radford/},
	abstract = {Simulated annealing-moving from a tractable distribution to a distribution of interest via a sequence of intermediate distributions-has traditionally been used as an inexact method of handling isolated modes in Markov chain samplers. Here, it is shown how one can use the Markov chain transitions for such an annealing sequence to define an importance sampler. The Markov chain aspect allows this method to perform acceptably even for high-dimensional problems, where finding good importance sampling distributions would otherwise be very difficult, while the use of importance weights ensures that the estimates found converge to the correct values as the number of annealing runs increases. This annealed importance sampling procedure resembles the second half of the previously-studied tempered transitions, and can be seen as a generalization of a recently-proposed variant of sequential importance sampling. It is also related to thermodynamic integration methods for estimating ratios of normalizing constants. Annealed importance sampling is most attractive when isolated modes are present, or when estimates of normalizing constants are required, but it may also be more generally useful, since its independent sampling allows one to bypass some of the problems of assessing convergence and autocorrelation in Markov chain samplers.},
	author = {Neal, Radford M},
	year = {1998},
	file = {Neal - 1998 - Annealed Importance Sampling:/Users/jamesscott/Zotero/storage/AD9FD378/Neal - 1998 - Annealed Importance Sampling.pdf:application/pdf},
}

@article{newman_random_2001,
	title = {Random {Graphs} with {Arbitrary} {Degree} {Distributions} and their {Applications}},
	volume = {64},
	url = {https://journals.aps.org/pre/pdf/10.1103/PhysRevE.64.026118},
	doi = {10.1103/PhysRevE.64.026118},
	abstract = {Recent work on the structure of social networks and the internet has focused attention on graphs with distributions of vertex degree that are significantly different from the Poisson degree distributions that have been widely studied in the past. In this paper we develop in detail the theory of random graphs with arbitrary degree distributions. In addition to simple undirected, unipartite graphs, we examine the properties of directed and bipartite graphs. Among other results, we derive exact expressions for the position of the phase transition at which a giant component first forms, the mean component size, the size of the giant component if there is one, the mean number of vertices a certain distance away from a randomly chosen vertex, and the average vertex-vertex distance within a graph. We apply our theory to some real-world graphs, including the worldwide web and collaboration graphs of scientists and Fortune 1000 company directors. We demonstrate that in some cases random graphs with appropriate distributions of vertex degree predict with surprising accuracy the behavior of the real world, while in others there is a measurable discrepancy between theory and reality, perhaps indicating the presence of additional social structure in the network that is not captured by the random graph.},
	journal = {Physical Review, E},
	author = {Newman, M E J and Strogatz, S H and Watts, D J},
	year = {2001},
	pages = {1--17},
	file = {Newman, Strogatz, Watts - 2001 - Random Graphs with Arbitrary Degree Distributions and their Applications:/Users/jamesscott/Zotero/storage/A2S3X5N3/Newman, Strogatz, Watts - 2001 - Random Graphs with Arbitrary Degree Distributions and their Applications.pdf:application/pdf},
}

@article{squartini_reciprocity_2013,
	title = {Reciprocity of {Weighted} {Networks}},
	volume = {3},
	url = {www.nature.com/scientificreports},
	doi = {10.1038/srep02729},
	abstract = {All types of networks arise as intricate combinations of dyadic building blocks formed by pairs of vertices. In directed networks, the dyadic patterns are entirely determined by reciprocity, i.e. the tendency to form, or to avoid, mutual links. Reciprocity has dramatic effects on every networks dynamical processes and the emergence of structures like motifs and communities. The binary reciprocity has been extensively studied: that of weighted networks is still poorly understood. We introduce a general approach to it, by defining quantities capturing the observed patterns (from dyad-specific to vertex-specific and network-wide) and introducing analytically solved models (Exponential Random Graphs-type). Counter-intuitively, the previous reciprocity measures based on the similarity of the mutual links-weights are uninformative. By contrast, our measures can classify different weighted networks, track the temporal evolution of a networks reciprocity, identify patterns. We show that in some networks the local reciprocity structure can be inferred from the global one.},
	journal = {Scientific Reports},
	author = {Squartini, Tiziano and Picciolo, Francesco and Ruzzenenti, Franco and Garlaschelli, Diego},
	year = {2013},
	file = {Squartini et al. - 2013 - Reciprocity of Weighted Networks:/Users/jamesscott/Zotero/storage/S3QA8ILC/Squartini et al. - 2013 - Reciprocity of Weighted Networks.pdf:application/pdf},
}

@techreport{hayes_variable_nodate,
	title = {Variable {Length} {Path} {Coupling}},
	url = {http://people.cs.uchicago.edu/~hayest/papers/VariableLengthPathCoupling/VariableLengthPathCoupling-SODA04.pdf},
	abstract = {We present a new technique for constructing and analyzing couplings to bound the convergence rate of finite Markov chains. Our main theorem is a generalization of the path coupling theorem of Bubley and Dyer, allowing the defining partial couplings to have length determined by a random stopping time. Unlike the original path coupling theorem, our version can produce multi-step (non-Markovian) couplings. Using our variable length path coupling theorem, we improve the upper bound on the mixing time of the Glauber dynamics for randomly sampling colorings.},
	author = {Hayes, Thomas P and Vigoda, Eric},
	file = {Hayes, Vigoda - Unknown - Variable Length Path Coupling:/Users/jamesscott/Zotero/storage/425A5XHY/Hayes, Vigoda - Unknown - Variable Length Path Coupling.pdf:application/pdf},
}

@techreport{neal_annealed_1998-1,
	title = {Annealed {Importance} {Sampling}},
	url = {http://www.cs.utoronto.ca/∼radford/},
	abstract = {Simulated annealing-moving from a tractable distribution to a distribution of interest via a sequence of intermediate distributions-has traditionally been used as an inexact method of handling isolated modes in Markov chain samplers. Here, it is shown how one can use the Markov chain transitions for such an annealing sequence to define an importance sampler. The Markov chain aspect allows this method to perform acceptably even for high-dimensional problems, where finding good importance sampling distributions would otherwise be very difficult, while the use of importance weights ensures that the estimates found converge to the correct values as the number of annealing runs increases. This annealed importance sampling procedure resembles the second half of the previously-studied tempered transitions, and can be seen as a generalization of a recently-proposed variant of sequential importance sampling. It is also related to thermodynamic integration methods for estimating ratios of normalizing constants. Annealed importance sampling is most attractive when isolated modes are present, or when estimates of normalizing constants are required, but it may also be more generally useful, since its independent sampling allows one to bypass some of the problems of assessing convergence and autocorrelation in Markov chain samplers.},
	urldate = {2019-04-30},
	author = {Neal, Radford M},
	year = {1998},
	file = {PDF:/Users/jamesscott/Zotero/storage/RGV4ARDX/full-text.pdf:application/pdf},
}

@techreport{hsu_maximal_nodate-1,
	title = {{MAXIMAL} {COUPLING} {OF} {EUCLIDEAN} {BROWNIAN} {MOTIONS}},
	abstract = {We prove that the mirror coupling is the unique maximal Markovian coupling of two Euclidean Brownian motions starting from single points and discuss the connection between the uniqueness problems of Brownian coupling and mass transportation.},
	urldate = {2019-04-30},
	author = {Hsu, Elton P and Sturm, Karl-Theodor},
	file = {PDF:/Users/jamesscott/Zotero/storage/VS5Q4GW3/full-text.pdf:application/pdf},
}

@article{noauthor_parallel_nodate-1,
	title = {Parallel {MCMCMC} for {Bayesian} {Phylogenetic} {Inference}},
	urldate = {2019-04-30},
}

@techreport{burdzy_efficient_2005-1,
	title = {Efficient {Markovian} couplings: examples and counterexamples},
	abstract = {In this paper we study the notion of an efficient coupling of Markov processes. Informally, an efficient coupling is one which couples at the maximum possible exponential rate, as given by the spectral gap. This notion is of interest not only for its own sake, but also of growing importance arising from the recent advent of methods of "perfect simulation": it helps to establish the "price of perfection" for such methods. In general one can always achieve efficient coupling if the coupling is allowed to "cheat" (if each component's behaviour is affected by future behaviour of the other component), but the situation is more interesting if the coupling is required to be co-adapted. We present an informal heuristic for the existence of an efficient coupling, and justify the heuristic by proving rigorous results and examples in the contexts of finite reversible Markov chains and of reflecting Brownian motion in planar domains.},
	urldate = {2019-04-30},
	author = {Burdzy, Krzysztof and Kendall, Wilfrid S},
	year = {2005},
	keywords = {exact simulation, Markov chain, 60H30, 65U05, Chen-optimal coupling, co-adapted coupling, coupling exponent, diffusion, efficient coupling, efficient coupling heuris-tic, mirror coupling, monotonic-ity, perfect simulation, price of perfection, reflecting Brownian motion, spectral gap, synchronous coupling AMS Subject Classification: 60J27},
	file = {PDF:/Users/jamesscott/Zotero/storage/E9PJJSXE/full-text.pdf:application/pdf},
}

@techreport{ben-ari_efficient_nodate-1,
	title = {Efficient {Coupling} for {Random} {Walk} with {Redistribution}},
	abstract = {What can one say on convergence to stationarity of a finite state Markov chain that behaves "locally" like a nearest neighbor random walk on Z ? The model we consider is a version of nearest neighbor lazy random walk on the state space \{0,. .. , N \}: the probability for staying put at each site is 1 2 , the transition to the nearest neighbors, one on the right and one on the left, occurs with probability 1 4 each, where we identify two sites, J 0 and J N as, respectively, the neighbor of 0 from the left and the neighbor of N from the right (but 0 is not a neighbor of J 0 and N is not neighbor of J N). This model is a discrete version of diffusion with redistribution on an interval studied by several authors in the recent past, and for which the exponential rates of convergence to stationarity was computed analytically, but had no intuitive or probabilis-tic interpretation, except for case where the jumps from the endpoints are identical (or more generally have the same distribution). We study convergence to stationarity probabilistically, by finding an efficient coupling. The coupling identifies the "bottlenecks" responsible for the rates of convergence and also gives tight computable bounds on the total variation norm of the process between two starting points. The adaptation to the diffusion case is straightforward.},
	urldate = {2019-04-30},
	author = {Ben-Ari, Iddo and Panzo, Hugo and Tripp, Elizabeth},
	file = {PDF:/Users/jamesscott/Zotero/storage/BJJAXKU9/full-text.pdf:application/pdf},
}

@techreport{jacob_unbiased_2018-2,
	title = {Unbiased {Markov} chain {Monte} {Carlo} with couplings},
	abstract = {Markov chain Monte Carlo (MCMC) methods provide consistent approximations of integrals as the number of iterations goes to infinity. MCMC estimators are generally biased after any fixed number of iterations, which complicates both parallel computation and the construction of confidence intervals. We propose to remove this bias by using couplings of Markov chains together with a telescopic sum argument of Glynn and Rhee (2014). The resulting unbiased estimators can be computed independently on parallel processors. We discuss practical couplings for popular MCMC algorithms. We establish the theoretical validity of the proposed estimators and study their efficiency relative to the underlying MCMC algorithms. Finally, we illustrate the performance and limitations of the method on toy examples, on an Ising model around its critical temperature, on a high-dimensional variable selection problem, and on an approximation of the cut distribution arising in Bayesian inference for models made of multiple modules.},
	urldate = {2019-04-30},
	author = {Jacob, Pierre E and O'leary, John and Atchadé, Yves F},
	year = {2018},
	file = {PDF:/Users/jamesscott/Zotero/storage/JCUHBT8U/full-text.pdf:application/pdf},
}

@techreport{heng_unbiased_2018-2,
	title = {Unbiased {Hamiltonian} {Monte} {Carlo} with couplings},
	abstract = {We propose a methodology to parallelize Hamiltonian Monte Carlo estimators. Our approach constructs a pair of Hamiltonian Monte Carlo chains that are coupled in such a way that they meet exactly after some random number of iterations. These chains can then be combined so that resulting estimators are unbiased. This allows us to produce independent replicates in parallel and average them to obtain estimators that are consistent in the limit of the number of replicates, instead of the usual limit of the number of Markov chain iterations. We investigate the scalability of our coupling in high dimensions on a toy example. The choice of algorithmic parameters and the efficiency of our proposed methodology are then illustrated on a logistic regression with 300 covariates, and a log-Gaussian Cox point processes model with low to fine grained discretizations.},
	urldate = {2019-04-30},
	author = {Heng, Jeremy and Jacob, Pierre E},
	year = {2018},
	keywords = {Hamiltonian Monte Carlo, Unbiased estimation, Coupling, Parallel computing},
	file = {PDF:/Users/jamesscott/Zotero/storage/GC9K6RXR/full-text.pdf:application/pdf},
}

@techreport{eberle_quantitative_2018-1,
	title = {{QUANTITATIVE} {CONTRACTION} {RATES} {FOR} {MARKOV} {CHAINS} {ON} {GENERAL} {STATE} {SPACES}},
	abstract = {We investigate the problem of quantifying contraction coefficients of Markov transition kernels in Kantorovich (L 1 Wasserstein) distances. For diffusion processes, relatively precise quantitative bounds on contraction rates have recently been derived by combining appropriate couplings with carefully designed Kantorovich distances. In this paper, we partially carry over this approach from diffusions to Markov chains. We derive quantitative lower bounds on contraction rates for Markov chains on general state spaces that are powerful if the dynamics is dominated by small local moves. For Markov chains on R d with isotropic transition kernels, the general bounds can be used efficiently together with a coupling that combines maximal and reflection coupling. The results are applied to Euler discretizations of stochastic differential equations with non-globally contractive drifts, and to the Metropolis adjusted Langevin algorithm for sampling from a class of probability measures on high dimensional state spaces that are not globally log-concave.},
	urldate = {2019-04-30},
	author = {Eberle, Andreas and Majka, Mateusz B},
	year = {2018},
	file = {PDF:/Users/jamesscott/Zotero/storage/X2HTMA68/full-text.pdf:application/pdf},
}

@article{titsias_hamming_2017-1,
	title = {The {Hamming} {Ball} {Sampler}},
	volume = {112},
	issn = {0162-1459},
	url = {https://amstat.tandfonline.com/action/journalInformation?journalCode=uasa20http://dx.doi.org/./..},
	doi = {10.1080/01621459.2016.1222288},
	abstract = {We introduce the Hamming ball sampler, a novel Markov chain Monte Carlo algorithm, for efficient inference in statistical models involving high-dimensional discrete state spaces. The sampling scheme uses an auxiliary variable construction that adaptively truncates the model space allowing iterative exploration of the full model space. The approach generalizes conventional Gibbs sampling schemes for discrete spaces and provides an intuitive means for user-controlled balance between statistical efficiency and computational tractability. We illustrate the generic utility of our sampling algorithm through application to a range of statistical models. Supplementary materials for this article are available online.},
	number = {520},
	urldate = {2019-04-30},
	journal = {JOURNAL OF THE AMERICAN STATISTICAL ASSOCIATION YEAR},
	author = {Titsias, Michalis K and Yau, Christopher},
	year = {2017},
	keywords = {Markov chain Monte Carlo, Bayesian, Discrete state spaces},
	pages = {1598--1611},
	file = {PDF:/Users/jamesscott/Zotero/storage/FIS2CCHJ/full-text.pdf:application/pdf},
}

@techreport{zanella_informed_2017-1,
	title = {Informed proposals for local {MCMC} in discrete spaces},
	abstract = {There is a lack of methodological results to design efficient Markov chain Monte Carlo (MCMC) algorithms for statistical models with discrete-valued high-dimensional parameters. Motivated by this consideration, we propose a simple framework for the design of informed MCMC proposals (i.e. Metropolis-Hastings proposal distributions that appropriately incorporate local information about the target) which is naturally applicable to both discrete and continuous spaces. We explicitly characterize the class of optimal proposal distributions under this framework, which we refer to as locally-balanced proposals, and prove their Peskun-optimality in high-dimensional regimes. The resulting algorithms are straightforward to implement in discrete spaces and provide orders of magnitude improvements in efficiency compared to alternative MCMC schemes, including discrete versions of Hamiltonian Monte Carlo. Simulations are performed with both simulated and real datasets, including a detailed application to Bayesian record linkage. A direct connection with gradient-based MCMC suggests that locally-balanced proposals may be seen as a natural way to extend the latter to discrete spaces.},
	urldate = {2019-04-30},
	author = {Zanella, Giacomo},
	year = {2017},
	note = {ISBN: 1711.07424v1},
	file = {PDF:/Users/jamesscott/Zotero/storage/UMJPT3Q2/full-text.pdf:application/pdf},
}

@techreport{zhang_continuous_nodate-1,
	title = {Continuous {Relaxations} for {Discrete} {Hamiltonian} {Monte} {Carlo}},
	abstract = {Continuous relaxations play an important role in discrete optimization, but have not seen much use in approximate probabilistic inference. Here we show that a general form of the Gaussian Integral Trick makes it possible to transform a wide class of discrete variable undirected models into fully continuous systems. The continuous representation allows the use of gradient-based Hamiltonian Monte Carlo for inference, results in new ways of estimating normalization constants (partition functions), and in general opens up a number of new avenues for inference in difficult discrete systems. We demonstrate some of these continuous relaxation inference algorithms on a number of illustrative problems.},
	urldate = {2019-04-30},
	author = {Zhang, Yichuan and Sutton, Charles and Storkey, Amos and Ghahramani, Zoubin},
	file = {PDF:/Users/jamesscott/Zotero/storage/EPRUQU8L/full-text.pdf:application/pdf},
}

@techreport{nishimura_discontinuous_nodate-1,
	title = {Discontinuous {Hamiltonian} {Monte} {Carlo} for discrete parameters and discontinuous likelihoods},
	abstract = {Hamiltonian Monte Carlo has emerged as a standard tool for posterior computation. In this article , we present an extension that can efficiently explore target distributions with discontinuous densities, which in turn enables efficient sampling from ordinal parameters though embedding of probability mass functions into continuous spaces. We motivate our approach through a theory of discontinuous Hamiltonian dynamics and develop a corresponding numerical solver. The proposed solver is the first of its kind, with a remarkable ability to exactly preserve the Hamiltonian and thus yield a type of rejection-free proposal. We apply our algorithm to challenging posterior inference problems to demonstrate its wide applicability and competitive performance.},
	urldate = {2019-04-30},
	author = {Nishimura, Akihiko and Dunson, David B and Lu, Jianfeng},
	keywords = {Markov chain Monte Carlo, geometric numerical integration, measure-valued differential equation, rejection-free, Some key words: Bayesian inference},
	file = {PDF:/Users/jamesscott/Zotero/storage/RHVWFDQP/full-text.pdf:application/pdf},
}

@techreport{pakman_auxiliary-variable_nodate-1,
	title = {Auxiliary-variable {Exact} {Hamiltonian} {Monte} {Carlo} {Samplers} for {Binary} {Distributions}},
	abstract = {We present a new approach to sample from generic binary distributions, based on an exact Hamiltonian Monte Carlo algorithm applied to a piecewise continuous augmentation of the binary distribution of interest. An extension of this idea to distributions over mixtures of binary and possibly-truncated Gaussian or exponential variables allows us to sample from posteriors of linear and probit regression models with spike-and-slab priors and truncated parameters. We illustrate the advantages of these algorithms in several examples in which they outperform the Metropolis or Gibbs samplers.},
	urldate = {2019-04-30},
	author = {Pakman, Ari and Paninski, Liam},
	file = {PDF:/Users/jamesscott/Zotero/storage/ZZ3JLTKI/full-text.pdf:application/pdf},
}

@inproceedings{hayes_non-markovian_nodate-1,
	title = {A non-{Markovian} coupling for randomly sampling colorings},
	isbn = {0-7695-2040-5},
	url = {http://ieeexplore.ieee.org/document/1238234/},
	doi = {10.1109/SFCS.2003.1238234},
	urldate = {2019-04-30},
	booktitle = {44th {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science}, 2003. {Proceedings}.},
	publisher = {IEEE Computer. Soc},
	author = {Hayes, T.P. and Vigoda, E.},
	pages = {618--627},
}

@techreport{hayes_variable_2006-1,
	title = {Variable {Length} {Path} {Coupling}},
	abstract = {We present a new technique for constructing and analyzing couplings to bound the convergence rate of finite Markov chains. Our main theorem is a generalization of the path coupling theorem of Bub-ley and Dyer, allowing the defining partial couplings to have length determined by a random stopping time. Unlike the original path coupling theorem, our version can produce multi-step (non-Markovian) couplings. Using our variable length path coupling theorem, we improve the upper bound on the mixing time of the Glauber dynamics for randomly sampling colorings.},
	urldate = {2019-04-30},
	author = {Hayes, Thomas P and Vigoda, Eric},
	year = {2006},
	file = {PDF:/Users/jamesscott/Zotero/storage/YUEXLXLF/full-text.pdf:application/pdf},
}

@article{smith_gibbs_2014-1,
	title = {A {GIBBS} {SAMPLER} {ON} {THE} n-{SIMPLEX}},
	volume = {24},
	doi = {10.1214/12-AAP916},
	abstract = {We determine the mixing time of a simple Gibbs sampler on the unit simplex, confirming a conjecture of Aldous. The upper bound is based on a two-step coupling, where the first step is a simple contraction argument and the second step is a non-Markovian coupling. We also present a MCMC-based perfect sampling algorithm based on our proof which can be applied with Gibbs samplers that are harder to analyze.},
	number = {1},
	urldate = {2019-04-30},
	journal = {The Annals of Applied Probability},
	author = {Smith, Aaron},
	year = {2014},
	keywords = {Gibbs sampler, perfect sampling, 60J10, 65C04, Markov chain},
	pages = {114--130},
	file = {PDF:/Users/jamesscott/Zotero/storage/BXJDV268/full-text.pdf:application/pdf},
}

@techreport{cappello_sequential_2019-1,
	title = {Sequential importance sampling for multi-resolution {Kingman}-{Tajima} coalescent counting},
	abstract = {Statistical inference of evolutionary parameters from molecular sequence data relies on coalescent models to account for the shared genealogical ancestry of the samples. However , inferential algorithms do not scale to available data sets. A strategy to improve computational efficiency is to rely on simpler coalescent and mutation models, resulting in smaller hidden state spaces. An estimate of the cardinality of the state-space of genealogi-cal trees at different resolutions is essential to decide the best modeling strategy for a given dataset. To our knowledge, there is neither an exact nor approximate method to determine these cardinalities. We propose a sequential importance sampling algorithm to estimate the cardinality of the space of genealogical trees under different coalescent resolutions. Our sampling scheme proceeds sequentially across the set of combinatorial constraints imposed by the data. We analyse the cardinality of different genealogical tree spaces on simulations to study the settings that favor coarser resolutions. We estimate the cardinality of genealogical tree spaces from mtDNA data from the 1000 genomes and a sample from a Melanesian population to illustrate the settings in which it is advantageous to employ coarser resolutions.},
	urldate = {2019-04-30},
	author = {Cappello, Lorenzo and Palacios, Julia A},
	year = {2019},
	file = {PDF:/Users/jamesscott/Zotero/storage/ADIR74LA/full-text.pdf:application/pdf},
}

@techreport{desalvo_random_2016-1,
	title = {Random {Sampling} of {Contingency} {Tables} via {Probabilistic} {Divide}-and-{Conquer}},
	abstract = {We present a new approach for random sampling of contingency tables of any size and constraints based on a recently introduced probabilistic divide-and-conquer technique. A simple exact sampling algorithm is presented for 2 × n tables, as well as a generalization where each entry of the table has a specified marginal distribution. MSC 2010 subject classifications: Primary 62H17; secondary 60C05, 52B99.},
	urldate = {2019-04-30},
	author = {Desalvo, Stephen and Zhao, James Y},
	year = {2016},
	keywords = {exact sampling, 52B99contingency tables, 60C05, 62H17, probabilistic divide-and-conquer, transportation polytope},
	file = {PDF:/Users/jamesscott/Zotero/storage/NYLP5VEA/full-text.pdf:application/pdf},
}

@techreport{brubaker_family_2012-1,
	title = {A {Family} of {MCMC} {Methods} on {Implicitly} {Defined} {Manifolds}},
	abstract = {Traditional MCMC methods are only applicable to distributions defined on R n. However , there exist many application domains where the distributions cannot easily be defined on a Euclidean space. To address this limitation, we propose a general constrained version of Hamiltonian Monte Carlo, and give conditions under which the Markov chain is convergent. Based on this general framework we define a family of MCMC methods which can be applied to sample from distributions on non-linear manifolds. We demonstrate the effectiveness of our approach on a variety of problems including sampling from the Bingham-von Mises-Fisher distribution, col-laborative filtering and pose estimation.},
	urldate = {2019-05-04},
	author = {Brubaker, Marcus A and Salzmann, Mathieu and Urtasun, Raquel},
	year = {2012},
	file = {PDF:/Users/jamesscott/Zotero/storage/QP8468LK/full-text.pdf:application/pdf},
}

@techreport{betancourt_nested_2010-1,
	title = {Nested {Sampling} with {Constrained} {Hamiltonian} {Monte} {Carlo}},
	abstract = {Nested sampling is a powerful approach to Bayesian inference ultimately limited by the computationally demanding task of sampling from a heavily constrained probability distribution. An effective algorithm in its own right, Hamiltonian Monte Carlo is readily adapted to efficiently sample from any smooth, constrained distribution. Utilizing this constrained Hamiltonian Monte Carlo, I introduce a general implementation of the nested sampling algorithm.},
	urldate = {2019-05-04},
	author = {Betancourt, Michael},
	year = {2010},
	file = {PDF:/Users/jamesscott/Zotero/storage/TG53UVBK/full-text.pdf:application/pdf},
}

@article{noauthor_one-shot_nodate-1,
	title = {One-shot coupling for certain stochastic recursive sequences},
	urldate = {2019-05-04},
}

@techreport{glynn_exact_2014-1,
	title = {{EXACT} {ESTIMATION} {FOR} {MARKOV} {CHAIN} {EQUILIBRIUM} {EXPECTATIONS}},
	abstract = {We introduce a new class of Monte Carlo methods, which we call exact estimation algorithms. Such algorithms provide unbiased estimators for equilibrium expectations associated with real-valued functionals defined on a Markov chain. We provide easily implemented algorithms for the class of positive Harris recurrent Markov chains, and for chains that are contracting on average. We further argue that exact estimation in the Markov chain setting provides a significant theoretical relaxation relative to exact simulation methods.},
	urldate = {2019-05-04},
	author = {Glynn, Peter W and Rhee, Chang-Han},
	year = {2014},
	keywords = {exact estimation, exact sampling, exact simulation, Markov chain equilibrium expectation, Markov chain stationary expectation, perfect sampling, perfect simulation 2010 Mathematics Subject Classification: Primary 65C05 Secondary 60J05, Unbiased estimation},
	file = {PDF:/Users/jamesscott/Zotero/storage/D2WQVD6V/full-text.pdf:application/pdf},
}

@techreport{bou-rabee_coupling_nodate-1,
	title = {Coupling and {Convergence} for {Hamiltonian} {Monte} {Carlo}},
	abstract = {Based on a new coupling approach, we prove that the transition step of the Hamiltonian Monte Carlo algorithm is contractive w.r.t. a carefully designed Kantorovich (L 1 Wasserstein) distance. The lower bound for the contraction rate is explicit. Global convexity of the potential is not required, and thus multimodal target distributions are included. Explicit quantitative bounds for the number of steps required to approximate the stationary distribution up to a given error are a direct consequence of con-tractivity. These bounds show that HMC can overcome diffusive behaviour if the duration of the Hamiltonian dynamics is adjusted appropriately. MSC 2010 subject classifications: Primary 60J05; Secondary 65P10, 65C05.},
	urldate = {2019-05-04},
	author = {Bou-Rabee, Nawaf and Eberle, Andreas and Zimmer, Raphael},
	keywords = {and phrases: coupling, convergence to equilibrium, geo-metric integrator, Hamiltonian Monte Carlo, Hybrid Monte Carlo, Markov Chain Monte Carlo, Metropolis-Hastings},
	file = {PDF:/Users/jamesscott/Zotero/storage/NTU2T57J/full-text.pdf:application/pdf},
}

@article{del_moral_digital_2003-1,
	title = {Digital {Object} {Identifier} ( {On} contraction properties of {Markov} kernels},
	volume = {126},
	doi = {10.1007/s00440-003-0270-6},
	abstract = {We study Lipschitz contraction properties of general Markov kernels seen as operators on spaces of probability measures equipped with entropy-like "distances". Universal quantitative bounds on the associated ergodic constants are deduced from Dobrushin's ergodic coefficient. Strong contraction properties in Orlicz spaces for relative densities are proved under more restrictive mixing assumptions. We also describe contraction bounds in the entropy sense around arbitrary probability measures by introducing a suitable Dirichlet form and the corresponding modified logarithmic Sobolev constants. The interest in these bounds is illustrated on the example of inhomogeneous Gaussian chains. In particular, the existence of an invariant measure is not required in general.},
	urldate = {2019-05-04},
	journal = {Probab. Theory Relat. Fields},
	author = {Del Moral, P and Ledoux, · M and Miclo, · L},
	year = {2003},
	pages = {395--420},
	file = {PDF:/Users/jamesscott/Zotero/storage/7N2ZDQKI/full-text.pdf:application/pdf},
}

@article{noauthor_efficient_nodate-1,
	title = {Efficient {Markovian} {Couplings}: {Examples} and {Counterexamples}},
	urldate = {2019-05-04},
}

@techreport{hayes_variable_nodate-1,
	title = {Variable {Length} {Path} {Coupling}},
	abstract = {We present a new technique for constructing and analyzing couplings to bound the convergence rate of finite Markov chains. Our main theorem is a generalization of the path coupling theorem of Bubley and Dyer, allowing the defining partial couplings to have length determined by a random stopping time. Unlike the original path coupling theorem, our version can produce multi-step (non-Markovian) couplings. Using our variable length path coupling theorem, we improve the upper bound on the mixing time of the Glauber dynamics for randomly sampling colorings.},
	urldate = {2019-05-04},
	author = {Hayes, Thomas P and Vigoda, Eric},
	file = {PDF:/Users/jamesscott/Zotero/storage/URU3TI6F/full-text.pdf:application/pdf},
}

@techreport{vanetti_piecewise-deterministic_2018-1,
	title = {Piecewise-{Deterministic} {Markov} {Chain} {Monte} {Carlo}},
	abstract = {A novel class of non-reversible Markov chain Monte Carlo schemes relying on continuous-time piecewise-deterministic Markov Processes has recently emerged. In these algorithms, the state of the Markov process evolves according to a deterministic dynamics which is modified using a Markov transition kernel at random event times. These methods enjoy remarkable features including the ability to update only a subset of the state components while other components implicitly keep evolving and the ability to use an unbiased estimate of the gradient of the log-target while preserving the target as invariant distribution. However, they also suffer from important limitations. The deterministic dynamics used so far do not exploit the structure of the target. Moreover, exact simulation of the event times is feasible for an important yet restricted class of problems and, even when it is, it is application specific. This limits the applicability of these techniques and prevents the development of a generic software implementation of them. We introduce novel MCMC methods addressing these shortcomings. In particular, we introduce novel continuous-time algorithms relying on exact Hamiltonian flows and novel non-reversible discrete-time algorithms which can exploit complex dynamics such as approximate Hamiltonian dynamics arising from symplectic integrators while preserving the attractive features of continuous-time algorithms. We demonstrate the performance of these schemes on a variety of applications.},
	urldate = {2019-05-04},
	author = {Vanetti, Paul and Bouchard-Côté, Alexandre and Deligiannidis, George and Doucet, Arnaud},
	year = {2018},
	keywords = {generalized Metropolis-Hastings, Hamiltonian dynamics, intractable likelihood, non-reversible Markov chain Monte Carlo, piecewise-deterministic Markov process, weak convergence},
	file = {PDF:/Users/jamesscott/Zotero/storage/QKG9WBWJ/full-text.pdf:application/pdf},
}

@techreport{bierkens_piecewise_2018-1,
	title = {Piecewise {Deterministic} {Markov} {Processes} for {Scalable} {Monte} {Carlo} on {Restricted} {Domains}},
	abstract = {Piecewise Deterministic Monte Carlo algorithms enable simulation from a posterior distribution, whilst only needing to access a sub-sample of data at each iteration. We show how they can be implemented in settings where the parameters live on a restricted domain.},
	urldate = {2019-05-04},
	author = {Bierkens, Joris and Bouchard-Côté, Alexandre and Doucet, Arnaud and Duncan, Andrew B and Fearnhead, Paul and Lienart, Thibaut and Roberts, Gareth and Vollmer, Sebastian J},
	year = {2018},
	file = {PDF:/Users/jamesscott/Zotero/storage/X9Q2QUW7/full-text.pdf:application/pdf},
}

@techreport{hoff_additive_2018-2,
	title = {Additive and multiplicative effects network models},
	abstract = {Network datasets typically exhibit certain types of statistical dependencies, such as within-dyad correlation, row and column heterogeneity, and third-order dependence patterns such as transitivity and clustering. The first two of these can be well-represented statistically with a social relations model, a type of additive random effects model originally developed for continuous dyadic data. Third-order patterns can be represented with multiplicative random effects models, which are related to matrix decompositions commonly used for matrix-variate data analysis. Additionally, these multiplicative random effects models generalize other popular latent variable network models, such as the stochastic blockmodel and the latent space model. In this article we review a general regression framework for the analysis of network data that combines these two types of random effects and accommodates a variety of network data types, including continuous, binary and ordinal network relations.},
	urldate = {2019-05-04},
	author = {Hoff, Peter D},
	year = {2018},
	keywords = {Bayesian, factor model, generalized linear model, latent variable, matrix decomposi-tion, mixed effects model},
	file = {PDF:/Users/jamesscott/Zotero/storage/KLMDVZ4A/full-text.pdf:application/pdf},
}

@article{squartini_2013,
	title = {Reciprocity of {Weighted} {Networks}},
	volume = {3},
	issn = {20452322},
	url = {www.nature.com/scientificreports},
	doi = {10.1038/srep02729},
	abstract = {All types of networks arise as intricate combinations of dyadic building blocks formed by pairs of vertices. In directed networks, the dyadic patterns are entirely determined by reciprocity, i.e. the tendency to form, or to avoid, mutual links. Reciprocity has dramatic effects on every networks dynamical processes and the emergence of structures like motifs and communities. The binary reciprocity has been extensively studied: that of weighted networks is still poorly understood. We introduce a general approach to it, by defining quantities capturing the observed patterns (from dyad-specific to vertex-specific and network-wide) and introducing analytically solved models (Exponential Random Graphs-type). Counter-intuitively, the previous reciprocity measures based on the similarity of the mutual links-weights are uninformative. By contrast, our measures can classify different weighted networks, track the temporal evolution of a networks reciprocity, identify patterns. We show that in some networks the local reciprocity structure can be inferred from the global one.},
	urldate = {2019-05-07},
	journal = {Scientific Reports},
	author = {Squartini, Tiziano and Picciolo, Francesco and Ruzzenenti, Franco and Garlaschelli, Diego},
	year = {2013},
	file = {PDF:/Users/jamesscott/Zotero/storage/DFHJQS63/full-text.pdf:application/pdf},
}

@article{newman_2001,
	title = {The structure of scientific collaboration networks},
	volume = {98},
	url = {http://www.pnas.org/content/98/2/404.abstract},
	doi = {10.1073/pnas.98.2.404},
	abstract = {The structure of scientific collaboration networks is investigated. Two scientists are considered connected if they have authored a paper together and explicit networks of such connections are constructed by using data drawn from a number of databases, including MEDLINE (biomedical research), the Los Alamos e-Print Archive (physics), and NCSTRL (computer science). I show that these collaboration networks form ” small worlds,” in which randomly chosen pairs of scientists are typically separated by only a short path of intermediate acquaintances. I further give results for mean and distribution of numbers of collaborators of authors, demonstrate the presence of clustering in the networks, and highlight a number of apparent differences in the patterns of collaboration between the fields studied.},
	number = {2},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Newman, M E J},
	year = {2001},
	keywords = {*file-import-18-01-19},
	pages = {404--409},
}

@article{guimera_2010,
	title = {Origin of {Compartmentalization} in {Food} {Webs}},
	volume = {91},
	number = {10},
	journal = {Ecology},
	author = {Guimerà, Roger and Stouffer, D B and Sales-Pardo, Marta and Leicht, E A and Newman, M E J and Amaral, Luis A N},
	year = {2010},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {2941--2951},
}

@article{halaj_2013,
	title = {Assessing interbank contagion using simulated networks},
	volume = {10},
	number = {2-3},
	journal = {Computational Management Science},
	author = {Hałaj, Grzegorz and Kok, Christoffer},
	year = {2013},
	note = {Publisher: Springer},
	keywords = {*file-import-18-10-01},
	pages = {157--186},
}

@misc{heng_2018,
	title = {Unbiased {Hamiltonian} {Monte} {Carlo} with couplings},
	url = {http://arxiv.org/abs/1709.00404},
	abstract = {We propose a methodology to parallelize Hamiltonian Monte Carlo estimators.
Our approach constructs a pair of Hamiltonian Monte Carlo chains that are
coupled in such a way that they meet exactly after some random number of
iterations. These chains can then be combined so that resulting estimators are
unbiased. This allows us to produce independent replicates in parallel and
average them to obtain estimators that are consistent in the limit of the
number of replicates, instead of the usual limit of the number of Markov chain
iterations. We investigate the scalability of our coupling in high dimensions
on a toy example. The choice of algorithmic parameters and the efficiency of
our proposed methodology are then illustrated on a logistic regression with 300
covariates, and a log-Gaussian Cox point processes model with low to fine
grained discretizations.},
	author = {Heng, J and Jacob, P},
	month = aug,
	year = {2018},
	annote = {arXiv:1709.00404 [stat.CO]},
}

@article{tebaldi_west_1998,
	title = {Bayesian {Inference} on {Network} {Traffic} {Using} {Link} {Count} {Data}},
	volume = {93},
	url = {http://dx.doi.org/10.1080/01621459.1998.10473707},
	doi = {10.1080/01621459.1998.10473707},
	abstract = {Abstract We study Bayesian models and methods for analysing network traffic counts in problems of inference about the traffic intensity between directed pairs of origins and destinations in networks. This is a class of problems very recently discussed by Vardi in a 1996 JASA article and is of interest in both communication and transportation network studies. The current article develops the theoretical framework of variants of the origin-destination flow problem and introduces Bayesian approaches to analysis and inference. In the first, the so-called fixed routing problem, traffic or messages pass between nodes in a network, with each message originating at a specific source node, and ultimately moving through the network to a predetermined destination node. All nodes are candidate origin and destination points. The framework assumes no travel time complications, considering only the number of messages passing between pairs of nodes in a specified time interval. The route count, or route flow, problem is to infer the set of actual number of messages passed between each directed origin-destination pair in the time interval, based on the observed counts flowing between all directed pairs of adjacent nodes. Based on some development of the theoretical structure of the problem and assumptions about prior distributional forms, we develop posterior distributions for inference on actual origin-destination counts and associated flow rates. This involves iterative simulation methods, or Markov chain Monte Carlo (MCMC), that combine Metropolis?Hastings steps within an overall Gibbs sampling framework. We discuss issues of convergence and related practical matters, and illustrate the approach in a network previously studied in Vardi's article. We explore both methodological and applied aspects much further in a concrete problem of a road network in North Carolina, studied in transportation flow assessment contexts by civil engineers. This investigation generates critical insight into limitations of statistical analysis, and particularly of non-Bayesian approaches, due to inherent structural features of the problem. A truly Bayesian approach, imposing partial stochastic constraints through informed prior distributions, offers a way of resolving these problems and is consistent with prevailing trends in updating traffic flow intensities in this field. Following this, we explore a second version of the problem that introduces elements of uncertainty about routes taken by individual messages in terms of Markov selection of outgoing links for messages at any given node. For specified route choice probabilities, we introduce the concept of a super-network?namely, a fixed routing problem in which the stochastic problem may be embedded. This leads to solution of the stochastic version of the problem using the methods developed for the original formulation of the fixed routing problem. This is also illustrated. Finally, we discuss various related issues and model extensions, including inference on stochastic route choice selection probabilities, questions of missing data and partially observed link counts, and relationships with current research on road traffic network problems in which travel times within links are nonnegligible and may be estimated from additional data.},
	number = {442},
	journal = {Journal of the American Statistical Association},
	author = {Tebaldi, Claudia and West, Mike},
	month = jun,
	year = {1998},
	note = {Publisher: Taylor \& Francis},
	pages = {557--573},
}

@article{faloutsos_1999,
	title = {On {Power}-law {Relationships} of the {Internet} {Topology}},
	volume = {29},
	url = {http://doi.acm.org/10.1145/316194.316229},
	doi = {10.1145/316194.316229},
	number = {4},
	journal = {SIGCOMM Comput. Commun. Rev.},
	author = {Faloutsos, Michalis and Faloutsos, Petros and Faloutsos, Christos},
	month = aug,
	year = {1999},
	note = {Publisher: ACM
Place: New York, NY, USA},
	keywords = {*file-import-18-01-19},
	pages = {251--262},
}

@article{castro_2004,
	title = {Network tomography: {Recent} developments},
	journal = {Statistical science},
	author = {Castro, Rui and Coates, Mark and Liang, Gang and Nowak, Robert and Yu, Bin},
	year = {2004},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-10-04},
	pages = {499--517},
}

@article{conrad_2016,
	title = {Accelerating {Asymptotically} {Exact} {MCMC} for {Computationally} {Intensive} {Models} via {Local} {Approximations}},
	volume = {111},
	url = {https://doi.org/10.1080/01621459.2015.1096787},
	doi = {10.1080/01621459.2015.1096787},
	number = {516},
	journal = {Journal of the American Statistical Association},
	author = {Conrad, Patrick R and Marzouk, Youssef M and Pillai, Natesh S and Smith, Aaron},
	year = {2016},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-09-27},
	pages = {1591--1607},
}

@article{glasserman_2016,
	title = {Contagion in {Financial} {Networks}},
	volume = {54},
	url = {http://www.aeaweb.org/articles?id=10.1257/jel.20151228},
	doi = {10.1257/jel.20151228},
	number = {3},
	journal = {Journal of Economic Literature},
	author = {Glasserman, Paul and Young, H Peyton},
	month = sep,
	year = {2016},
	keywords = {*file-import-18-01-28},
	pages = {779--831},
}

@article{jerrum_2004,
	title = {A {Polynomial}-time {Approximation} {Algorithm} for the {Permanent} of a {Matrix} with {Nonnegative} {Entries}},
	volume = {51},
	url = {http://doi.acm.org/10.1145/1008731.1008738},
	doi = {10.1145/1008731.1008738},
	number = {4},
	journal = {J. ACM},
	author = {Jerrum, Mark and Sinclair, Alistair and Vigoda, Eric},
	month = jul,
	year = {2004},
	note = {Publisher: ACM
Place: New York, NY, USA},
	keywords = {carlo, chain, markov, monte, matrix, of, *file-import-18-01-15, a, chains, mixing, permanent, rapidly},
	pages = {671--697},
}

@article{upper_2004,
	title = {Estimating bilateral exposures in the {German} interbank market: {Is} there a danger of contagion?},
	volume = {48},
	url = {http://www.sciencedirect.com/science/article/pii/S0014292104000145},
	doi = {https://doi.org/10.1016/j.euroecorev.2003.12.009},
	number = {4},
	journal = {European Economic Review},
	author = {Upper, Christian and Worms, Andreas},
	year = {2004},
	keywords = {interbank, *file-import-18-10-01, banks, contagion, market, of, regulation},
	pages = {827--849},
}

@article{squartini_2011,
	title = {Analytical maximum-likelihood method to detect patterns in real networks},
	volume = {13},
	number = {8},
	journal = {New Journal of Physics},
	author = {Squartini, Tiziano and Garlaschelli, Diego},
	year = {2011},
	note = {Publisher: IOP Publishing},
	keywords = {*file-import-18-10-01},
	pages = {83001},
}

@article{bishop_1969,
	title = {Incomplete {Two}-{Dimensional} {Contingency} {Tables}},
	volume = {25},
	number = {1},
	journal = {Biometrics},
	author = {Bishop, Yvonne M M and Fienberg, Stephen E},
	year = {1969},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {119--128},
}

@book{gelman_2013,
	title = {Bayesian data analysis},
	publisher = {Chapman and Hall/CRC},
	author = {Gelman, Andrew and Stern, Hal S and Carlin, John B and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
	year = {2013},
	keywords = {*file-import-18-10-04},
}

@article{vardi_1996,
	title = {Network {Tomography}: {Estimating} {Source}-{Destination} {Traffic} {Intensities} from {Link} {Data}},
	volume = {91},
	url = {http://dx.doi.org/10.1080/01621459.1996.10476697},
	doi = {10.1080/01621459.1996.10476697},
	abstract = {Abstract The problem of estimating the node-to-node traffic intensity from repeated measurements of traffic on the links of a network is formulated and discussed under Poisson assumptions and two types of traffic-routing regimens: deterministic (a fixed known path between each directed pair of nodes) and Markovian (a random path between each directed pair of nodes, determined according to a known Markov chain fixed for that pair). Maximum likelihood estimation and related approximations are discussed, and computational difficulties are pointed out. A detailed methodology is presented for estimates based on the method of moments. The estimates are derived algorithmically, taking advantage of the fact that the first and second moment equations give rise to a linear inverse problem with positivity restrictions that can be approached by an EM algorithm, resulting in a particularly simple solution to a hard problem. A small simulation study is carried out.},
	number = {433},
	journal = {Journal of the American Statistical Association},
	author = {Vardi, Y},
	month = mar,
	year = {1996},
	note = {Publisher: Taylor \& Francis},
	pages = {365--377},
}

@article{schneider_1990,
	title = {A comparative study of algorithms for matrix balancing},
	volume = {38},
	number = {3},
	journal = {Operations research},
	author = {Schneider, Michael H and Zenios, Stavros A},
	year = {1990},
	note = {Publisher: INFORMS},
	keywords = {*file-import-18-10-04},
	pages = {439--455},
}

@techreport{scott_2018a,
	title = {State-{Dependent} {Kernel} {Selection} for {Conditional} {Sampling} of {Graphs}},
	url = {http://arxiv.org/abs/1809.06758},
	abstract = {This paper introduces new efficient algorithms for two problems: sampling
conditional on vertex degrees in unweighted graphs, and sampling conditional on
vertex strengths in weighted graphs. The algorithms can sample conditional on
the presence or absence of an arbitrary number of edges. The resulting
conditional distributions provide the basis for exact tests. Existing samplers
based on MCMC or sequential importance sampling are generally not scalable;
their efficiency degrades in sparse graphs. MCMC methods usually require
explicit computation of a Markov basis to navigate the complex state space;
this is computationally intensive even for small graphs. We use state-dependent
kernel selection to develop new MCMC samplers. These do not require a Markov
basis, and are efficient both in sparse and dense graphs. The key idea is to
intelligently select a Markov kernel on the basis of the current state of the
chain. We apply our methods to testing hypotheses on a real network and
contingency table. The algorithms appear orders of magnitude more efficient
than existing methods in the test cases considered.},
	author = {Scott, J and Gandy, A},
	month = sep,
	year = {2018},
	annote = {arXiv:1809.06758 [stat.ME]},
}

@book{pearson_1904,
	title = {On the {Theory} of {Contingency} and its {Relation} to {Association} and {Normal} {Correlation}; {On} the {General} {Theory} of {Skew} {Correlation} and {Non}-{Linear} {Regression}},
	publisher = {Cambridge University Press},
	author = {Pearson, Karl},
	year = {1904},
	keywords = {*file-import-18-07-16},
}

@book{moussa_2011,
	title = {Contagion and systemic risk in financial networks},
	publisher = {Citeseer},
	author = {Moussa, Amal},
	year = {2011},
	keywords = {*file-import-18-10-01},
}

@article{besag_clifford_1989,
	title = {Generalized {Monte} {Carlo} significance tests},
	volume = {76},
	url = {+},
	doi = {10.1093/biomet/76.4.633},
	number = {4},
	journal = {Biometrika},
	author = {Besag, Julian and Clifford, Peter},
	year = {1989},
	keywords = {*file-import-18-01-14},
	pages = {633--642},
}

@article{blanchet_2009,
	title = {Efficient importance sampling for binary contingency tables},
	volume = {19},
	url = {https://doi.org/10.1214/08-AAP558},
	doi = {10.1214/08-AAP558},
	number = {3},
	journal = {Ann. Appl. Probab.},
	author = {Blanchet, Jose H},
	year = {2009},
	note = {Publisher: The Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-14},
	pages = {949--982},
}

@incollection{baral_2012,
	title = {Estimation of bilateral exposures-a copula approach},
	booktitle = {Technical {Report}},
	publisher = {mimeo},
	author = {Baral, Pallavi and Fique, Jose P},
	year = {2012},
	keywords = {*file-import-18-10-01},
}

@article{goodman_1965,
	title = {On the {Statistical} {Analysis} of {Mobility} {Tables}},
	volume = {70},
	number = {5},
	journal = {American Journal of Sociology},
	author = {Goodman, Leo A},
	year = {1965},
	note = {Publisher: University of Chicago Press},
	keywords = {*file-import-18-07-16},
	pages = {564--585},
}

@article{snijders_1991,
	title = {Enumeration and {Simulation} {Methods} for 0-1 {Matrices} with {Given} {Marginals}},
	volume = {56},
	url = {http://dx.doi.org/10.1007/bf02294482},
	doi = {10.1007/bf02294482},
	number = {3},
	journal = {Psychometrika},
	author = {Snijders, Tom A B},
	year = {1991},
	note = {Publisher: Springer-Verlag},
	pages = {397--417},
}

@article{gai_2010,
	title = {Contagion in financial networks},
	volume = {466},
	url = {http://rspa.royalsocietypublishing.org/content/466/2120/2401},
	doi = {10.1098/rspa.2009.0410},
	abstract = {This paper develops an analytical model of contagion in financial networks with arbitrary structure. We explore how the probability and potential impact of contagion is influenced by aggregate and idiosyncratic shocks, changes in network structure and asset market liquidity. Our findings suggest that financial systems exhibit a robust-yet-fragile tendency: while the probability of contagion may be low, the effects can be extremely widespread when problems occur. And we suggest why the resilience of the system in withstanding fairly large shocks prior to 2007 should not have been taken as a reliable guide to its future robustness.},
	number = {2120},
	journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
	author = {Gai, Prasanna and Kapadia, Sujit},
	year = {2010},
	note = {Publisher: The Royal Society},
	keywords = {*file-import-18-01-28},
	pages = {2401--2423},
}

@article{wells_2004,
	title = {Financial interlinkages in the {United} {Kingdom}'s interbank market and the risk of contagion},
	author = {Wells, Simon J},
	year = {2004},
	keywords = {*file-import-18-10-01},
}

@article{fienberg_1969,
	title = {Preliminary {Graphical} {Analysis} and {Quasi}-{Independence} for two-way {Contingency} {Tables}},
	volume = {18},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Fienberg, Stephen E},
	year = {1969},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {153--168},
}

@article{cimini_2015,
	title = {Systemic risk analysis on reconstructed economic and financial networks},
	volume = {5},
	journal = {Scientific reports},
	author = {Cimini, Giulio and Squartini, Tiziano and Garlaschelli, Diego and Gabrielli, Andrea},
	year = {2015},
	note = {Publisher: Nature Publishing Group},
	keywords = {*file-import-18-10-01},
	pages = {15758},
}

@incollection{diaconis_1995,
	title = {Rectangular {Arrays} with {Fixed} {Margins}},
	volume = {72},
	url = {http://dx.doi.org/10.1007/978-1-4612-0801-3_3},
	abstract = {In a variety of combinatorial and statistical applications, one needs to know the number of rectangular arrays of nonnegative integers with given row and column sums. The combinatorial problems include counting magic squares, enumerating permutations by descent patterns and a variety of problems in representation theory. The statistical problems involve goodness of fit tests for contingency tables. We review these problems along with the available techniques for exact and approximate solution.},
	booktitle = {Discrete {Probability} and {Algorithms}},
	publisher = {Springer New York},
	author = {Diaconis, Persi and Gangolli, Anil},
	editor = {Aldous, David and Diaconis, Persi and Spencer, Joel and {Steele}},
	year = {1995},
	doi = {10.1007/978-1-4612-0801-3_3},
	note = {Series Title: The IMA Volumes in Mathematics and its Applications},
	pages = {15--41},
}

@article{aoki_2005,
	title = {Markov {Chain} {Monte} {Carlo} {Exact} {Tests} for {Incomplete} two-way {Contingency} {Tables}},
	volume = {75},
	number = {10},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Aoki, Satoshi and Takemura, Akimichi},
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-06-05},
	pages = {787--812},
}

@incollection{mazzarisi_2017,
	title = {Methods for reconstructing interbank networks from limited information: a comparison},
	booktitle = {Econophysics and {Sociophysics}: {Recent} {Progress} and {Future} {Directions}},
	publisher = {Springer},
	author = {Mazzarisi, Piero and Lillo, Fabrizio},
	year = {2017},
	keywords = {*file-import-18-10-01},
	pages = {201--215},
}

@article{elliot_2014,
	title = {Financial {Networks} and {Contagion}},
	volume = {104},
	url = {http://www.aeaweb.org/articles?id=10.1257/aer.104.10.3115},
	doi = {10.1257/aer.104.10.3115},
	number = {10},
	journal = {American Economic Review},
	author = {Elliott, Matthew and Golub, Benjamin and Jackson, Matthew O},
	month = oct,
	year = {2014},
	keywords = {*file-import-18-01-28},
	pages = {3115--3153},
}

@article{chen_2005,
	title = {Sequential {Monte} {Carlo} {Methods} for {Statistical} {Analysis} of {Tables}},
	volume = {100},
	issn = {0162-1459},
	url = {http://dx.doi.org/10.1198/016214504000001303},
	doi = {10.1198/016214504000001303},
	abstract = {We describe a sequential importance sampling (SIS) procedure for analyzing two-way zero?one or contingency tables with fixed marginal sums. An essential feature of the new method is that it samples the columns of the table progressively according to certain special distributions. Our method produces Monte Carlo samples that are remarkably close to the uniform distribution, enabling one to approximate closely the null distributions of various test statistics about these tables. Our method compares favorably with other existing Monte Carlo-based algorithms, and sometimes is a few orders of magnitude more efficient. In particular, compared with Markov chain Monte Carlo (MCMC)-based approaches, our importance sampling method not only is more efficient in terms of absolute running time and frees one from pondering over the mixing issue, but also provides an easy and accurate estimate of the total number of tables with fixed marginal sums, which is far more difficult for an MCMC method to achieve.},
	number = {469},
	journal = {Journal of the American Statistical Association},
	author = {Chen, Yuguo and Diaconis, Persi and Holmes, Susan P and Liu, Jun S},
	month = mar,
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	pages = {109--120},
}

@article{drehmann_2013,
	title = {Measuring the systemic importance of interconnected banks},
	volume = {22},
	number = {4},
	journal = {Journal of Financial Intermediation},
	author = {Drehmann, Mathias and Tarashev, Nikola},
	year = {2013},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-01},
	pages = {586--607},
}

@book{rasch_1960,
	title = {Probabilistic {Models} for some {Intelligence} and {Achievement} {Tests}},
	publisher = {University of Chicago Press},
	author = {Rasch, Georg},
	year = {1960},
	note = {Publication Title: Copenhagen: Danish Institute for Educational Research},
	keywords = {*file-import-18-01-14},
}

@article{strona_2014,
	title = {A fast and unbiased procedure to randomize ecological binary matrices with fixed row and column totals},
	volume = {5},
	url = {http://dx.doi.org/http://dx.doi.org/10.1038/ncomms5114},
	doi = {http://dx.doi.org/10.1038/ncomms5114},
	journal = {Nature Communications},
	author = {Strona, Giovanni and Nappo, Domenico and Boccacci, Francesco and Fattorini, Simone and San-Miguel-Ayanz, Jesus},
	year = {2014},
	keywords = {*file-import-18-01-14},
}

@article{krause_2003,
	title = {Compartments {Revealed} in {Food}-{Web} {Structure}},
	volume = {426},
	number = {6964},
	journal = {Nature},
	author = {Krause, Ann E and Frank, Kenneth A and Mason, Doran M and Ulanowicz, Robert E and Taylor, William W},
	year = {2003},
	note = {Publisher: Nature Publishing Group},
	keywords = {*file-import-18-07-12},
	pages = {282--285},
}

@article{manly_1995,
	title = {A {Note} on the {Analysis} of {Species} {Co}-{Occurrences}},
	volume = {76},
	url = {http://dx.doi.org/10.2307/1940919},
	doi = {10.2307/1940919},
	abstract = {The analysis of records of species occurrences on islands in an attempt to detect interactions between species has been an area of controversy in recent years in terms of the validity of some of the statistical methods used. In this note I make two contributions to the continuing debate. First, I advocate a generalized Monte Carlo testing procedure because this is easy to implement, is computationally efficient, and has guaranteed properties when the null hypothesis of no species interactions is correct. Second, I propose a test statistic that can be decomposed into a component for each individual species, and I demonstrate how this makes it possible to isolate species with unusual patterns of co—occurrence with other species, even after an allowance for multiple testing is made.},
	number = {4},
	journal = {Ecology},
	author = {Manly, Bryan F J},
	month = jun,
	year = {1995},
	note = {Publisher: Ecological Society of America},
	pages = {1109--1115},
}

@book{agresti2003,
	title = {Categorical {Data} {Analysis}},
	publisher = {John Wiley \& Sons},
	author = {Agresti, Alan},
	year = {2013},
	keywords = {*file-import-18-06-05},
}

@misc{jacob_2018,
	title = {Unbiased {Markov} chain {Monte} {Carlo} with couplings},
	url = {http://arxiv.org/abs/1708.03625},
	abstract = {Markov chain Monte Carlo (MCMC) methods provide consistent approximations of
integrals as the number of iterations goes to infinity. MCMC estimators are
generally biased after any fixed number of iterations, which complicates both
parallel computation and the construction of confidence intervals. We propose
to remove this bias by using couplings of Markov chains together with a
telescopic sum argument of Glynn \& Rhee (2014). The resulting unbiased
estimators can be computed in parallel, with confidence intervals following
directly from the Central Limit Theorem for i.i.d. variables. We discuss
practical couplings for popular algorithms such as Metropolis-Hastings, Gibbs
samplers, and Hamiltonian Monte Carlo. We establish the theoretical validity of
the proposed estimators and study their efficiency relative to the underlying
MCMC algorithms. Finally, we illustrate the performance and limitations of the
method on toy examples, a variable selection problem, and an approximation of
the cut distribution arising in Bayesian inference for models made of multiple
modules.},
	author = {Jacob, P and O'Leary, J and Atchadé, Yves},
	month = feb,
	year = {2018},
	annote = {arXiv:1708.03625 [stat.ME]},
}

@article{haldane_2011,
	title = {Systemic risk in banking ecosystems},
	volume = {469},
	url = {http://dx.doi.org/10.1038/nature09659},
	doi = {10.1038/nature09659},
	journal = {Nature},
	author = {Haldane, Andrew G and May, Robert M},
	month = jan,
	year = {2011},
	keywords = {*file-import-18-01-28},
	pages = {351--355},
}

@article{mistrulli_2011,
	title = {Assessing financial contagion in the interbank market: {Maximum} entropy versus observed interbank lending patterns},
	volume = {35},
	number = {5},
	journal = {Journal of Banking \& Finance},
	author = {Mistrulli, Paolo E},
	year = {2011},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-01},
	pages = {1114--1127},
}

@article{roberts_2000,
	title = {Simple {Methods} for {Simulating} {Sociomatrices} with {Given} {Marginal} {Totals}},
	volume = {22},
	url = {http://www.sciencedirect.com/science/article/pii/S0378873300000265},
	doi = {https://doi.org/10.1016/S0378-8733(00)00026-5},
	number = {3},
	journal = {Social Networks},
	author = {Roberts, John M},
	year = {2000},
	keywords = {*file-import-18-01-14},
	pages = {273--283},
}

@article{porter_2009,
	title = {Communities in networks},
	volume = {56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349607513&},
	number = {9},
	journal = {Notices of the American Mathematical Society},
	author = {Porter, M A and Onnela, J P and Mucha, P J},
	year = {2009},
	keywords = {*file-import-18-01-19},
	pages = {1082--1097},
	annote = {cited By 421},
}

@article{erdos_1959,
	title = {On {Random} {Graphs} {I}.},
	volume = {6},
	journal = {Publicationes Mathematicae (Debrecen)},
	author = {ErdH os, Paul and Rényi, Alfréd},
	year = {1959},
	keywords = {*file-import-18-01-19, graphs, random},
	pages = {290--297},
}

@book{ryser_1963,
	title = {Combinatorial {Mathematics}},
	url = {http://dx.doi.org/10.5948/UPO9781614440147},
	publisher = {Mathematical Association of America},
	author = {Ryser, Herbert J},
	year = {1963},
	doi = {10.5948/UPO9781614440147},
	keywords = {*file-import-18-01-14},
}

@article{verhelst_2008,
	title = {An {Efficient} {MCMC} {Algorithm} to {Sample} {Binary} {Matrices} with {Fixed} {Marginals}},
	volume = {73},
	url = {http://dx.doi.org/10.1007/s11336-008-9062-3},
	doi = {10.1007/s11336-008-9062-3},
	number = {4},
	journal = {Psychometrika},
	author = {Verhelst, Norman D},
	year = {2008},
	note = {Publisher: Springer-Verlag},
	pages = {705--728},
}

@article{jeong_2001,
	title = {Lethality and centrality in protein networks},
	volume = {411},
	url = {http://dx.doi.org/10.1038/35075138},
	doi = {10.1038/35075138},
	number = {6833},
	journal = {Nature},
	author = {Jeong, H and Mason, S P and Barabasi, A L and Oltvai, Z N},
	year = {2001},
	keywords = {*file-import-18-01-19},
	pages = {41--42},
	annote = {10.1038/35075138},
}

@article{elsinger_2006,
	title = {Using {Market} {Information} for {Banking} {System} {Risk} {Assessment}},
	volume = {2},
	url = {https://ideas.repec.org/a/ijc/ijcjou/y2006q1a4.html},
	abstract = {We propose a new method for the analysis of systemic stability of a banking system relying mostly on market data. We model both asset correlations and interlinkages from interbank borrowing so that our analysis gauges two major sources of systemic risk: correlated exposures and mutual credit relations that may cause domino effects of insolvencies. We apply our method to a data set of the ten major UK banks and analyze insolvency risk over a one-year horizon. We also suggest a stress-testing procedure by analyzing the conditional asset return distribution that results from the hypothetical failure of individual institutions in this system. Rather than looking at individual bank defaults ceteris paribus, we take the change in the asset return distribution and the resulting change in the risk of all other banks into account. This takes previous stress tests of interlinkages a substantial step further.},
	number = {1},
	journal = {International Journal of Central Banking},
	author = {Elsinger, Helmut and Lehar, Alfred and Summer, Martin},
	month = mar,
	year = {2006},
	keywords = {*file-import-18-10-03},
}

@misc{cheddar,
	title = {Cheddar: {Analysis} and {Visualisation} of {Ecological} {Communities}},
	url = {https://github.com/quicklizard99/cheddar/},
	author = {Hudson, Lawrence and Reuman, Daniel and Emerson, Rob},
	year = {2018},
	keywords = {*file-import-18-07-12},
	annote = {R package version 0.1-633},
}

@article{park_2004,
	title = {Statistical mechanics of networks},
	volume = {70},
	number = {6},
	journal = {Physical Review E},
	author = {Park, Juyong and Newman, Mark E J},
	year = {2004},
	note = {Publisher: APS},
	keywords = {*file-import-18-10-04},
	pages = {66117},
}

@techreport{acemoglu_2013,
	title = {Systemic {Risk} and {Stability} in {Financial} {Networks}},
	url = {http://www.nber.org/papers/w18727},
	abstract = {We provide a framework for studying the relationship between the financial network architecture and the likelihood of systemic failures due to contagion of counterparty risk. We show that financial contagion exhibits a form of phase transition as interbank connections increase: as long as the magnitude and the number of negative shocks affecting financial institutions are sufficiently small, more "complete" interbank claims enhance the stability of the system. However, beyond a certain point, such interconnections start to serve as a mechanism for propagation of shocks and lead to a more fragile financial system. We also show that, under natural contracting assumptions, financial networks that emerge in equilibrium may be socially inefficient due to the presence of a network externality: even though banks take the effects of their lending, risk-taking and failure on their immediate creditors into account, they do not internalize the consequences of their actions on the rest of the network.},
	institution = {National Bureau of Economic Research},
	author = {Acemoglu, Daron and Ozdaglar, Asuman and Tahbaz-Salehi, Alireza},
	month = jan,
	year = {2013},
	doi = {10.3386/w18727},
	note = {Issue: 18727},
	keywords = {*file-import-18-01-28},
}

@article{ponocny_2001,
	title = {Nonparametric goodness-of-fit tests for the rasch model},
	volume = {66},
	url = {http://dx.doi.org/10.1007/bf02294444},
	doi = {10.1007/bf02294444},
	number = {3},
	journal = {Psychometrika},
	author = {Ponocny, Ivo},
	year = {2001},
	note = {Publisher: Springer-Verlag},
	pages = {437--459},
}

@article{gandy_2018,
	title = {Adjustable network reconstruction with applications to {CDS} exposures},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X17306279},
	doi = {https://doi.org/10.1016/j.jmva.2018.08.011},
	journal = {Journal of Multivariate Analysis},
	author = {Gandy, Axel and Veraart, Luitgard A},
	year = {2018},
	keywords = {graphs, *file-import-18-10-03, balancing, bayesian, calibration, matrix, methods, random, risk, systemic},
}

@article{eisinger_2017,
	title = {Sampling for {Conditional} {Inference} on {Contingency} {Tables}},
	volume = {26},
	number = {1},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Eisinger, Robert D and Chen, Yuguo},
	year = {2017},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-06-05},
	pages = {79--87},
}

@article{goodman_1968,
	title = {The {Analysis} of {Cross}-{Classified} {Data}: {Independence}, {Quasi}-{Independence}, and {Interactions} in {Contingency} {Tables} with or without {Missing} {Entries}},
	volume = {63},
	number = {324},
	journal = {Journal of the American Statistical Association},
	author = {Goodman, Leo A},
	year = {1968},
	note = {Publisher: Taylor \& Francis Group},
	keywords = {*file-import-18-07-13},
	pages = {1091--1131},
}

@article{ulrich_2007,
	title = {Null {Model} {Analysis} of {Species} {Nestedness} {Patterns}},
	volume = {88},
	number = {7},
	journal = {Ecology},
	author = {Ulrich, Werner and Gotelli, Nicholas J},
	year = {2007},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {1824--1831},
}

@article{diaconis_sturmfels_1998,
	title = {Algebraic {Algorithms} for {Sampling} from {Conditional} {Distributions}},
	volume = {26},
	url = {https://doi.org/10.1214/aos/1030563990},
	doi = {10.1214/aos/1030563990},
	number = {1},
	journal = {Annals of Statistics},
	author = {Diaconis, Persi and Sturmfels, Bernd},
	year = {1998},
	note = {Publisher: The Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-14},
	pages = {363--397},
}

@article{brualdi_1980,
	title = {Matrices of zeros and ones with fixed row and column sum vectors},
	volume = {33},
	url = {http://www.sciencedirect.com/science/article/pii/0024379580901056},
	doi = {https://doi.org/10.1016/0024-3795(80)90105-6},
	journal = {Linear Algebra and its Applications},
	author = {Brualdi, Richard A},
	year = {1980},
	keywords = {*file-import-18-01-14},
	pages = {159--231},
}

@article{rao_1996,
	title = {A {Markov} {Chain} {Monte} {Carlo} {Method} for {Generating} {Random} (0, 1) {Matrices} with {Given} {Marginals}},
	volume = {58},
	url = {http://www.jstor.org/stable/25051102},
	number = {2},
	journal = {Sankhya: The Indian Journal of Statistics, Series A (1961-2002)},
	author = {Rao, A Ramachandra and Jana, Rabindranath and Bandyopadhyay, Suraj},
	year = {1996},
	note = {Publisher: Springer},
	keywords = {*file-import-18-01-14},
	pages = {225--242},
}

@article{mcdonald_2007,
	title = {Markov chain {Monte} {Carlo} {Exact} {Inference} for {Social} {Networks}},
	volume = {29},
	url = {http://www.sciencedirect.com/science/article/pii/S0378873306000141},
	doi = {https://doi.org/10.1016/j.socnet.2006.04.003},
	number = {1},
	journal = {Social Networks},
	author = {McDonald, John W and Smith, Peter W F and Forster, Jonathan J},
	year = {2007},
	keywords = {*file-import-18-01-14, adjacency, algorithm, carlo, census, chain, conditional, exact, markov, matrices, metropolishastings, monte, reciprocity, test, triad},
	pages = {127--136},
}

@article{chen_small_2005,
	title = {Exact tests for the rasch model via sequential importance sampling},
	volume = {70},
	url = {http://dx.doi.org/10.1007/s11336-003-1069-1},
	doi = {10.1007/s11336-003-1069-1},
	abstract = {Rasch proposed an exact conditional inference approach to testing his model but never implemented it because it involves the calculation of a complicated probability. This paper furthers Rasch's approach by (1) providing an efficient Monte Carlo methodology for accurately approximating the required probability and (2) illustrating the usefulness of Rasch's approach for several important testing problems through simulation studies. Our Monte Carlo methodology is shown to compare favorably to other Monte Carlo methods proposed for this problem in two respects: it is considerably faster and it provides more reliable estimates of the Monte Carlo standard error.},
	number = {1},
	journal = {Psychometrika},
	author = {Chen, Yuguo and Small, Dylan},
	month = mar,
	year = {2005},
	note = {Publisher: Springer-Verlag},
	pages = {11--30},
}

@book{krugman_1996,
	title = {The {Self} {Organising} {Economy}},
	publisher = {Wiley},
	author = {Krugman, Paul},
	month = feb,
	year = {1996},
	keywords = {*file-import-18-01-19},
}

@article{borgatti_2000,
	title = {Models of core/periphery structures},
	volume = {21},
	url = {http://www.sciencedirect.com/science/article/pii/S0378873399000192},
	doi = {http://dx.doi.org/10.1016/S0378-8733(99)00019-2},
	number = {4},
	journal = {Social Networks},
	author = {Borgatti, Stephen P and Everett, Martin G},
	year = {2000},
	keywords = {*file-import-18-01-19, core},
	pages = {375--395},
}

@article{miller_2013,
	title = {Exact sampling and counting for fixed-margin matrices},
	volume = {41},
	url = {https://doi.org/10.1214/13-AOS1131},
	doi = {10.1214/13-AOS1131},
	number = {3},
	journal = {Ann. Statist.},
	author = {Miller, Jeffrey W and Harrison, Matthew T},
	year = {2013},
	note = {Publisher: The Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-14},
	pages = {1569--1592},
}

@article{gotelli_2001,
	title = {Swap and {Fill} {Algorithms} in {Null} {Model} {Analysis}: {Rethinking} the {Knight}'s {Tour}},
	volume = {129},
	url = {http://dx.doi.org/10.1007/s004420100717},
	doi = {10.1007/s004420100717},
	number = {2},
	journal = {Oecologia},
	author = {Gotelli, NicholasJ and Entsminger, GaryL},
	year = {2001},
	note = {Publisher: Springer Berlin Heidelberg},
	pages = {281--291},
}

@article{mantel_1963,
	title = {Analyses of {Birth}-{Rank} {Data}},
	volume = {19},
	number = {2},
	journal = {Biometrics},
	author = {Mantel, Nathan and Halperin, Max},
	year = {1963},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {324--340},
}

@book{diamond_1975,
	title = {Ecology and evolution of communities},
	publisher = {Harvard University Press},
	author = {Cody, Martin L and Diamond, Jared M},
	year = {1975},
	keywords = {*file-import-18-04-11},
}

@article{zhang_chen_2013,
	title = {Sampling for {Conditional} {Inference} on {Network} {Data}},
	volume = {108},
	url = {http://dx.doi.org/10.1080/01621459.2012.758587},
	doi = {10.1080/01621459.2012.758587},
	abstract = {Random graphs with given vertex degrees have been widely used as a model for many real-world complex networks. However, both statistical inference and analytic study of such networks present great challenges. In this article, we propose a new sequential importance sampling method for sampling networks with a given degree sequence. These samples can be used to approximate closely the null distributions of a number of test statistics involved in such networks and provide an accurate estimate of the total number of networks with given vertex degrees. We study the asymptotic behavior of the proposed algorithm and prove that the importance weight remains bounded as the size of the graph grows. This property guarantees that the proposed sampling algorithm can still work efficiently even for large sparse graphs. We apply our method to a range of examples to demonstrate its efficiency in real problems.},
	number = {504},
	journal = {Journal of the American Statistical Association},
	author = {Zhang, Jingfei and Chen, Yuguo},
	month = dec,
	year = {2013},
	note = {Publisher: Taylor \& Francis},
	pages = {1295--1307},
}

@article{connor_1979,
	title = {The {Assembly} of {Species} {Communities}: {Chance} or {Competition}?},
	volume = {60},
	url = {http://www.jstor.org/stable/1936961},
	abstract = {We challenge Diamond's (1975) idea that island species distributions are determined predominantly by competitions canonized by his @'assembly rules.@' We show that every assembly rule is either tautological, trivial, or a pattern expected were species distributed at random. In order to demonstrate that competition is responsible for the joint distributions of species, one would have to falsify a null hypothesis stating that the distributions are generated by the species randomly and individually colonizing an archipelago.},
	number = {6},
	journal = {Ecology},
	author = {Connor, Edward F and Simberloff, Daniel},
	year = {1979},
	note = {Publisher: Ecological Society of America},
	keywords = {*file-import-18-03-13},
	pages = {1132--1140},
}

@article{liu_2016,
	title = {Systemic risk components in a network model of contagion},
	volume = {48},
	url = {http://dx.doi.org/10.1080/0740817X.2015.1110650},
	doi = {10.1080/0740817X.2015.1110650},
	number = {6},
	journal = {IIE Transactions},
	author = {Staum, Jeremy and Feng, Mingbin and Liu, Ming},
	year = {2016},
	keywords = {*file-import-18-01-28},
	pages = {501--510},
}

@article{bezakova_2012,
	title = {Negative {Examples} for {Sequential} {Importance} {Sampling} of {Binary} {Contingency} {Tables}},
	volume = {64},
	issn = {0178-4617},
	url = {http://dx.doi.org/10.1007/s00453-011-9569-3},
	doi = {10.1007/s00453-011-9569-3},
	abstract = {The sequential importance sampling (SIS) algorithm has gained considerable popularity for its empirical success. One of its noted applications is to the binary contingency tables problem, an important problem in statistics, where the goal is to estimate the number of 0/1 matrices with prescribed row and column sums. We give a family of examples in which the SIS procedure, if run for any subexponential number of trials, will underestimate the number of tables by an exponential factor. This result holds for any of the usual design choices in the SIS algorithm, namely the ordering of the columns and rows. These are apparently the first theoretical results on the efficiency of the SIS algorithm for binary contingency tables. Finally, we present experimental evidence that the SIS algorithm is efficient for row and column sums that are regular. Our work is a first step in determining the class of inputs for which SIS is effective.},
	number = {4},
	journal = {Algorithmica},
	author = {Bezáková, Ivona and Sinclair, Alistair and Štefankovič, Daniel and Vigoda, Eric},
	month = sep,
	year = {2012},
	note = {Publisher: Springer-Verlag},
	pages = {606--620},
}

@article{mastrandrea_2014,
	title = {Enhanced reconstruction of weighted networks from strengths and degrees},
	volume = {16},
	number = {4},
	journal = {New Journal of Physics},
	author = {Mastrandrea, Rossana and Squartini, Tiziano and Fagiolo, Giorgio and Garlaschelli, Diego},
	year = {2014},
	note = {Publisher: IOP Publishing},
	keywords = {*file-import-18-10-01},
	pages = {43022},
}

@article{conrad_2018,
	title = {Parallel {Local} {Approximation} {MCMC} for {Expensive} {Models}},
	volume = {6},
	url = {https://doi.org/10.1137/16M1084080},
	doi = {10.1137/16M1084080},
	number = {1},
	journal = {SIAM/ASA Journal on Uncertainty Quantification},
	author = {Conrad, P and Davis, A and Marzouk, Y and Pillai, N and Smith, A},
	year = {2018},
	keywords = {*file-import-18-09-28},
	pages = {339--373},
}

@article{watson_1956,
	title = {Missing and "mixed-up" {Frequencies} in {Contingency} {Tables}},
	volume = {12},
	number = {1},
	journal = {Biometrics},
	author = {Watson, Geoffrey S},
	year = {1956},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {47--50},
}

@article{savage_1960,
	title = {A {Statistical} {Model} of the {Gross} {Analysis} of {Transaction} {Flows}},
	journal = {Econometrica: Journal of the Econometric Society},
	author = {Savage, I Richard and Deutsch, Karl W},
	year = {1960},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {551--572},
}

@article{caldarelli_2002,
	title = {Scale-free networks from varying vertex intrinsic fitness},
	volume = {89},
	number = {25},
	journal = {Physical review letters},
	author = {Caldarelli, Guido and Capocci, Andrea and De Los Rios, Paolo and Munoz, Miguel A},
	year = {2002},
	note = {Publisher: APS},
	keywords = {*file-import-18-10-01},
	pages = {258702},
}

@article{cocco_2009,
	title = {Lending relationships in the interbank market},
	volume = {18},
	number = {1},
	journal = {Journal of Financial Intermediation},
	author = {Cocco, Joao F and Gomes, Francisco J and Martins, Nuno C},
	year = {2009},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-04},
	pages = {24--48},
}

@article{diaconis1985,
	title = {Testing for independence in a two-way table: new interpretations of the chi-square statistic},
	journal = {The Annals of Statistics},
	author = {Diaconis, Persi and Efron, Bradley},
	year = {1985},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-06-05},
	pages = {845--874},
}

@article{squartini_2017,
	title = {Network reconstruction via density sampling},
	volume = {2},
	number = {1},
	journal = {Applied Network Science},
	author = {Squartini, Tiziano and Cimini, Giulio and Gabrielli, Andrea and Garlaschelli, Diego},
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {*file-import-18-10-01},
	pages = {3},
}

@article{fortunato_2010,
	title = {Community detection in graphs},
	volume = {486},
	url = {http://www.sciencedirect.com/science/article/pii/S0370157309002841},
	doi = {http://dx.doi.org/10.1016/j.physrep.2009.11.002},
	number = {3},
	journal = {Physics Reports},
	author = {Fortunato, Santo},
	year = {2010},
	keywords = {*file-import-18-01-19, graphs},
	pages = {75--174},
}

@incollection{olesen_2010,
	title = {From {Broadstone} to {Zackenberg}: {Space}, {Time} and {Hierarchies} in {Ecological} {Networks}},
	volume = {42},
	booktitle = {Advances in ecological research},
	publisher = {Elsevier},
	author = {Olesen, Jens M and Dupont, Yoko L and O'Gorman, Eoin and Ings, Thomas C and Layer, Katrin and Melián, Carlos J and Trøjelsgaard, Kristian and Pichler, Doris E and Rasmussen, Claus and Woodward, Guy},
	year = {2010},
	keywords = {*file-import-18-07-12},
	pages = {1--69},
}

@article{li_2005,
	title = {Bayesian inference for origin-destination matrices of transport networks using the {EM} algorithm},
	volume = {47},
	number = {4},
	journal = {Technometrics},
	author = {Li, Baibing},
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-01-28},
	pages = {399--408},
}

@article{pimm_1980,
	title = {Are {Food} {Webs} {Divided} into {Compartments}?},
	volume = {49},
	number = {3},
	journal = {The Journal of Animal Ecology},
	author = {Pimm, Stuart L and Lawton, John H},
	year = {1980},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-12},
	pages = {879--898},
}

@article{gustafsson_1980,
	title = {A {Solution} of the {Conditional} {Estimation} {Problem} for {Long} {Tests} in the {Rasch} model for {Dichotomous} {Items}},
	volume = {40},
	number = {2},
	journal = {Educational and Psychological Measurement},
	author = {Gustafsson, Jan-Eric},
	year = {1980},
	note = {Publisher: Sage Publications Sage CA: Thousand Oaks, CA},
	keywords = {*file-import-18-01-14},
	pages = {377--385},
}

@book{levin_2009,
	title = {Markov {Chains} and {Mixing} {Time}},
	publisher = {American Mathematical Society},
	author = {{Levin} and Wilmer, E L},
	year = {2009},
	keywords = {*file-import-18-01-19},
}

@article{blitzstein_diaconis_2011,
	title = {A {Sequential} {Importance} {Sampling} {Algorithm} for {Generating} {Random} {Graphs} with {Prescribed} {Degrees}},
	volume = {6},
	url = {http://dx.doi.org/10.1080/15427951.2010.557277},
	doi = {10.1080/15427951.2010.557277},
	abstract = {Abstract Random graphs with given degrees are a natural next step in complexity beyond the Erd?s?Rényi model, yet the degree constraint greatly complicates simulation and estimation. We use an extension of a combinatorial characterization due to Erd?s and Gallai to develop a sequential algorithm for generating a random labeled graph with a given degree sequence. The algorithm is easy to implement and allows for surprisingly efficient sequential importance sampling. The resulting probabilities are easily computed on the fly, allowing the user to reweight estimators appropriately, in contrast to some ad hoc approaches that generate graphs with the desired degrees but with completely unknown probabilities. Applications are given, including simulating an ecological network and estimating the number of graphs with a given degree sequence.},
	number = {4},
	journal = {Internet Mathematics},
	author = {Blitzstein, Joseph and Diaconis, Persi},
	month = mar,
	year = {2011},
	note = {Publisher: Taylor \& Francis},
	pages = {489--522},
}

@article{roberts_2015,
	title = {Surprising {Convergence} {Properties} of {Some} {Simple} {Gibbs} {Samplers} under {Various} {Scans}},
	volume = {5},
	url = {http://www.ccsenet.org/journal/index.php/ijsp/article/view/55570},
	doi = {10.5539/ijsp.v5n1p51},
	abstract = {We examine the convergence properties of some simple Gibbs sampler examples under various scans. We find some surprising results, including Gibbs samplers where deterministic-scan is much more efficient than random-scan, and other samplers where the opposite is true. We also present an example where the convergence takes precisely the same time with any fixed deterministic scan, but modifying the scan in any way leads to significantly slower convergence.},
	number = {1},
	journal = {International Journal of Statistics and Probability},
	author = {Roberts, Gareth O and Rosenthal, Jeffrey S},
	year = {2015},
	keywords = {*file-import-18-01-19},
	pages = {51},
}

@misc{M2,
	title = {Macaulay2, a {Software} {System} for {Research} in {Algebraic} {Geometry}},
	author = {Grayson, Daniel R and Stillman, Michael E},
	note = {Medium: Available at {\textbackslash}{\textbackslash}urlhttp://www.math.uiuc.edu/Macaulay2/},
	keywords = {*file-import-18-07-16},
}

@incollection{barrat_2007,
	title = {The {Architecture} of {Complex} {Weighted} {Networks}: {Measurements} and {Models}},
	booktitle = {Large {Scale} {Structure} {And} {Dynamics} {Of} {Complex} {Networks}: {From} {Information} {Technology} to {Finance} and {Natural} {Science}},
	publisher = {World Scientific},
	author = {Barrat, Alain and Barthelemy, Marc and Vespignani, Alessandro},
	year = {2007},
	keywords = {*file-import-18-10-04},
	pages = {67--92},
}

@article{baird_1989,
	title = {The {Seasonal} {Dynamics} of the {Chesapeake} {Bay} {Ecosystem}},
	volume = {59},
	number = {4},
	journal = {Ecological Monographs},
	author = {Baird, Daniel and Ulanowicz, Robert E},
	year = {1989},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {329--364},
}

@article{boss_2004,
	title = {Network topology of the interbank market},
	volume = {4},
	number = {6},
	journal = {Quantitative finance},
	author = {Boss, Michael and Elsinger, Helmut and Summer, Martin and {Thurner}},
	year = {2004},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-10-04},
	pages = {677--684},
}

@article{gandy_2016,
	title = {A {Bayesian} {Methodology} for {Systemic} {Risk} {Assessment} in {Financial} {Networks}},
	volume = {63},
	number = {12},
	journal = {Management Science},
	author = {Gandy, Axel and Veraart, Luitgard A M},
	year = {2016},
	note = {Publisher: INFORMS},
	keywords = {*file-import-18-01-19},
	pages = {4428--4446},
}

@article{craig_von_peter_2015,
	title = {Filling in the blanks: network structure and interbank contagion},
	volume = {15},
	url = {http://dx.doi.org/10.1080/14697688.2014.968195},
	doi = {10.1080/14697688.2014.968195},
	number = {4},
	journal = {Quantitative Finance},
	author = {Anand, Kartik and Craig, Ben and von Peter, Goetz},
	year = {2015},
	keywords = {*file-import-18-01-19},
	pages = {625--636},
}

@article{doreian_1985,
	title = {Structural equivalence in a psychology journal network},
	volume = {36},
	url = {http://dx.doi.org/10.1002/asi.4630360611},
	doi = {10.1002/asi.4630360611},
	number = {6},
	journal = {Journal of the American Society for Information Science},
	author = {Doreian, Patrick},
	year = {1985},
	note = {Publisher: Wiley Subscription Services, Inc., A Wiley Company},
	keywords = {*file-import-18-01-19},
	pages = {411--417},
}

@article{hazelton_2015,
	title = {Network tomography for integer-valued traffic},
	volume = {9},
	number = {1},
	journal = {The Annals of Applied Statistics},
	author = {Hazelton, Martin L and {Others}},
	year = {2015},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {*file-import-18-01-28},
	pages = {474--506},
}

@article{rapallo_2006,
	title = {Markov {Bases} and {Structural} {Zeros}},
	volume = {41},
	number = {2},
	journal = {Journal of Symbolic Computation},
	author = {Rapallo, Fabio},
	year = {2006},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-06-05},
	pages = {164--172},
}

@article{peltonen_2014,
	title = {The network structure of the {CDS} market and its determinants},
	volume = {13},
	url = {http://www.sciencedirect.com/science/article/pii/S1572308914000503},
	doi = {http://dx.doi.org/10.1016/j.jfs.2014.05.004},
	journal = {Journal of Financial Stability},
	author = {Peltonen, Tuomas A and Scheicher, Martin and Vuillemey, Guillaume},
	year = {2014},
	keywords = {*file-import-18-01-19, cds, credit, default, swap},
	pages = {118--133},
}

@article{gangi_2018,
	title = {Assessing systemic risk due to fire sales spillover through maximum entropy network reconstruction},
	author = {Di Gangi, Domenico and Lillo, Fabrizio and Pirino, Davide},
	year = {2018},
	keywords = {*file-import-18-10-01},
}

@article{milo_2002,
	title = {Network {Motifs}: {Simple} {Building} {Blocks} of {Complex} {Networks}},
	volume = {298},
	issn = {1095-9203},
	url = {http://dx.doi.org/10.1126/science.298.5594.824},
	doi = {10.1126/science.298.5594.824},
	abstract = {Complex networks are studied across many fields of science. To uncover their structural design principles, we defined ” network motifs,” patterns of interconnections occurring in complex networks at numbers that are significantly higher than those in randomized networks. We found such motifs in networks from biochemistry, neurobiology, ecology, and engineering. The motifs shared by ecological food webs were distinct from the motifs shared by the genetic networks of Escherichia coli and Saccharomyces cerevisiae or from those found in the World Wide Web. Similar motifs were found in networks that perform information processing, even though they describe elements as different as biomolecules within a cell and synaptic connections between neurons in Caenorhabditis elegans. Motifs may thus define universal classes of networks. This approach may uncover the basic building blocks of most networks.},
	number = {5594},
	journal = {Science},
	author = {Milo, R and Shen-Orr, S and Itzkovitz, S and Kashtan, N and Chklovskii, D and Alon, U},
	month = oct,
	year = {2002},
	pmid = {12399590},
	note = {Publisher: American Association for the Advancement of Science
Place: Departments of Physics of Complex Systems and Molecular Cell Biology, Weizmann Institute of Science, Rehovot, Israel 76100.},
	pages = {824--827},
}

@book{wasserman_1994,
	title = {Social {Network} {Analysis}: {Methods} and {Applications}},
	url = {https://books.google.co.uk/books?id=wsMgAwAAQBAJ},
	publisher = {Cambridge University Press},
	author = {Wasserman, S and Faust, K},
	year = {1994},
	note = {Series Title: Structural Analysis in the Social Sciences},
	keywords = {*file-import-18-01-14},
}

@article{cimini_2015b,
	title = {Estimating topological properties of weighted networks from limited information},
	volume = {92},
	number = {4},
	journal = {Physical Review E},
	author = {Cimini, Giulio and Squartini, Tiziano and Gabrielli, Andrea and Garlaschelli, Diego},
	year = {2015},
	note = {Publisher: APS},
	keywords = {*file-import-18-10-01},
	pages = {40802},
}

@article{chen_2007,
	title = {Conditional {Inference} on {Tables} {With} {Structural} {Zeros}},
	volume = {16},
	issn = {1061-8600},
	url = {http://dx.doi.org/10.1198/106186007x209226},
	doi = {10.1198/106186007x209226},
	abstract = {We develop a set of sequential importance sampling (SIS) strategies for sampling nearly uniformly from two-way zero-one or contingency tables with fixed marginal sums and a given set of structural zeros. The SIS procedure samples tables column by column or cell by cell by using appropriate proposal distributions, and enables us to approximate closely the null distributions of a number of test statistics involved in such tables. When structural zeros are on the diagonal or follow certain patterns, more efficient SIS algorithms are developed which guarantee that every generated table is valid. Examples show that our methods can be applied to make conditional inference on zero-one and contingency tables, and are more efficient than other existing Monte Carlo algorithms.},
	number = {2},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Chen, Yuguo},
	month = jun,
	year = {2007},
	note = {Publisher: Taylor \& Francis},
	pages = {445--467},
}

@article{anand_2018,
	title = {The missing links: {A} global study on uncovering financial network structures from partial data},
	volume = {35},
	journal = {Journal of Financial Stability},
	author = {Anand, Kartik and van Lelyveld, Iman and Banai, Ádám and Friedrich, Soeren and Garratt, Rodney and Hałaj, Grzegorz and Fique, Jose and Hansen, Ib and Jaramillo, Seraf'in M and Lee, Hwayun and {Others}},
	year = {2018},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-04},
	pages = {107--119},
}

@article{bayati_2010,
	title = {A {Sequential} {Algorithm} for {Generating} {Random} {Graphs}},
	volume = {58},
	url = {http://dx.doi.org/10.1007/s00453-009-9340-1},
	doi = {10.1007/s00453-009-9340-1},
	abstract = {Abstract We present a nearly-linear time algorithm for counting and randomly generating simple graphs with a given degree sequence in a certain range. For degree sequence (d i ) i=1 n with maximum degree d max =O(m 1/4−τ ), our algorithm generates almost uniform random graphs with that degree sequence in time O(md max ) where is the number of edges in the graph and τ is any positive constant. The fastest known algorithm for uniform generation of these graphs (McKay and Wormald in J. Algorithms 11(1):52–67, 1990) has a running time of O(m 2 d max 2). Our method also gives an independent proof of McKay's estimate (McKay in Ars Combinatoria A 19:15–25, 1985) for the number of such graphs. We also use sequential importance sampling to derive fully Polynomial-time Randomized Approximation Schemes (FPRAS) for counting and uniformly generating random graphs for the same range of d max =O(m 1/4−τ ). Moreover, we show that for d=O(n 1/2−τ ), our algorithm can generate an asymptotically uniform d-regular graph. Our results improve the previous bound of d=O(n 1/3−τ ) due to Kim and Vu (Adv. Math. 188:444–469, 2004) for regular graphs.},
	number = {4},
	journal = {Algorithmica},
	author = {Bayati, Mohsen and Kim, Jeong H and Saberi, Amin},
	year = {2010},
	note = {Publisher: Springer-Verlag},
	pages = {860--910},
}

@article{carvalho_2014,
	title = {A {Bayesian} {Statistical} {Approach} for {Inference} on {Static} {Origin} {Destination} {Matrices} in {Transportation} {Studies}},
	volume = {56},
	url = {http://dx.doi.org/10.1080/00401706.2013.826144},
	doi = {10.1080/00401706.2013.826144},
	number = {2},
	journal = {Technometrics},
	author = {Carvalho, Luis},
	month = apr,
	year = {2014},
	note = {Publisher: Taylor \& Francis},
	pages = {225--237},
}

@article{musmeci_2013,
	title = {Bootstrapping topological properties and systemic risk of complex networks using the fitness model},
	volume = {151},
	number = {3-4},
	journal = {Journal of Statistical Physics},
	author = {Musmeci, Nicolò and Battiston, Stefano and Caldarelli, Guido and Puliga, Michelangelo and Gabrielli, Andrea},
	year = {2013},
	note = {Publisher: Springer},
	keywords = {*file-import-18-10-01},
	pages = {720--734},
}

@article{holland_leinghardt_1981,
	title = {An {Exponential} {Family} of {Probability} {Distributions} for {Directed} {Graphs}},
	volume = {76},
	url = {http://dx.doi.org/10.1080/01621459.1981.10477598},
	doi = {10.1080/01621459.1981.10477598},
	abstract = {Abstract Directed graph (or digraph) data arise in many fields, especially in contemporary research on structures of social relationships. We describe an exponential family of distributions that can be used for analyzing such data. A substantive rationale for the general model is presented, and several special cases are discussed along with some possible substantive interpretations. A computational algorithm based on iterative scaling procedures for use in fitting data is described, as are the results of a pilot simulation study. An example using previously reported empirical data is worked out in detail. An extension to multiple relationship data is discussed briefly.},
	number = {373},
	journal = {Journal of the American Statistical Association},
	author = {Holland, Paul W and Leinhardt, Samuel},
	month = mar,
	year = {1981},
	note = {Publisher: Taylor \& Francis},
	pages = {33--50},
}

@article{dimaggio_2017,
	title = {The value of trading relations in turbulent times},
	volume = {124},
	url = {http://www.sciencedirect.com/science/article/pii/S0304405X1730003X},
	doi = {http://dx.doi.org/10.1016/j.jfineco.2017.01.003},
	number = {2},
	journal = {Journal of Financial Economics},
	author = {Maggio, Marco D and Kermani, Amir and Song, Zhaogang},
	year = {2017},
	keywords = {*file-import-18-01-19, bond, corporate},
	pages = {266--284},
}

@article{barrat_2004,
	title = {The architecture of complex weighted networks},
	volume = {101},
	url = {http://www.pnas.org/content/101/11/3747},
	doi = {10.1073/pnas.0400087101},
	abstract = {Networked structures arise in a wide array of different contexts such as technological and transportation infrastructures, social phenomena, and biological systems. These highly interconnected systems have recently been the focus of a great deal of attention that has uncovered and characterized their topological complexity. Along with a complex topological structure, real networks display a large heterogeneity in the capacity and intensity of the connections. These features, however, have mainly not been considered in past studies where links are usually represented as binary states, i.e., either present or absent. Here, we study the scientific collaboration network and the world-wide air-transportation network, which are representative examples of social and large infrastructure systems, respectively. In both cases it is possible to assign to each edge of the graph a weight proportional to the intensity or capacity of the connections among the various elements of the network. We define appropriate metrics combining weighted and topological observables that enable us to characterize the complex statistical properties and heterogeneity of the actual strength of edges and vertices. This information allows us to investigate the correlations among weighted quantities and the underlying topological structure of the network. These results provide a better description of the hierarchies and organizational principles at the basis of the architecture of weighted networks.},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Barrat, A and Barthélemy, M and Pastor-Satorras, R and Vespignani, A},
	year = {2004},
	note = {Publisher: National Academy of Sciences},
	keywords = {*file-import-18-10-04},
	pages = {3747--3752},
}

@article{wasserman_1977,
	title = {Random directed graph distributions and the triad census in social networks},
	volume = {5},
	url = {http://dx.doi.org/10.1080/0022250x.1977.9989865},
	doi = {10.1080/0022250x.1977.9989865},
	abstract = {This paper uses the concept of the triad census as, developed by Holland and Leinhardt, and describes several distributions on directed graphs. Methods are presented for calculating the mean and the covariance matrix of the triad census for the uniform distribution that conditions on the number of choices made by each individual in the social network. Several complex distributions on digraphs are approximated, and an application of these methods to a sociogram is given.},
	number = {1},
	journal = {The Journal of Mathematical Sociology},
	author = {Wasserman, Stanley S},
	month = jan,
	year = {1977},
	note = {Publisher: Routledge},
	pages = {61--86},
}

@article{goodman_1963,
	title = {Statistical {Methods} for the {Preliminary} {Analysis} of {Transaction} {Flows}},
	volume = {31},
	number = {1},
	journal = {Econometrica},
	author = {Goodman, Leo A},
	year = {1963},
	note = {Publisher: JSTOR},
	keywords = {*file-import-18-07-13},
	pages = {197--208},
}

@article{mastromatteo_2012,
	title = {Reconstruction of financial networks for robust estimation of systemic risk},
	volume = {2012},
	number = {03},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Mastromatteo, Iacopo and Zarinelli, Elia and Marsili, Matteo},
	year = {2012},
	note = {Publisher: IOP Publishing},
	keywords = {*file-import-18-10-01},
}

@article{allen_2000,
	title = {Financial contagion},
	volume = {108},
	number = {1},
	journal = {Journal of political economy},
	author = {Allen, Franklin and Gale, Douglas},
	year = {2000},
	note = {Publisher: The University of Chicago Press},
	keywords = {*file-import-18-10-04},
	pages = {1--33},
}

@article{craig_2014,
	title = {Interbank tiering and money center banks},
	volume = {23},
	number = {3},
	journal = {Journal of Financial Intermediation},
	author = {Craig, Ben and Von Peter, Goetz},
	year = {2014},
	note = {Publisher: Elsevier},
	keywords = {*file-import-18-10-01},
	pages = {322--347},
}

@article{anand_2015,
	title = {Filling in the blanks: {Network} structure and interbank contagion},
	volume = {15},
	number = {4},
	journal = {Quantitative Finance},
	author = {Anand, Kartik and Craig, Ben and Von Peter, Goetz},
	year = {2015},
	note = {Publisher: Taylor \& Francis},
	keywords = {*file-import-18-10-01},
	pages = {625--636},
}

@article{albert_1999,
	title = {Internet: {Diameter} of the {World}-{Wide} {Web}},
	volume = {401},
	url = {http://dx.doi.org/10.1038/43601},
	doi = {10.1038/43601},
	number = {6749},
	journal = {Nature},
	author = {Albert, Reka and Jeong, Hawoong and Barabasi, Albert-Laszlo},
	year = {1999},
	keywords = {*file-import-18-01-19},
	pages = {130--131},
	annote = {10.1038/43601},
}

@techreport{cont_2013,
	title = {Network structure and systemic risk in banking systems},
	url = {https://ideas.repec.org/p/hal/journl/hal-00912018.html},
	abstract = {We present a quantitative methodology for analyzing the potential for contagion and systemic risk in a network of interlinked financial institutions, using a metric for the systemic importance of institutions: the Contagion Index. We apply this methodology to a data set of mutual exposures and capital levels of financial institutions in Brazil in 2007 and 2008, and analyze the role of balance sheet size and network structure in each institution's contribution to systemic risk. Our results emphasize the contribution of heterogeneity in network structure and concentration of counterparty exposures to a given institution in explaining its systemic importance. These observations plead for capital requirements which depend on exposures, rather than aggregate balance sheet size, and which target systemically important institutions.},
	institution = {HAL},
	author = {Cont, Rama and Moussa, Amal and Santos, Edson B},
	month = jul,
	year = {2013},
	doi = {10.1016/j.jebo.2010.07.00},
	note = {Issue: hal-00912018},
	keywords = {*file-import-18-10-04},
}

@article{kannan_1999,
	title = {Simple {Markov}‐chain algorithms for generating bipartite graphs and tournaments},
	volume = {14},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-2418%28199907%2914%3A4%3C293%3A%3AAID-RSA1%3E3.0.CO%3B2-G},
	doi = {10.1002/(SICI)1098-2418(199907)14:4%3C293::AID-RSA1%3E3.0.CO;2-G},
	abstract = {Abstract We consider two problems: randomly generating labeled bipartite graphs with a given degree sequence and randomly generating labeled tournaments with a given score sequence. We analyze simple Markov chains for both problems. For the first problem, we cannot prove that our chain is rapidly mixing in general, but in the near‐regular case, i.e., when all the degrees are almost equal, we give a proof of rapid mixing. Our methods also apply to the corresponding problem for general (nonbipartite) regular graphs, which was studied earlier by several researchers. One significant difference in our approach is that our chain has one state for every graph (or bipartite graph) with the given degree sequence; in particular, there are no auxiliary states as in the chain used by Jerrum and Sinclair. For the problem of generating tournaments, we are able to prove that our Markov chain on tournaments is rapidly mixing, if the score sequence is near‐regular. The proof techniques we use for the two problems are similar. \{{\textbackslash}copyright\}1999 John Wiley \& Sons, Inc. Random Struct. Alg., 14: 293–308, 1999},
	number = {4},
	journal = {Random Structures \& Algorithms},
	author = {Kannan, Ravi and Tetali, Prasad and Vempala, Santosh},
	year = {1999},
	keywords = {*file-import-18-04-18},
	pages = {293--308},
}

@book{cormen_2009,
	address = {Cambridge, Massachusetts},
	title = {Introduction to {Algorithms}},
	publisher = {MIT press},
	author = {Cormen, Thomas H {and} Leiserson, Charles E {and} Rivest, Ronald L {and} Stein, Clifford},
	year = {2009},
	keywords = {*file-import-18-01-17},
}

@article{lelyveld_2014,
	title = {Finding the core: {Network} structure in interbank markets},
	volume = {49},
	url = {http://www.sciencedirect.com/science/article/pii/S0378426614002738},
	doi = {http://dx.doi.org/10.1016/j.jbankfin.2014.08.006},
	journal = {Journal of Banking \& Finance},
	author = {in 't Veld, Daan and van Lelyveld, Iman},
	year = {2014},
	keywords = {*file-import-18-01-19, interbank, networks},
	pages = {27--40},
}

@article{roberts_stone_1990,
	title = {Island-sharing by archipelago species},
	volume = {83},
	url = {http://dx.doi.org/10.1007/bf00317210},
	doi = {10.1007/bf00317210},
	number = {4},
	journal = {Oecologia},
	author = {Roberts, Alan and Stone, Lewis},
	year = {1990},
	note = {Publisher: Springer-Verlag},
	pages = {560--567},
}

@article{rezende_2009,
	title = {Compartments in a {Marine} {Food} {Web} {Associated} with {Phylogeny}, {Body} {Mass}, and {Habitat} {Structure}},
	volume = {12},
	number = {8},
	journal = {Ecology Letters},
	author = {Rezende, Enrico L and Albert, Eva M and Fortuna, Miguel A and Bascompte, Jordi},
	year = {2009},
	note = {Publisher: Wiley Online Library},
	keywords = {*file-import-18-07-12},
	pages = {779--788},
}

@article{williams_2004,
	title = {Limits to {Trophic} {Levels} and {Omnivory} in {Complex} {Food} {Webs}: {Theory} and {Data}},
	volume = {163},
	number = {3},
	journal = {The American Naturalist},
	author = {Williams, Richard J and Martinez, Neo D},
	year = {2004},
	note = {Publisher: The University of Chicago Press},
	keywords = {*file-import-18-07-12},
	pages = {458--468},
}

@article{girvan_2002,
	title = {Community {Structure} in {Social} and {Biological} {Networks}},
	volume = {99},
	number = {12},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Girvan, Michelle and Newman, Mark E J},
	year = {2002},
	note = {Publisher: National Acad Sciences},
	keywords = {*file-import-18-07-12},
	pages = {7821--7826},
}

@misc{kahle_2017,
	title = {latte: {LattE} and 4ti2 in {R}},
	url = {https://github.com/dkahle/latte},
	author = {Kahle, David {and} Gracia-Puente, Luis {and} Yoshida Ruriko},
	year = {2017},
	annote = {R package version 0.2.0},
}

@article{muller_model_2013-1,
	title = {Model {Selection} in {Linear} {Mixed} {Models}},
	volume = {28},
	doi = {10.1214/12-STS410},
	abstract = {Linear mixed effects models are highly flexible in handling a broad range of data types and are therefore widely used in applications. A key part in the analysis of data is model selection, which often aims to choose a parsimonious model with other desirable properties from a possibly very large set of candidate statistical models. Over the last 5-10 years the literature on model selection in linear mixed models has grown extremely rapidly. The problem is much more complicated than in linear regression because selection on the covariance structure is not straightforward due to computational issues and boundary problems arising from positive semidefinite constraints on covariance matrices. To obtain a better understanding of the available methods, their properties and the relationships between them, we review a large body of literature on linear mixed model selection. We arrange, implement, discuss and compare model selection methods based on four major approaches: information criteria such as AIC or BIC, shrinkage methods based on penalized loss functions such as LASSO, the Fence procedure and Bayesian techniques.},
	number = {2},
	urldate = {2019-05-15},
	journal = {Statistical Science},
	author = {Müller, Samuel and Scealy, J L and Welsh, A H},
	year = {2013},
	keywords = {Cholesky decomposition, AIC, Bayes factor, BIC, fence, information criteria, LASSO, linear mixed model, model selection, shrinkage methods},
	pages = {135--167},
	file = {PDF:/Users/jamesscott/Zotero/storage/9AV95BSM/full-text.pdf:application/pdf},
}

@article{li_variable_2010-1,
	title = {{VARIABLE} {SELECTION} {AND} {REGRESSION} {ANALYSIS} {FOR} {GRAPH}-{STRUCTURED} {COVARIATES} {WITH} {AN} {APPLICATION} {TO} {GENOMICS} 1},
	volume = {4},
	doi = {10.1214/10-AOAS332},
	abstract = {Graphs and networks are common ways of depicting biological information. In biology, many different biological processes are represented by graphs, such as regulatory networks, metabolic pathways and protein-protein interaction networks. This kind of a priori use of graphs is a useful supplement to the standard numerical data such as microarray gene expression data. In this paper we consider the problem of regression analysis and variable selection when the covariates are linked on a graph. We study a graph-constrained regularization procedure and its theoretical properties for regression analysis to take into account the neighborhood information of the variables measured on a graph. This procedure involves a smoothness penalty on the coefficients that is defined as a quadratic form of the Laplacian matrix associated with the graph. We establish estimation and model selection consistency results and provide estimation bounds for both fixed and diverging numbers of parameters in regression models. We demonstrate by simulations and a real data set that the proposed procedure can lead to better variable selection and prediction than existing methods that ignore the graph information associated with the covariates. 1. Introduction. There has been a growing interest in penalized least squares problems via L 1 or other types of regularization, especially in high-dimensional settings. Important penalty functions that can lead to sparse variable selection in regression include Lasso [Tibshirani (1996)] and SCAD [Fan and Li (2001)]. In particular, Lasso has the crucial advantage of being a convex problem, which leads to efficient computational algorithms by coordinate descent [Efron et al. (2004); Friedman et al. (2007); Wu and Lange (2008)] and sparse solutions. Zou (2006) proposed a novel adaptive Lasso},
	number = {3},
	urldate = {2019-05-15},
	author = {Li, Caiyan and Li, Hongzhe},
	year = {2010},
	pages = {1498--1516},
	file = {PDF:/Users/jamesscott/Zotero/storage/MM5QNBB8/full-text.pdf:application/pdf},
}

@techreport{hoff_modeling_nodate-1,
	title = {Modeling homophily and stochastic equivalence in symmetric relational data},
	abstract = {This article discusses a latent variable model for inference and prediction of symmetric relational data. The model, based on the idea of the eigenvalue decomposition , represents the relationship between two nodes as the weighted inner-product of node-specific vectors of latent characteristics. This "eigenmodel" generalizes other popular latent variable models, such as latent class and distance models: It is shown mathematically that any latent class or distance model has a representation as an eigenmodel, but not vice-versa. The practical implications of this are examined in the context of three real datasets, for which the eigenmodel has as good or better out-of-sample predictive performance than the other two models.},
	urldate = {2019-05-15},
	author = {Hoff, Peter D},
	file = {PDF:/Users/jamesscott/Zotero/storage/KARGRKA2/full-text.pdf:application/pdf},
}

@techreport{hoff_additive_2018-3,
	title = {Additive and multiplicative effects network models},
	abstract = {Network datasets typically exhibit certain types of statistical dependencies, such as within-dyad correlation, row and column heterogeneity, and third-order dependence patterns such as transitivity and clustering. The first two of these can be well-represented statistically with a social relations model, a type of additive random effects model originally developed for continuous dyadic data. Third-order patterns can be represented with multiplicative random effects models, which are related to matrix decompositions commonly used for matrix-variate data analysis. Additionally, these multiplicative random effects models generalize other popular latent variable network models, such as the stochastic blockmodel and the latent space model. In this article we review a general regression framework for the analysis of network data that combines these two types of random effects and accommodates a variety of network data types, including continuous, binary and ordinal network relations.},
	urldate = {2019-05-15},
	author = {Hoff, Peter D},
	year = {2018},
	keywords = {Bayesian, factor model, generalized linear model, latent variable, matrix decomposi-tion, mixed effects model},
	file = {PDF:/Users/jamesscott/Zotero/storage/AH6WCYKZ/full-text.pdf:application/pdf},
}

@misc{rapallo_2003,
	title = {Algebraic {Markov} {Bases} and {MCMC} for {Two}-{Way} {Contingency} {Tables}},
	url = {https://www.jstor.org/stable/4616770},
	abstract = {The Diaconis-Sturmfels algorithm is a method for sampling from conditional distributions, based on the algebraic theory of toric ideals. This algorithm is applied to categorical data analysis through the notion of Markov basis. An application of this algorithm is a non-parametric Monte Carlo approach to the goodness of fit tests for contingency tables. In this paper, we characterize or compute the Markov bases for some log-linear models for two-way contingency tables using techniques from Computational Commutative Algebra, namely Gröbner bases. This applies to a large set of cases including independence, quasi-independence, symmetry, quasi-symmetry. Three examples of quasi-symmetry and quasi-independence from Fingleton (Models of category counts, Cambridge University Press, Cambridge, 1984) and Agresti (An Introduction to categorical data analysis, Wiley, New York, 1996) illustrate the practical applicability and the relevance of this algebraic methodology.},
	urldate = {2019-05-16},
	publisher = {WileyBoard of the Foundation of the Scandinavian Journal of Statistics},
	author = {Rapallo, Fabio},
	doi = {10.2307/4616770},
	note = {Pages: 385-397
Publication Title: Scandinavian Journal of Statistics
Volume: 30},
}

@book{pollard_2001,
	address = {Cambridge},
	title = {A {User}'s {Guide} to {Measure} {Theoretic} {Probability}},
	isbn = {978-0-511-81155-5},
	url = {http://ebooks.cambridge.org/ref/id/CBO9780511811555},
	urldate = {2019-05-22},
	publisher = {Cambridge University Press},
	author = {Pollard, David},
	year = {2001},
	doi = {10.1017/CBO9780511811555},
}

@book{pollard_users_2002-1,
	title = {A user's guide to measure theoretic probability},
	isbn = {978-0-511-81155-5},
	abstract = {This text is not just a presentation of mathematical theory, but also a discussion of why that theory takes its current form. It will be a secure starting point for anyone who needs to invoke rigorous probabilistic arguements and understand what they mean. Chapter 1. Motivation -- Ch. 2. A modicum of measure theory -- Ch. 3. Densities and derivatives -- Ch. 4. Product spaces and independence -- Ch. 5. Conditioning -- Ch. 6. Martingale et al. -- Ch. 7. Convergence in distribution -- Ch. 8. Fourier transforms -- Ch. 9. Brownian motion -- Ch. 10. Representations and couplings -- Ch. 11. Exponential tails and the law of the iterated logarithm -- Ch. 12. Multivariate normal distributions -- App. A. Measures and integrals -- App. B. Hilbert spaces -- App. C. Convexity -- App. D. Binomial and normal distributions -- App. E. Martingales in continuous time -- App. F. Disintegration of measures.},
	urldate = {2019-05-22},
	publisher = {Cambridge University Press},
	author = {Pollard, David},
	year = {2002},
}

@article{Wasserman1977,
	title = {Random directed graph distributions and the triad census in social networks†},
	volume = {5},
	issn = {0022-250X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/0022250X.1977.9989865},
	doi = {10.1080/0022250X.1977.9989865},
	abstract = {This paper uses the concept of the triad census as, developed by Holland and Leinhardt, and describes several distributions on directed graphs. Methods are presented for calculating the mean and the covariance matrix of the triad census for the uniform distribution that conditions on the number of choices made by each individual in the social network. Several complex distributions on digraphs are approximated, and an application of these methods to a sociogram is given.},
	number = {1},
	urldate = {2019-05-25},
	journal = {The Journal of Mathematical Sociology},
	author = {Wasserman, Stanley S.},
	month = jan,
	year = {1977},
	note = {Publisher:  Taylor \& Francis Group },
	pages = {61--86},
}

@article{agresti_1992,
	title = {A {Survey} of {Exact} {Inference} for {Contingency} {Tables}},
	volume = {7},
	url = {http://projecteuclid.org/euclid.ss/1177011454},
	doi = {10.1214/ss/1177011454},
	number = {1},
	urldate = {2019-05-25},
	journal = {Statistical Science},
	author = {Agresti, Alan},
	month = feb,
	year = {1992},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {131--153},
}

@article{newmann_2001,
	title = {Random {Graphs} with {Arbitrary} {Degree} {Distributions} and their {Applications}},
	volume = {64},
	doi = {10.1103/PhysRevE.64.026118},
	abstract = {Recent work on the structure of social networks and the internet has focused attention on graphs with distributions of vertex degree that are significantly different from the Poisson degree distributions that have been widely studied in the past. In this paper we develop in detail the theory of random graphs with arbitrary degree distributions. In addition to simple undirected, unipartite graphs, we examine the properties of directed and bipartite graphs. Among other results, we derive exact expressions for the position of the phase transition at which a giant component first forms, the mean component size, the size of the giant component if there is one, the mean number of vertices a certain distance away from a randomly chosen vertex, and the average vertex-vertex distance within a graph. We apply our theory to some real-world graphs, including the worldwide web and collaboration graphs of scientists and Fortune 1000 company directors. We demonstrate that in some cases random graphs with appropriate distributions of vertex degree predict with surprising accuracy the behavior of the real world, while in others there is a measurable discrepancy between theory and reality, perhaps indicating the presence of additional social structure in the network that is not captured by the random graph.},
	urldate = {2019-05-27},
	journal = {Physical Review, E},
	author = {Newman, M E J and Strogatz, S H and Watts, D J},
	year = {2001},
	pages = {1--17},
	file = {PDF:/Users/jamesscott/Zotero/storage/T8X9SM2S/full-text.pdf:application/pdf},
}

@article{mizruchi_1983,
	title = {Who {Controls} {Whom}? {An} {Examination} of the {Relation} between {Management} and {Boards} of {Directors} in {Large} {American} {Corporations}},
	volume = {8},
	issn = {03637425},
	url = {http://www.jstor.org/stable/257831?origin=crossref},
	doi = {10.2307/257831},
	abstract = {Most organization theorists believe that boards of directors in large American corporations are dominated by management. This paper argues that this view is based on a problematic definition of control. Several distinctions between long run and short run control are presented, and a framework in which boards of directors have control over managers is suggested. Case examples are given and possible objections are confronted. Finally, an agenda for further research on board-management relations is offered.},
	number = {3},
	urldate = {2019-05-27},
	journal = {The Academy of Management Review},
	author = {Mizruchi, Mark S.},
	month = jul,
	year = {1983},
	note = {Publisher: Academy of Management},
	pages = {426--435},
}

@incollection{allatta_2003,
	address = {Dordrecht},
	title = {Structural {Analysis} of {Communities} of {Practice}: {An} {Investigation} of {Job} title, {Location}, and {Management} {Intention}},
	url = {http://link.springer.com/10.1007/978-94-017-0115-0_2},
	urldate = {2019-05-27},
	booktitle = {Communities and {Technologies}},
	publisher = {Springer Netherlands},
	author = {Allatta, Joan T.},
	year = {2003},
	doi = {10.1007/978-94-017-0115-0_2},
	pages = {23--42},
}

@article{newman_2002,
	title = {Assortative {Mixing} in {Networks}},
	volume = {89},
	issn = {0031-9007},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12443515},
	doi = {10.1103/PhysRevLett.89.208701},
	abstract = {A network is said to show assortative mixing if the nodes in the network that have many connections tend to be connected to other nodes with many connections. Here we measure mixing patterns in a variety of networks and find that social networks are mostly assortatively mixed, but that technological and biological networks tend to be disassortative. We propose a model of an assortatively mixed network, which we study both analytically and numerically. Within this model we find that networks percolate more easily if they are assortative and that they are also more robust to vertex removal.},
	number = {20},
	urldate = {2019-05-27},
	journal = {Physical Review Letters},
	author = {Newman, M. E. J.},
	month = oct,
	year = {2002},
	pmid = {12443515},
	pages = {208701},
}

@article{opsahl_2013,
	title = {Triadic {Closure} in {Two}-{Mode} {Networks}: {Redefining} the {Global} and {Local} {Clustering} {Coefficients}},
	volume = {35},
	issn = {0378-8733},
	url = {https://www.sciencedirect.com/science/article/pii/S0378873311000360},
	doi = {10.1016/J.SOCNET.2011.07.001},
	abstract = {As the vast majority of network measures are defined for one-mode networks, two-mode networks often have to be projected onto one-mode networks to be analyzed. A number of issues arise in this transformation process, especially when analyzing ties among nodes’ contacts. For example, the values attained by the global and local clustering coefficients on projected random two-mode networks deviate from the expected values in corresponding classical one-mode networks. Moreover, both the local clustering coefficient and constraint (structural holes) are inversely associated to nodes’ two-mode degree. To overcome these issues, this paper proposes redefinitions of the clustering coefficients for two-mode networks.},
	number = {2},
	urldate = {2019-05-27},
	journal = {Social Networks},
	author = {Opsahl, Tore},
	month = may,
	year = {2013},
	note = {Publisher: North-Holland},
	pages = {159--167},
}

@article{galeano_2009,
	title = {Weighted-{Interaction} {Nestedness} {Estimator} ({WINE}): {A} {New} {Estimator} to {Calculate} over {Frequency} {Matrices}},
	volume = {24},
	issn = {13648152},
	doi = {10.1016/j.envsoft.2009.05.014},
	abstract = {We propose a new nestedness estimator that takes into account the weight of the interactions, that is, it runs over frequency matrices. A nestedness measurement is calculated through the average distance from each matrix cell containing a link to the cell with the lowest marginal totals, in the packed matrix, using a weighted Manhattan distance. The significance of this nestedness measure is tested against a null model that constraints matrix fill to observed values and retains the distribution of number of events. This is the first methodological approach that allows for the characterization of weighted nestedness. We have developed a graphical user interface (GUI) running in Matlab to compute all these parameters. The software is also available as a script for R-package and in C++ version. © 2009 Elsevier Ltd. All rights reserved.},
	number = {11},
	journal = {Environmental Modelling and Software},
	author = {Galeano, Javier and Pastor, Juan M. and Iriondo, Jose M.},
	year = {2009},
	keywords = {Ecological complex network, Frequency matrix, Matlab, Nestedness, Weighted-interaction},
	pages = {1342--1346},
}

@misc{stringr,
	title = {stringr: {Simple}, {Consistent} {Wrappers} for {Common} {String} {Operations}},
	url = {https://cran.r-project.org/package=stringr},
	author = {Wickham, Hadley},
	year = {2019},
	annote = {R package version 1.4.0},
}

@misc{algstat,
	title = {algstat: {Algebraic} {Statistics} in \{{R}\}},
	url = {https://github.com/dkahle/algstat},
	author = {Kahle, David and Garcia-Puente, Luis and Yoshida, Ruriko},
	year = {2017},
	annote = {R package version 0.1.1},
}

@misc{latte,
	title = {latte: \{{LattE}\} and \{4ti2\} in \{{R}\}},
	url = {https://github.com/dkahle/latte},
	publisher = {R package version 0.2.0},
	author = {Kahle, David and Garcia-Puente, Luis and Yoshida, Ruriko},
	year = {2017},
	annote = {R package version 0.2.0},
}

@article{igraph,
	title = {The igraph software package for complex network research},
	abstract = {The igraph software package provides handy tools for researchers in network science. It is an open source portable library capable of handling huge graphs with millions of vertices and edges and it is also suitable to grid computing. It contains routines for creating, manipulating and visualizing networks, calculating various structural properties, importing from and exporting to various file formats and many more. Via its interfaces to high-level languages like GNU R and Python it supports rapid development and fast prototyping.},
	journal = {InterJournal Complex Systems},
	author = {Csardi, Gabor and Nepusz, Tamas},
	year = {2006},
	pmid = {1420},
}

@article{rcpp,
	title = {Rcpp: {Seamless} {R} and {C}++ integration},
	issn = {15487660},
	doi = {10.18637/jss.v040.i08},
	abstract = {The Rcpp package simplies integrating C++ code with R. It provides a consistent C++ class hierarchy that maps various types of R objects (vectors, matrices, functions, environments,.) to dedicated C++ classes. Object interchange between R and C++ is managed by simple, exible and extensible concepts which include broad support for C++ Standard Template Library idioms. C++ code can both be compiled, linked and loaded on the y, or added via packages. Flexible error and exception code handling is provided. Rcpp substantially lowers the barrier for programmers wanting to combine C++ code with R.},
	journal = {Journal of Statistical Software},
	author = {Eddelbuettel, Dirk and François, Romain},
	year = {2011},
	keywords = {Call, Foreign function interface, R},
}

@article{smirnov_1948,
	title = {Table for {Estimating} the {Goodness} of {Fit} of {Empirical} {Distributions}},
	volume = {19},
	url = {https://doi.org/10.1214/aoms/1177730256},
	doi = {10.1214/aoms/1177730256},
	number = {2},
	journal = {Ann. Math. Statist.},
	author = {Smirnov, N},
	year = {1948},
	note = {Publisher: The Institute of Mathematical Statistics},
	pages = {279--281},
}

@article{gandy_veraart_2017,
	title = {A \{{B}\}ayesian {Methodology} for {Systemic} {Risk} {Assessment} in {Financial} {Networks}},
	volume = {63},
	doi = {10.1287/mnsc.2016.2546},
	number = {12},
	journal = {Management Science},
	author = {Gandy, Axel and Veraart, Luitgard A M},
	year = {2017},
	pages = {4428--4446},
}

@article{talts_2018,
	title = {Validating {Bayesian} {Inference} {Algorithms} with {Simulation}-{Based} {Calibration}},
	url = {http://arxiv.org/abs/1804.06788},
	abstract = {Verifying the correctness of Bayesian computation is challenging. This is especially true for complex models that are common in practice, as these require sophisticated model implementations and algorithms. In this paper we introduce {\textbackslash}emph\{simulation-based calibration\} (SBC), a general procedure for validating inferences from Bayesian algorithms capable of generating posterior samples. This procedure not only identifies inaccurate computation and inconsistencies in model implementations but also provides graphical summaries that can indicate the nature of the problems that arise. We argue that SBC is a critical part of a robust Bayesian workflow, as well as being a useful tool for those developing computational algorithms and statistical software.},
	urldate = {2019-11-28},
	author = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
	month = apr,
	year = {2018},
	file = {PDF:/Users/jamesscott/Zotero/storage/N3FKG5P7/full-text.pdf:application/pdf},
}

@article{geweke_2004,
	title = {Getting it right: {Joint} distribution tests of posterior simulators},
	issn = {01621459},
	doi = {10.1198/016214504000001132},
	abstract = {Analytical or coding, errors in posterior simulators can produce reasonable but incorrect approximations of posterior moments. This article develops simple tests of posterior simulators that detect both kinds of errors, and uses them to detect and correct errors in two previously published articles. The tests exploit the fact that a Bayesian model specifies the joint distribution of observables (data) and unobservables (parameters). There are two joint distribution simulators. The marginal-conditional simulator draws unobservables from the prior and then observables conditional on unobservables. The successive-conditional simulator alternates between the posterior simulator and an observables simulator. Formal comparison of moment approximations of the two simulators reveals existing analytical or coding errors in the posterior simulator.},
	journal = {Journal of the American Statistical Association},
	author = {Geweke, John},
	year = {2004},
	keywords = {Software, Markov chain Monte Carlo, Bayesian},
}

@article{cook_2006,
	title = {Validation of software for {Bayesian} models using posterior quantiles},
	issn = {10618600},
	doi = {10.1198/106186006X136976},
	abstract = {This article presents a simulation-based method designed to establish the computational correctness of software developed to fit a specific Bayesian model, capitalizing on properties of Bayesian posterior distributions. We illustrate the validation technique with two examples. The validation method is shown to find errors in software when they exist and, moreover, the validation output can be informative about the nature and location of such errors. We also compare our method with that of an earlier approach. © 2006 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cook, Samantha R. and Gelman, Andrew and Rubin, Donald B.},
	year = {2006},
	keywords = {Gibbs sampler, Hierarchical models, Markov chain Monte Carlo, Posterior distribution},
}

@article{girolami_calderhead_2011,
	title = {Riemann manifold {Langevin} and {Hamiltonian} {Monte} {Carlo} methods},
	issn = {13697412},
	doi = {10.1111/j.1467-9868.2010.00765.x},
	abstract = {The paper proposes Metropolis adjusted Langevin and Hamiltonian Monte Carlo sampling methods defined on the Riemann manifold to resolve the shortcomings of existing Monte Carlo algorithms when sampling from target densities that may be high dimensional and exhibit strong correlations. The methods provide fully automated adaptation mechanisms that circumvent the costly pilot runs that are required to tune proposal densities for Metropolis-Hastings or indeed Hamiltonian Monte Carlo and Metropolis adjusted Langevin algorithms. This allows for highly efficient sampling even in very high dimensions where different scalings may be required for the transient and stationary phases of the Markov chain. The methodology proposed exploits the Riemann geometry of the parameter space of statistical models and thus automatically adapts to the local structure when simulating paths across this manifold, providing highly efficient convergence and exploration of the target density. The performance of these Riemann manifold Monte Carlo methods is rigorously assessed by performing inference on logistic regression models, log-Gaussian Cox point processes, stochastic volatility models and Bayesian estimation of dynamic systems described by non-linear differential equations. Substantial improvements in the time-normalized effective sample size are reported when compared with alternative sampling approaches. MATLAB code that is available from allows replication of all the results reported. © 2011 Royal Statistical Society.},
	journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
	author = {Girolami, Mark and Calderhead, Ben},
	year = {2011},
	keywords = {Bayesian inference, Geometry in statistics, Hamiltonian Monte Carlo methods, Langevin diffusion, Markov chain Monte Carlo methods, Riemann manifolds},
}

@article{roberts_stramer_2002,
	title = {Langevin diffusions and {Metropolis}-{Hastings} algorithms},
	abstract = {We consider a class of Langevin diffusions with state-dependent volatility. The volatility of the diffusion is chosen so as to make the stationary distribution of the diffusion with respect to its natural clock, a heated version of the stationary density of interest. The motivation behind this construction is the desire to construct uniformly ergodic diffusions with required stationary densities. Discrete time algorithms constructed by Hastings accept reject mechanisms are constructed from discretisations of the algorithms, and the properties of these algorithms are investigated.},
	journal = {Methodology And Computing In Applied Probability},
	author = {Roberts, GO and Stramer, O},
	year = {2002},
	keywords = {65c40, ams 2000 subject classification, langevin diffusions and algorithms, mcmc},
}

@article{duane_1987,
	title = {Hybrid {Monte} {Carlo}},
	issn = {03702693},
	doi = {10.1016/0370-2693(87)91197-X},
	abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons. © 1987.},
	journal = {Physics Letters B},
	author = {Duane, Simon and Kennedy, A. D. and Pendleton, Brian J. and Roweth, Duncan},
	year = {1987},
}

@article{geman_geman_1984,
	title = {Stochastic {Relaxation}, {Gibbs} {Distributions}, and the {Bayesian} {Restoration} of {Images}},
	issn = {01628828},
	doi = {10.1109/TPAMI.1984.4767596},
	abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (“annealing”) or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel “relaxation” algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios. © 1984, IEEE.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Geman, Stuart and Geman, Donald},
	year = {1984},
	keywords = {Annealing, Gibbs distribution, image restoration, line process, MAP estimate, Markov random field, relaxation scene modeling, spatial degradation},
}

@article{gelman_2017,
	title = {Correction to: {Validation} of {Software} for {Bayesian} {Models} using {Posterior} {Quantiles}},
	volume = {26},
	issn = {15372715},
	doi = {10.1080/10618600.2017.1377082},
	abstract = {We thank Sean Talts and Michael Betancourt for sharing an example that made us realize the incorrectness of the following statement in Cook, Gelman, and Rubin 2006):Let, the empirical quantile for the ith replication. For any generic function h, we can determine the distribution of h(q) for correctly working software. In particular, if the software works properly and therefore the posterior quantiles are uniformly distributed, then h(q) = Φ− 1(q) should have a standard normal distribution, where Φ represents the standard normal CDF.The above claim is false, for two reasons. First, the relevant reference distribution is discrete uniform, not continuous uniform, so the normal CDF is at best just an approximation. Second, with Markov chain simulation, the draws θ(ℓ) are dependent, so for any finite L, the distribution of qi will not even be discrete uniform. The error wasn't noticed in the original paper because the method happened to work out on the examples. In general, however, any claim of the statistical properties of any statement about the distribution of draws from iterative simulation should account for the dependence of these simulation draws.},
	number = {4},
	urldate = {2019-11-28},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gelman, Andrew},
	month = oct,
	year = {2017},
	note = {Publisher: American Statistical Association},
	pages = {940},
	file = {PDF:/Users/jamesscott/Zotero/storage/EGKDDF45/full-text.pdf:application/pdf},
}

@incollection{sokal_1997,
	title = {Monte {Carlo} {Methods} in {Statistical} {Mechanics}: {Foundations} and {New} {Algorithms}},
	abstract = {Abstract These notes are an updated version of lectures given at the Cours de Troisième Cycle de la Physique en Suisse Romande (Lausanne, Switzerland) in June 1989. We thank the Troisième Cycle de la Physique en Suisse Romande and Professor Michel Droz for ...},
	author = {Sokal, A.},
	year = {1997},
	doi = {10.1007/978-1-4899-0319-8_6},
}

@article{cowles_1996,
	title = {Markov {Chain} {Monte} {Carlo} {Convergence} {Diagnostics}: {A} {Comparative} {Review}},
	volume = {91},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/action/journalInformation?journalCode=uasa20},
	doi = {10.1080/01621459.1996.10476956},
	urldate = {2020-01-16},
	journal = {Journal of the American Statistical Association},
	author = {Cowles, Mary Kathryn and Carlin, Bradley P},
	year = {1996},
	pages = {883--904},
	file = {PDF:/Users/jamesscott/Zotero/storage/NGH8F9J5/full-text.pdf:application/pdf},
}

@article{anderson_1962,
	title = {On the {Distribution} of the {Two}-{Sample} {Cramer}-von {Mises} {Criterion}},
	issn = {0003-4851},
	doi = {10.1214/aoms/1177704477},
	abstract = {An s stage k name snowball sampling procedure is defined as follows: A random sample of individuals is drawn from a given finite population. (The kind of random sample will be discussed later in this section.) Each individual in the sample is asked to name k different individuals in the population, where k is a specified integer; for example, each individual may be asked to name his "k best friends," or the "k individuals with whom he most frequently associates," or the "k individuals whose opinions he most frequently seeks," etc. (For the sake of simplicity, we assume throughout that an individual cannot include himself in his list of k individuals.) The individuals who were not in the random sample but were named by individuals in it form the first stage. Each of the individuals in the first stage is then asked to name k different individuals. (We assume that the question asked of the individuals in the random sample and of those in each stage is the same and that k is the same.) The individuals who were not in the random sample nor in the first stage but were named by individuals who were in the first stage form the second stage. Each of the individuals in the second stage is then asked to name k different individuals. The individuals who were not in the random sample nor in the first or second stages but were named by individuals who were in the second stage form the third stage. Each of the individuals in the third stage is then asked to name k different individuals. This procedure is continued until each of the individuals in the sth stage has been asked to name k different individuals. The data obtained using an s stage k name snowball sampling procedure can be utilized to make statistical inferences about various aspects of the relationships present in the population. The relationships present, in the hypothetical situation where each individual in the population is asked to name k different individuals, can be described by a matrix with rows and columns corresponding to the members of the population, rows for the individuals naming and columns for the individuals named, where the entry thetaij in the ith row and jth column is 1 if the ith individual in the population includes the jth individual among the k individuals he would name, and it is 0 otherwise. While the matrix of the theta's cannot be known in general unless every individual in the population is interviewed (i.e., asked to name k different individuals), it will be possible to make statistical inferences about various aspects of this matrix from the data obtained using an s stage k name snowball sampling procedure. For example, when s = k = 1, the number, M11, of mutual relationships present in the population (i.e., the number of values i with thetaij = thetaji = 1 for some value of j {\textgreater} i) can be estimated. The methods of statistical inference applied to the data obtained from an s stage k name snowball sample will of course depend on the kind of random sample drawn as the initial step. In most of the present paper, we shall suppose that a random sample (i.e., the "zero stage" in snowball sample) is drawn so that the probability, p, that a given individual in the population will be in the sample is independent of whether a different given individual has appeared. This kind of sampling has been called binomial sampling; the specified value of p (assumed known) has been called the sampling fraction 4. This sampling scheme might also be described by saying that a given individual is included in the sample just when a coin, which has a probability p of "heads," comes up "heads," where the tosses of the coin from individual to individual are independent. (To each individual there corresponds an independent Bernoulli trial determining whether he will or will not be included in the sample.) This sampling scheme differs in some respects from the more usual models where the sample size is fixed in advance or where the ratio of the sample size to the population size (i.e., the sample size-population size ratio) is fixed. For binomial sampling, this ratio is a random variable whose expected value is p. (The variance of this ratio approaches zero as the population becomes infinite.) In some situations (where, for example, the variance of this ratio is near zero), mathematical results obtained for binomial sampling are sometimes quite similar to results obtained using some of the more usual sampling models (see 4, 7; compare the variance formulas in 3 and 5); in such cases it will often not make much difference, from a practical point of view, which sampling model is utilized. (In Section 6 of the present paper some results for snowball sampling based on an initial sample of the more usual kind are obtained and compared with results presented in the earlier sections of this paper obtained for snowball sampling based on an initial binomial sample.) For snowball sampling based on an initial binomial sample, and with s = k = 1, so that each individual asked names just one other individual and there is just one stage beyond the initial sample, Section 2 of this paper discusses unbiased estimation of M11, the number of pairs of individuals in the population who would name each other. One of the unbiased estimators considered (among a certain specified class of estimators) has uniformly smallest variance when the population characteristics are unknown; this one is based on a sufficient statistic for a simplified summary of the data and is the only unbiased estimator of M11 based on that sufficient statistic (when the population characteristics are unknown). This estimator (when s = k = 1) has a smaller variance than a comparable minimum variance unbiased estimator computed from a larger random sample when s = 0 and k = 1 (i.e., where only the individuals in the random sample are interviewed) even where the expected number of individuals in the larger random sample (s = 0, k = 1) is equal to the maximum expected number of individuals studied when s = k = 1 (i.e., the sum of the expected number of individuals in the initial sample and the maximum expected number of individuals in the first stage). In fact, the variance of the estimator when s = 0 and k = 1 is at least twice as large as the variance of the comparable estimator when s = k = 1 even where the expected number of individuals studied when s = 0 and k = 1 is as large as the maximum expected number of individuals studied when s = k = 1. Thus, for estimating M11, the sampling scheme with s = k = 1 is preferable to the sampling scheme with s = 0 and k = 1. Furthermore, we observe that when s = k = 1 the unbiased estimator based on the simplified summary of the data having minimum variance when the population characteristics are unknown can be improved upon in cases where certain population characteristics are known, or where additional data not included in the simplified summary are available. Several improved estimators are derived and discussed. Some of the results for the special case of s = k = 1 are generalized in Sections 3 and 4 to deal with cases where s and k are any specified positive integers. In Section 5, results are presented about s stage k name snowball sampling procedures, where each individual asked to name k different individuals chooses k individuals at random from the population. (Except in Section 5, the numbers thetaij, which form the matrix referred to earlier, are assumed to be fixed (i.e., to be population parameters); in Section 5, they are random variables. A variable response error is not considered except in so far as Section 5 deals with an extreme case of this.) For social science literature that discusses problems related to snowball sampling, see 2, 8, and the articles they cite. This literature indicates, among other things, the importance of studying "social structure and...the relations among individuals" 2.},
	journal = {The Annals of Mathematical Statistics},
	author = {Anderson, T. W.},
	year = {1962},
}

@article{Gandy2019,
	title = {Compound {Poisson} {Models} for {Financial} {Networks}},
	doi = {10.2139/ssrn.3401059},
	urldate = {2020-02-07},
	journal = {SSRN Electronic Journal},
	author = {Gandy, Axel and Veraart, Luitgard A. M.},
	month = jun,
	year = {2019},
	note = {Publisher: Elsevier BV},
}

@book{meyn_tweedie_glynn_2009,
	title = {Markov {Chains} and {Stochastic} {Stability}},
	publisher = {Cambridge University Press},
	author = {Meyn, Sean and Tweedie, Richard L and Glynn, Peter W},
	year = {2009},
	doi = {10.1017/CBO9780511626630},
	note = {Series Title: Cambridge Mathematical Library},
}

@article{Flaxman2020,
	title = {Estimating the effects of non-pharmaceutical interventions on {COVID}-19 in {Europe}},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/s41586-020-2405-7},
	doi = {10.1038/s41586-020-2405-7},
	abstract = {Following the emergence of a novel coronavirus1 (SARS-CoV-2) and its spread outside of China, Europe has experienced large epidemics. In response, many European countries have implemented unprecedented non-pharmaceutical interventions such as closure of schools and national lockdowns. We study the impact of major interventions across 11 European countries for the period from the start of COVID-19 until the 4th of May 2020 when lockdowns started to be lifted. Our model calculates backwards from observed deaths to estimate transmission that occurred several weeks prior, allowing for the time lag between infection and death. We use partial pooling of information between countries with both individual and shared effects on the reproduction number. Pooling allows more information to be used, helps overcome data idiosyncrasies, and enables more timely estimates. Our model relies on fixed estimates of some epidemiological parameters such as the infection fatality rate, does not include importation or subnational variation and assumes that changes in the reproduction number are an immediate response to interventions rather than gradual changes in behavior. Amidst the ongoing pandemic, we rely on death data that is incomplete, with systematic biases in reporting, and subject to future consolidation. We estimate that, for all the countries we consider, current interventions have been sufficient to drive the reproduction number \$\$\{R\}\_\{t\}\$\$Rt below 1 (probability \$\$\{R\}\_\{t\}{\textbackslash},\$\$Rt{\textless} 1.0 is 99.9\%) and achieve epidemic control. We estimate that, across all 11 countries, between 12 and 15 million individuals have been infected with SARS-CoV-2 up to 4th May, representing between 3.2\% and 4.0\% of the population. Our results show that major non-pharmaceutical interventions and lockdown in particular have had a large effect on reducing transmission. Continued intervention should be considered to keep transmission of SARS-CoV-2 under control.},
	journal = {Nature},
	author = {Flaxman, Seth and Mishra, Swapnil and Gandy, Axel and Unwin, H Juliette T and Mellan, Thomas A and Coupland, Helen and Whittaker, Charles and Zhu, Harrison and Berah, Tresnia and Eaton, Jeffrey W and Monod, Mélodie and Perez-Guzman, Pablo N and Schmit, Nora and Cilloni, Lucia and Ainslie, Kylie E C and Baguelin, Marc and Boonyasiri, Adhiratha and Boyd, Olivia and Cattarino, Lorenzo and Cooper, Laura V and Cucunubá, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Djaafara, Bimandra and Dorigatti, Ilaria and van Elsland, Sabine L and FitzJohn, Richard G and Gaythorpe, Katy A M and Geidelberg, Lily and Grassly, Nicholas C and Green, William D and Hallett, Timothy and Hamlet, Arran and Hinsley, Wes and Jeffrey, Ben and Knock, Edward and Laydon, Daniel J and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Parag, Kris V and Siveroni, Igor and Thompson, Hayley A and Verity, Robert and Volz, Erik and Walters, Caroline E and Wang, Haowei and Wang, Yuanrong and Watson, Oliver J and Winskill, Peter and Xi, Xiaoyue and Walker, Patrick G T and Ghani, Azra C and Donnelly, Christl A and Riley, Steven M and Vollmer, Michaela A C and Ferguson, Neil M and Okell, Lucy C and Bhatt, Samir and Team, Imperial College COVID-19 Response},
	year = {2020},
}

@article{Li_2020,
	title = {Substantial undocumented infection facilitates the rapid dissemination of novel coronavirus ({SARS}-{CoV}-2)},
	issn = {10959203},
	doi = {10.1126/science.abb3221},
	abstract = {Estimation of the prevalence and contagiousness of undocumented novel coronavirus [severe acute respiratory syndrome–coronavirus 2 (SARS-CoV-2)] infections is critical for understanding the overall prevalence and pandemic potential of this disease. Here, we use observations of reported infection within China, in conjunction with mobility data, a networked dynamic metapopulation model, and Bayesian inference, to infer critical epidemiological characteristics associated with SARS-CoV-2, including the fraction of undocumented infections and their contagiousness. We estimate that 86\% of all infections were undocumented [95\% credible interval (CI): 82–90\%] before the 23 January 2020 travel restrictions. The transmission rate of undocumented infections per person was 55\% the transmission rate of documented infections (95\% CI: 46–62\%), yet, because of their greater numbers, undocumented infections were the source of 79\% of the documented cases. These findings explain the rapid geographic spread of SARS-CoV-2 and indicate that containment of this virus will be particularly challenging.},
	journal = {Science},
	author = {Li, Ruiyun and Pei, Sen and Chen, Bin and Song, Yimeng and Zhang, Tao and Yang, Wan and Shaman, Jeffrey},
	year = {2020},
	pmid = {32179701},
}

@article{Zhang_2019,
	title = {Patterns of human social contact and contact with animals in {Shanghai}, {China}},
	issn = {20452322},
	doi = {10.1038/s41598-019-51609-8},
	abstract = {East Asia is as a principal hotspot for emerging zoonotic infections. Understanding the likely pathways for their emergence and spread requires knowledge on human-human and human-animal contacts, but such studies are rare. We used self-completed and interviewer-completed contact diaries to quantify patterns of these contacts for 965 individuals in 2017/2018 in a high-income densely-populated area of China, Shanghai City. Interviewer-completed diaries recorded more social contacts (19.3 vs. 18.0) and longer social contact duration (35.0 vs. 29.1 hours) than self-reporting. Strong age-assortativity was observed in all age groups especially among young participants (aged 7–20) and middle aged participants (25–55 years). 17.7\% of participants reported touching animals (15.3\% (pets), 0.0\% (poultry) and 0.1\% (livestock)). Human-human contact was very frequent but contact with animals (especially poultry) was rare although associated with frequent human-human contact. Hence, this densely populated area is more likely to act as an accelerator for human-human spread but less likely to be at the source of a zoonosis outbreak. We also propose that telephone interview at the end of reporting day is a potential improvement of the design of future contact surveys.},
	journal = {Scientific Reports},
	author = {Zhang, Juanjuan and Klepac, Petra and Read, Jonathan M. and Rosello, Alicia and Wang, Xiling and Lai, Shengjie and Li, Meng and Song, Yujian and Wei, Qingzhen and Jiang, Hao and Yang, Juan and Lynn, Henry and Flasche, Stefan and Jit, Mark and Yu, Hongjie},
	year = {2019},
	pmid = {31641189},
}

@article{Zhao_2020,
	title = {Antibody responses to {SARS}-{CoV}-2 in patients of novel coronavirus disease 2019},
	issn = {15376591},
	doi = {10.1093/cid/ciaa344},
	abstract = {BACKGROUND: The novel coronavirus SARS-CoV-2 is a newly emerging virus. The antibody response in infected patient remains largely unknown, and the clinical values of antibody testing have not been fully demonstrated. METHODS: A total of 173 patients with SARS-CoV-2 infection were enrolled. Their serial plasma samples (n=535) collected during the hospitalization were tested for total antibodies (Ab), IgM and IgG against SARS-CoV-2. The dynamics of antibodies with the disease progress was analyzed. RESULTS: Among 173 patients, the seroconversion rate for Ab, IgM and IgG was 93.1\%, 82.7\% and 64.7\%, respectively. The reason for the negative antibody findings in 12 patients might due to the lack of blood samples at the later stage of illness. The median seroconversion time for Ab, IgM and then IgG were day-11, day-12 and day-14, separately. The presence of antibodies was {\textless}40\% among patients within 1-week since onset, and rapidly increased to 100.0\% (Ab), 94.3\% (IgM) and 79.8\% (IgG) since day-15 after onset. In contrast, RNA detectability decreased from 66.7\% (58/87) in samples collected before day-7 to 45.5\% (25/55) during day 15-39. Combining RNA and antibody detections significantly improved the sensitivity of pathogenic diagnosis for COVID-19 (p{\textless}0.001), even in early phase of 1-week since onset (p=0.007). Moreover, a higher titer of Ab was independently associated with a worse clinical classification (p=0.006). CONCLUSIONS: The antibody detection offers vital clinical information during the course of SARS-CoV-2 infection. The findings provide strong empirical support for the routine application of serological testing in the diagnosis and management of COVID-19 patients.},
	journal = {Clinical infectious diseases : an official publication of the Infectious Diseases Society of America},
	author = {Zhao, Juanjuan and Yuan, Quan and Wang, Haiyan and Liu, Wei and Liao, Xuejiao and Su, Yingying and Wang, Xin and Yuan, Jing and Li, Tingdong and Li, Jinxiu and Qian, Shen and Hong, Congming and Wang, Fuxiang and Liu, Yingxia and Wang, Zhaoqin and He, Qing and Li, Zhiyong and He, Bin and Zhang, Tianying and Fu, Yang and Ge, Shengxiang and Liu, Lei and Zhang, Jun and Xia, Ningshao and Zhang, Zheng},
	year = {2020},
	pmid = {32221519},
	keywords = {SARS-CoV-2, antibody, COVID-19},
}

@article{Jombart_2020,
	title = {Inferring the number of {COVID}-19 cases from recently reported deaths},
	issn = {2398502X},
	doi = {10.12688/wellcomeopenres.15786.1},
	abstract = {We estimate the number of COVID-19 cases from newly reported deaths in a population without previous reports. Our results suggest that by the time a single death occurs, hundreds to thousands of cases are likely to be present in that population. This suggests containment via contact tracing will be challenging at this point, and other response strategies should be considered. Our approach is implemented in a publicly available, user-friendly, online tool.},
	journal = {Wellcome Open Research},
	author = {Jombart, Thibaut and van Zandvoort, Kevin and Russell, Timothy W. and Jarvis, Christopher I. and Gimma, Amy and Abbott, Sam and Clifford, Sam and Funk, Sebastian and Gibbs, Hamish and Liu, Yang and Pearson, Carl A.B. and Bosse, Nikos I. and Eggo, Rosalind M. and Kucharski, Adam J. and Edmunds, W. John},
	year = {2020},
	pmid = {32511459},
	keywords = {Epidemics, Outbreak, Estimation, Statistics, Covid-19, Modelling, SARS-CoV-2},
}

@article{Cori2013,
	title = {A new framework and software to estimate time-varying reproduction numbers during epidemics},
	issn = {00029262},
	doi = {10.1093/aje/kwt133},
	abstract = {The quantification of transmissibility during epidemics is essential to designing and adjusting public health responses. Transmissibility can be measured by the reproduction number R, the average number of secondary cases caused by an infected individual. Several methods have been proposed to estimate R over the course of an epidemic; however, they are usually difficult to implement for people without a strong background in statistical modeling. Here, we present a ready-to-use tool for estimating R from incidence time series, which is implemented in popular software including Microsoft Excel (Microsoft Corporation, Redmond, Washington). This tool produces novel, statistically robust analytical estimates of R and incorporates uncertainty in the distribution of the serial interval (the time between the onset of symptoms in a primary case and the onset of symptoms in secondary cases). We applied the method to 5 historical outbreaks; the resulting estimates of R are consistent with those presented in the literature. This tool should help epidemiologists quantify temporal changes in the transmission intensity of future epidemics by using surveillance data. © The Author 2013.},
	journal = {American Journal of Epidemiology},
	author = {Cori, Anne and Ferguson, Neil M. and Fraser, Christophe and Cauchemez, Simon},
	year = {2013},
	pmid = {24043437},
	keywords = {Influenza, Smallpox, Incidence, Measles, Reproduction number, SARS, Software, cori\_2013},
}

@article{nouvellet_2018,
	title = {A simple approach to measure transmissibility and forecast incidence},
	issn = {18780067},
	doi = {10.1016/j.epidem.2017.02.012},
	abstract = {Outbreaks of novel pathogens such as SARS, pandemic influenza and Ebola require substantial investments in reactive interventions, with consequent implementation plans sometimes revised on a weekly basis. Therefore, short-term forecasts of incidence are often of high priority. In light of the recent Ebola epidemic in West Africa, a forecasting exercise was convened by a network of infectious disease modellers. The challenge was to forecast unseen “future” simulated data for four different scenarios at five different time points. In a similar method to that used during the recent Ebola epidemic, we estimated current levels of transmissibility, over variable time-windows chosen in an ad hoc way. Current estimated transmissibility was then used to forecast near-future incidence. We performed well within the challenge and often produced accurate forecasts. A retrospective analysis showed that our subjective method for deciding on the window of time with which to estimate transmissibility often resulted in the optimal choice. However, when near-future trends deviated substantially from exponential patterns, the accuracy of our forecasts was reduced. This exercise highlights the urgent need for infectious disease modellers to develop more robust descriptions of processes – other than the widespread depletion of susceptible individuals – that produce non-exponential patterns of incidence.},
	journal = {Epidemics},
	author = {Nouvellet, Pierre and Cori, Anne and Garske, Tini and Blake, Isobel M. and Dorigatti, Ilaria and Hinsley, Wes and Jombart, Thibaut and Mills, Harriet L. and Nedjati-Gilani, Gemma and Van Kerkhove, Maria D. and Fraser, Christophe and Donnelly, Christl A. and Ferguson, Neil M. and Riley, Steven},
	year = {2018},
	pmid = {28351674},
	keywords = {Forecasting, Renewal equation, Branching process, MCMC, Rapid response},
}

@article{cauchemez_2008,
	title = {Estimating the impact of school closure on influenza transmission from {Sentinel} data},
	issn = {14764687},
	doi = {10.1038/nature06732},
	abstract = {The threat posed by the highly pathogenic H5N1 influenza virus requires public health authorities to prepare for a human pandemic. Although pre-pandemic vaccines and antiviral drugs might significantly reduce illness rates, their stockpiling is too expensive to be practical for many countries. Consequently, alternative control strategies, based on non-pharmaceutical interventions, are a potentially attractive policy option. School closure is the measure most often considered. The high social and economic costs of closing schools for months make it an expensive and therefore controversial policy, and the current absence of quantitative data on the role of schools during influenza epidemics means there is little consensus on the probable effectiveness of school closure in reducing the impact of a pandemic. Here, from the joint analysis of surveillance data and holiday timing in France, we quantify the role of schools in influenza epidemics and predict the effect of school closure during a pandemic. We show that holidays lead to a 20-29\% reduction in the rate at which influenza is transmitted to children, but that they have no detectable effect on the contact patterns of adults. Holidays prevent 16-18\% of seasonal influenza cases (18-21\% in children). By extrapolation, we find that prolonged school closure during a pandemic might reduce the cumulative number of cases by 13-17\% (18-23\% in children) and peak attack rates by up to 39-45\% (47-52\% in children). The impact of school closure would be reduced if it proved difficult to maintain low contact rates among children for a prolonged period. ©2008 Nature Publishing Group.},
	journal = {Nature},
	author = {Cauchemez, Simon and Valleron, Alain Jacques and Boëlle, Pierre Yves and Flahault, Antoine and Ferguson, Neil M.},
	year = {2008},
	pmid = {18401408},
}

@article{fraser_2007,
	title = {Estimating individual and household reproduction numbers in an emerging epidemic},
	issn = {19326203},
	doi = {10.1371/journal.pone.0000758},
	abstract = {Reproduction numbers, defined as averages of the number of people infected by a typical case, play a central role in tracking infectious disease outbreaks. The aim of this paper is to develop methods for estimating reproduction numbers which are simple enough that they could be applied with limited data or in real time during an outbreak. I present a new estimator for the individual reproduction number, which describes the state of the epidemic at a point in time rather than tracking individuals over time, and discuss some potential benefits. Then, to capture more of the detail that micro-simulations have shown is important in outbreak dynamics, I analyse a model of transmission within and between households, and develop a method to estimate the household reproduction number, defined as the number of households infected by each infected household. This method is validated by numerical simulations of the spread of influenza and measles using historical data, and estimates are obtained for would-be emerging epidemics of these viruses. I argue that the household reproduction number is useful in assessing the impact of measures that target the household for isolation, quarantine, vaccination or prophylactic treatment, and measures such as social distancing and school or workplace closures which limit between-household transmission, all of which play a key role in current thinking on future infectious disease mitigation. © 2007 Christophe Fraser.},
	journal = {PLoS ONE},
	author = {Fraser, Christophe},
	year = {2007},
	pmid = {17712406},
}

@article{bellman_1952,
	title = {On {Age}-{Dependent} {Binary} {Branching} {Processes}},
	issn = {0003486X},
	doi = {10.2307/1969779},
	journal = {The Annals of Mathematics},
	author = {Bellman, Richard and Harris, Theodore},
	year = {1952},
}

@article{bellman_1948,
	title = {On the {Theory} of {Age}-{Dependent} {Stochastic} {Branching} {Processes}},
	issn = {0027-8424},
	doi = {10.1073/pnas.34.12.601},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bellman, R. and Harris, T. E.},
	year = {1948},
	pmid = {16588841},
}

@article{ferguson_2006,
	title = {Strategies for mitigating an influenza pandemic},
	issn = {14764687},
	doi = {10.1038/nature04795},
	abstract = {Development of strategies for mitigating the severity of a new influenza pandemic is now a top global public health priority. Influenza prevention and containment strategies can be considered under the broad categories of antiviral, vaccine and non-pharmaceutical (case isolation, household quarantine, school or workplace closure, restrictions on travel) measures. Mathematical models are powerful tools for exploring this complex landscape of intervention strategies and quantifying the potential costs and benefits of different options. Here we use a large-scale epidemic simulation to examine intervention options should initial containment of a novel influenza outbreak fail, using Great Britain and the United States as examples. We find that border restrictions and/or internal travel restrictions are unlikely to delay spread by more than 2-3 weeks unless more than 99\% effective. School closure during the peak of a pandemic can reduce peak attack rates by up to 40\%, but has little impact on overall attack rates, whereas case isolation or household quarantine could have a significant impact, if feasible. Treatment of clinical cases can reduce transmission, but only if antivirals are given within a day of symptoms starting. Given enough drugs for 50\% of the population, household-based prophylaxis coupled with reactive school closure could reduce clinical attack rates by 40-50\%. More widespread prophylaxis would be even more logistically challenging but might reduce attack rates by over 75\%. Vaccine stockpiled in advance of a pandemic could significantly reduce attack rates even if of low efficacy. Estimates of policy effectiveness will change if the characteristics of a future pandemic strain differ substantially from those seen in past pandemics. © 2006 Nature Publishing Group.},
	journal = {Nature},
	author = {Ferguson, Neil M. and Cummings, Derek A.T. and Fraser, Christophe and Cajka, James C. and Cooley, Philip C. and Burke, Donald S.},
	year = {2006},
	pmid = {16642006},
}

@article{fraser_2004,
	title = {Factors that make an infectious disease outbreak controllable},
	issn = {00278424},
	doi = {10.1073/pnas.0307506101},
	abstract = {The aim of this study is to identify general properties of emerging infectious agents that determine the likely success of two simple public health measures in controlling outbreaks, namely (i) isolating symptomatic individuals and (ii) tracing and quarantining their contacts. Because these measures depend on the recognition of specific disease symptoms, we investigate the relative timing of infectiousness and the appearance of symptoms by using a mathematical model. We show that the success of these control measures is determined as much by the proportion of transmission occurring prior to the onset of overt clinical symptoms (or via asymptomatic infection) as the inherent transmissibility of the etiological agent (measured by the reproductive number R0). From published studies, we estimate these quantities for two moderately transmissible viruses, severe acute respiratory syndrome coronavirus and HIV, and for two highly transmissible viruses, smallpox and pandemic influenza. We conclude that severe acute respiratory syndrome and smallpox are easier to control using these simple public health measures. Direct estimation of the proportion of asymptomatic and presymptomatic infections is achievable by contact tracing and should be a priority during an outbreak of a novel infectious agent.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Fraser, Christophe and Riley, Steven and Anderson, Roy M. and Ferguson, Neil M.},
	year = {2004},
	pmid = {15071187},
	keywords = {Epidemiology, Influenza, Severe acute respiratory syndrome, HIV, Smallpox},
}

@article{anderson_1982,
	title = {Directly transmitted infectious diseases: {Control} by vaccination},
	issn = {00368075},
	doi = {10.1126/science.7063839},
	abstract = {Mathematical models for the dynamics of directly transmitted viral and bacterial infections are guides to the understanding of observed patterns in the age-specific incidence of some common childhood diseases of humans, before and after the advent of vaccination programs. For those infections that show recurrent epidemic behavior, the interepidemic period can be related to parameters characterizing the infection (such as latent and infectious periods and the average age of first infection); this relation agrees with the data for a variety of childhood diseases. Criteria for the eradication of a disease are given, in terms of the proportion of the population to be vaccinated and the age-specific vaccination schedule. These criteria are compared with a detailed analysis of the vaccination programs against measles and whooping cough in Britain, and estimates are made of the levels of protection that would be needed to eradicate these diseases.},
	journal = {Science},
	author = {Anderson, Roy M. and May, Robert M.},
	year = {1982},
	pmid = {7063839},
}

@book{anderson_1992,
	title = {Infectious diseases of humans: dynamics and control},
	publisher = {Oxford university press},
	author = {Anderson, Roy M {and} Anderson, B {and} May, Robert M},
	year = {1992},
}

@article{kermack_1927,
	title = {A contribution to the mathematical theory of epidemics},
	issn = {0950-1207},
	doi = {10.1098/rspa.1927.0118},
	abstract = {(1) One of the most striking features in the study of epidemics is the difficulty of finding a causal factor which appears to be adequate to account for the magnitude of the frequent epidemics of disease which visit almost every population. It was with a view to obtaining more insight regarding the effects of the various factors which govern the spread of contagious epidemics that the present investigation was undertaken. Reference may here be made to the work of Ross and Hudson (1915-17) in which the same problem is attacked. The problem is here carried to a further stage, and it is considered from a point of view which is in one sense more general. The problem may be summarised as follows: One (or more) infected person is introduced into a community of individuals, more or less susceptible to the disease in question. The disease spreads from the affected to the unaffected by contact infection. Each infected person runs through the course of his sickness, and finally is removed from the number of those who are sick, by recovery or by death. The chances of recovery or death vary from day to day during the course of his illness. The chances that the affected may convey infection to the unaffected are likewise dependent upon the stage of the sickness. As the epidemic spreads, the number of unaffected members of the community becomes reduced. Since the course of an epidemic is short compared with the life of an individual, the population may be considered as remaining constant, except in as far as it is modified by deaths due to the epidemic disease itself. In the course of time the epidemic may come to an end. One of the most important probems in epidemiology is to ascertain whether this termination occurs only when no susceptible individuals are left, or whether the interplay of the various factors of infectivity, recovery and mortality, may result in termination, whilst many susceptible individuals are still present in the unaffected population. It is difficult to treat this problem in its most general aspect. In the present communication discussion will be limited to the case in which all members of the community are initially equally susceptible to the disease, and it will be further assumed that complete immunity is conferred by a single infection.},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	author = {Kermack, William Ogilvy {and} McKendrick, A. G.},
	year = {1927},
}

@article{wallinga_2004,
	title = {Different epidemic curves for severe acute respiratory syndrome reveal similar impacts of control measures},
	issn = {00029262},
	doi = {10.1093/aje/kwh255},
	abstract = {Severe acute respiratory syndrome (SARS) has been the first severe contagious disease to emerge in the 21st century. The available epidemic curves for SARS show marked differences between the affected regions with respect to the total number of cases and epidemic duration, even for those regions in which outbreaks started almost simultaneously and similar control measures were implemented at the same time. The authors developed a likelihood-based estimation procedure that infers the temporal pattern of effective reproduction numbers from an observed epidemic curve. Precise estimates for the effective reproduction numbers were obtained by applying this estimation procedure to available data for SARS outbreaks that occurred in Hong Kong, Vietnam, Singapore, and Canada in 2003. The effective reproduction numbers revealed that epidemics in the various affected regions were characterized by markedly similar disease transmission potentials and similar levels of effectiveness of control measures. In controlling SARS outbreaks, timely alerts have been essential: Delaying the institution of control measures by 1 week would have nearly tripled the epidemic size and would have increased the expected epidemic duration by 4 weeks.},
	journal = {American Journal of Epidemiology},
	author = {Wallinga, Jacco and Teunis, Peter},
	year = {2004},
	pmid = {15353409},
	keywords = {Disease outbreaks, Estimation, Infection, Models, SARS virus, Severe acute respiratory syndrome, statistical, Statistics},
}

@techreport{who_2003,
	title = {{SARS}: chronology of a serial killer.},
	institution = {World Health Organization},
	author = {WHO},
	year = {2003},
}

@techreport{hksar_2003,
	address = {Hong Kong},
	title = {Chronology of the {SARS} epidemic in {Hong} {Kong}.},
	institution = {SARS Expert Committee of HKSAR Government},
	author = {Government., SARS Expert Committee of HKSAR},
	year = {2003},
}

@article{champredon_2018,
	title = {Equivalence of the {Erlang}-distributed {SEIR} epidemic model and the renewal equation},
	issn = {00361399},
	doi = {10.1137/18M1186411},
	abstract = {Most compartmental epidemic models can be represented using the renewal equation. The value of the renewal equation is not widely appreciated in the epidemiological modelling community, perhaps because its equivalence to standard models has not been presented rigorously in nontrivial cases. Here, we provide analytical expressions for the intrinsic generation-interval distribution that must be used in the renewal equation in order to yield epidemic dynamics that are identical to those of the susceptible-exposed-infectious-recovered (SEIR) compartmental model with Erlang-distributed latent and infectious periods. This class of models includes the standard (exponentially distributed) SIR and SEIR models as special cases.},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Champredon, David and Dushoff, Jonathan and Earn, David J.D.},
	year = {2018},
	keywords = {Differential equations, Epidemic models, Erlang distribution, Generation-interval distribution, Renewal equation, SEIR},
}

@incollection{getz_2006,
	title = {Basic methods for modeling the invasion and spread of contagious diseases},
	abstract = {The evolution of disease requires a firm understanding of hetero-geneity among pathogen strains and hosts with regard to the processes of transmission, movement, recovery, and pathobiology. In this and a companion chapter (Getz et al. this volume), we focus on the question of how to model the invasion and spread of diseases in heterogeneous environments, without making an explicit link to natural selection-the topic of other chapters in this volume. We begin in this chapter by providing an overview of current methods used to model epidemics in homogeneous populations, covering continuous and discrete time formulations in both deterministic and stochastic frameworks. In particular, we introduce Kermack and McKendricks SIR (susceptible, infected, removed) formulation for the case where the removed (R) disease class is partitioned into immune (V class) and dead (D class) individuals. We also focus on transmission, contrasting mass-action and frequency-dependent formulations and results. This is followed by a presentation of various extensions including the consideration of the latent period of infection, the staging of disease classes, and the addition of vital and demographic processes. We then discuss the relative merits of continuous versus discrete time formulations to model real systems, particularly in the context of stochastic analyses. The overview is completed with a presentation of basic branching process theory as a sto-chastic generation-based model for the invasion of disease into populations of infinite size, with numerical extensions generalizing results to populations of finite size. In framework of branching process theory, we explore the question of minor versus major stochastic epidemics and illuminate the relationship between minor epidemics and a deterministic theory of disease invasion, as well as major epidemics and the deterministic theory of disease establishment. We conclude this chapter with a demonstration of how the basic ideas can be used to model containment policies associated with the outbreak of SARS in Asia in the early part of 2003.},
	booktitle = {Disease {Evolution}: {Models}, {Concepts}, and {Data} {Analyses}},
	publisher = {DIMACS Series in Discrete Mathematics and Theoretical Computer Science},
	author = {Getz, Wayne and Lloyd-Smith, James},
	year = {2006},
	doi = {10.1090/dimacs/071/05},
}

@article{bartoszynski_1967,
	title = {Branching {Processes} and the {Theory} of {Epidemics}},
	abstract = {1. Introduction In the present paper we shall discuss the extinction problem for certain branching processes. Our main purpose is to study those branching processes which can serve as models of epidemics; that is, spreads of an infectious disease. The phenomenon of epidemics is fairly complex, and all models necessarily have to be based on a certain compromise. This compromise consists of taking into account some of the (presumably important) factors governiing the spread of the disease at the cost of neglecting others. Our main idealization will consist of assuming such mechanisms of infection which yield a brailching process. Using informal language, it means that all infectives present in the population at a given time infect the susceptibles independently of each other. More precisely, if there are 7c infectives in the nth generation of the epidemics, then the distri-bution of the next (n + 1)st generation can be represented as the distribution of a sum of k independent, identically distributed random variables, with a specified distribution. These random variables represent the "progeny" of k infectives of nth generation. It is debatable whether the above assumption is justifiedlin the sense that},
	journal = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability},
	author = {Bartoszynski, Robert},
	year = {1967},
}

@misc{stan_2020,
	title = {The \{{Stan}\} {Core} {Library}},
	url = {http://mc-stan.org/},
	author = {{Stan Development Team}},
	year = {2018},
	annote = {Version 2.18.0},
}

@misc{scott_2020,
	title = {epidemia: {Modeling} of {Epidemics} using {Hierarchical} {Bayesian} {Models}},
	url = {https://imperialcollegelondon.github.io/epidemia/},
	author = {Scott, James A and Gandy, Axel and Mishra, Swapnil and Unwin, Juliette and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
	annote = {R package version 0.6.0},
}

@misc{rcore_2011,
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {R Core Team},
	year = {2020},
	doi = {10.1007/978-3-540-74686-7},
	note = {Publication Title: R Foundation for Statistical Computing
ISSN: 16000706},
}

@misc{rstan_2020,
	title = {\{{RStan}\}: the \{{R}\} interface to \{{Stan}\}},
	url = {http://mc-stan.org/},
	author = {{Stan Development Team}},
	year = {2020},
	annote = {R package version 2.21.2},
}

@misc{goodrich_2020,
	title = {rstanarm: \{{Bayesian}\} applied regression modeling via \{{Stan}\}.},
	url = {https://mc-stan.org/rstanarm},
	author = {Goodrich, Ben and Gabry, Jonah and Ali, Imad and Brilleman, Sam},
	year = {2020},
	annote = {R package version 2.21.1},
}

@article{bates_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} \{lme4\}},
	volume = {67},
	doi = {10.18637/jss.v067.i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	year = {2015},
	pages = {1--48},
}

@article{badr_2020,
	title = {Association between mobility patterns and {COVID}-19 transmission in the {USA}: a mathematical modelling study},
	issn = {14744457},
	doi = {10.1016/S1473-3099(20)30553-3},
	abstract = {Background: Within 4 months of COVID-19 first being reported in the USA, it spread to every state and to more than 90\% of all counties. During this period, the US COVID-19 response was highly decentralised, with stay-at-home directives issued by state and local officials, subject to varying levels of enforcement. The absence of a centralised policy and timeline combined with the complex dynamics of human mobility and the variable intensity of local outbreaks makes assessing the effect of large-scale social distancing on COVID-19 transmission in the USA a challenge. Methods: We used daily mobility data derived from aggregated and anonymised cell (mobile) phone data, provided by Teralytics (Zürich, Switzerland) from Jan 1 to April 20, 2020, to capture real-time trends in movement patterns for each US county, and used these data to generate a social distancing metric. We used epidemiological data to compute the COVID-19 growth rate ratio for a given county on a given day. Using these metrics, we evaluated how social distancing, measured by the relative change in mobility, affected the rate of new infections in the 25 counties in the USA with the highest number of confirmed cases on April 16, 2020, by fitting a statistical model for each county. Findings: Our analysis revealed that mobility patterns are strongly correlated with decreased COVID-19 case growth rates for the most affected counties in the USA, with Pearson correlation coefficients above 0·7 for 20 of the 25 counties evaluated. Additionally, the effect of changes in mobility patterns, which dropped by 35–63\% relative to the normal conditions, on COVID-19 transmission are not likely to be perceptible for 9–12 days, and potentially up to 3 weeks, which is consistent with the incubation time of severe acute respiratory syndrome coronavirus 2 plus additional time for reporting. We also show evidence that behavioural changes were already underway in many US counties days to weeks before state-level or local-level stay-at-home policies were implemented, implying that individuals anticipated public health directives where social distancing was adopted, despite a mixed political message. Interpretation: This study strongly supports a role of social distancing as an effective way to mitigate COVID-19 transmission in the USA. Until a COVID-19 vaccine is widely available, social distancing will remain one of the primary measures to combat disease spread, and these findings should serve to support more timely policy making around social distancing in the USA in the future. Funding: None.},
	journal = {The Lancet Infectious Diseases},
	author = {Badr, Hamada S. and Du, Hongru and Marshall, Maximilian and Dong, Ensheng and Squire, Marietta M. and Gardner, Lauren M.},
	year = {2020},
	pmid = {32621869},
}

@book{hox_2010,
	title = {Multilevel analysis: {Techniques} and applications},
	publisher = {Routledge},
	author = {Hox, Joop J and Moerbeek, Mirjam and de Schoot, Rens},
	year = {2010},
}

@book{gelman_2006,
	title = {Data {Analysis} {Using} {Regression} and {Multilevel}/{Hierarchical} {Models}},
	abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout. Author resource page: http://www.stat.columbia.edu/{\textasciitilde}gelman/arm/},
	publisher = {Cambridge University Press},
	author = {Gelman, Andrew and Hill, Jennifer},
	year = {2006},
	doi = {10.1017/cbo9780511790942},
	note = {Publication Title: Data Analysis Using Regression and Multilevel/Hierarchical Models},
}

@article{Cowling2020,
	title = {Impact assessment of non-pharmaceutical interventions against coronavirus disease 2019 and influenza in {Hong} {Kong}: an observational study},
	issn = {24682667},
	doi = {10.1016/S2468-2667(20)30090-6},
	abstract = {Background: A range of public health measures have been implemented to suppress local transmission of coronavirus disease 2019 (COVID-19) in Hong Kong. We examined the effect of these interventions and behavioural changes of the public on the incidence of COVID-19, as well as on influenza virus infections, which might share some aspects of transmission dynamics with COVID-19. Methods: We analysed data on laboratory-confirmed COVID-19 cases, influenza surveillance data in outpatients of all ages, and influenza hospitalisations in children. We estimated the daily effective reproduction number (Rt) for COVID-19 and influenza A H1N1 to estimate changes in transmissibility over time. Attitudes towards COVID-19 and changes in population behaviours were reviewed through three telephone surveys done on Jan 20–23, Feb 11–14, and March 10–13, 2020. Findings: COVID-19 transmissibility measured by Rt has remained at approximately 1 for 8 weeks in Hong Kong. Influenza transmission declined substantially after the implementation of social distancing measures and changes in population behaviours in late January, with a 44\% (95\% CI 34–53\%) reduction in transmissibility in the community, from an estimated Rt of 1·28 (95\% CI 1·26–1·30) before the start of the school closures to 0·72 (0·70–0·74) during the closure weeks. Similarly, a 33\% (24–43\%) reduction in transmissibility was seen based on paediatric hospitalisation rates, from an Rt of 1·10 (1·06–1·12) before the start of the school closures to 0·73 (0·68–0·77) after school closures. Among respondents to the surveys, 74·5\%, 97·5\%, and 98·8\% reported wearing masks when going out, and 61·3\%, 90·2\%, and 85·1\% reported avoiding crowded places in surveys 1 (n=1008), 2 (n=1000), and 3 (n=1005), respectively. Interpretation: Our study shows that non-pharmaceutical interventions (including border restrictions, quarantine and isolation, distancing, and changes in population behaviour) were associated with reduced transmission of COVID-19 in Hong Kong, and are also likely to have substantially reduced influenza transmission in early February, 2020. Funding: Health and Medical Research Fund, Hong Kong.},
	journal = {The Lancet Public Health},
	author = {Cowling, Benjamin J. and Ali, Sheikh Taslim and Ng, Tiffany W.Y. and Tsang, Tim K. and Li, Julian C.M. and Fong, Min Whui and Liao, Qiuyan and Kwan, Mike YW and Lee, So Lun and Chiu, Susan S. and Wu, Joseph T. and Wu, Peng and Leung, Gabriel M.},
	year = {2020},
	pmid = {32311320},
}

@book{kreft_2011,
	title = {Introducing {Multilevel} {Modeling}},
	abstract = {This is a user-oriented guide to the practicalities of multilevel modeling in social research. The authors introduce the researcher to the practical issues and problems of doing multilevel analyses. On the basis of genuine data sets, they illustrate the technique through worked examples, using the leading computer package for multilevel modeling, MLn. This book will be useful for students and researchers who need to know how to apply multilevel models appropriately and effectively. (PsycINFO Database Record (c) 2003 APA, all rights reserved)},
	publisher = {SAGE Publications Ltd},
	author = {Kreft, Ita and de Leeuw, Jan},
	year = {2011},
	doi = {10.4135/9781849209366},
	note = {Publication Title: Introducing Multilevel Modeling},
}

@article{fraser_2009,
	title = {Pandemic potential of a strain of influenza {A} ({H1N1}): {Early} findings},
	issn = {00368075},
	doi = {10.1126/science.1176062},
	abstract = {A novel influenza A (H1N1) virus has spread rapidly across the globe. Judging its pandemic potential is difficult with limited data, but nevertheless essential to inform appropriate health responses. By analyzing the outbreak in Mexico, early data on international spread, and viral genetic diversity, we make an early assessment of transmissibility and severity. Our estimates suggest that 23,000 (range 6000 to 32,000) individuals had been infected in Mexico by late April, giving an estimated case fatality ratio (CFR) of 0.4\% (range: 0.3 to 1.8\%) based on confirmed and suspected deaths reported to that time. In a community outbreak in the small community of La Gloria, Veracruz, no deaths were attributed to infection, giving an upper 95\% bound on CFR of 0.6\%. Thus, although substantial uncertainty remains, clinical severity appears less than that seen in the 1918 influenza pandemic but comparable with that seen in the 1957 pandemic. Clinical attack rates in children in La Gloria were twice that in adults ({\textless}15 years of age: 61\%; =15 years: 29\%). Three different epidemiological analyses gave basic reproduction number (R0) estimates in the range of 1.4 to 1.6, whereas a genetic analysis gave a central estimate of 1.2. This range of values is consistent with 14 to 73 generations of human-to-human transmission having occurred in Mexico to late April. Transmissibility is therefore substantially higher than that of seasonal flu, and comparable with lower estimates of R0 obtained from previous influenza pandemics.},
	journal = {Science},
	author = {Fraser, Christophe and Donnelly, Christl A. and Cauchemez, Simon and Hanage, William P. and Van Kerkhove, Maria D. and Hollingsworth, T. Déirdre and Griffin, Jamie and Baggaley, Rebecca F. and Jenkins, Helen E. and Lyons, Emily J. and Jombart, Thibaut and Hinsley, Wes R. and Grassly, Nicholas C. and Balloux, Francois and Ghani, Azra C. and Ferguson, Neil M. and Rambaut, Andrew and Pybus, Oliver G. and Lopez-Gatell, Hugo and Alpuche-Aranda, Celia M. and Chapela, Ietza Bojorquez and Zavala, Ethel Palacios and Ma. Espejo Guevara, Dulce and Checchi, Francesco and Garcia, Erika and Hugonnet, Stephane and Roth, Cathy},
	year = {2009},
	pmid = {19433588},
}

@article{miller_2020,
	title = {Mobility trends provide a leading indicator of changes in {SARS}-{CoV}-2 transmission},
	url = {https://www.medrxiv.org/content/early/2020/05/11/2020.05.07.20094441},
	doi = {10.1101/2020.05.07.20094441},
	journal = {medRxiv},
	author = {Miller, Andrew C and Foti, Nicholas J and Lewnard, Joseph A and Jewell, Nicholas P and Guestrin, Carlos and Fox, Emily B},
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory Press},
}

@article{riley_2003,
	title = {Transmission dynamics of the etiological agent of {SARS} in {Hong} {Kong}: {Impact} of public health interventions},
	issn = {00368075},
	doi = {10.1126/science.1086478},
	abstract = {We present an analysis of the first 10 weeks of the severe acute respiratory syndrome (SARS) epidemic in Hong Kong. The epidemic to date has been characterized by two large clusters - initiated by two separate "super-spread" events (SSEs) - and by ongoing community transmission. By fitting a stochastic model to data on 1512 cases, including these clusters, we show that the etiological agent of SARS is moderately transmissible. Excluding SSES, we estimate that 2.7 secondary infections were generated per case on average at the start of the epidemic, with a substantial contribution from hospital transmission. Transmission rates fell during the epidemic, primarily as a result of reductions in population contact rates and improved hospital infection control, but also because of more rapid hospital attendance by symptomatic individuals. As a result, the epidemic is now in decline, although continued vigilance is necessary for this to be maintained. Restrictions on longer range population movement are shown to be a potentially useful additional control measure in some contexts. We estimate that most currently infected persons are now hospitalized, which highlights the importance of control of nosocomial transmission.},
	journal = {Science},
	author = {Riley, Steven and Fraser, Christophe and Donnelly, Christl A. and Ghani, Azra C. and Abu-Raddad, Laith J. and Hedley, Anthony J. and Leung, Gabriel M. and Ho, Lai Ming and Lam, Tai Hing and Thach, Thuan Q. and Chau, Patsy and Chan, King Pan and Lo, Su Vui and Leung, Pak Yin and Tsang, Thomas and Ho, William and Lee, Koon Hung and Lau, Edith M.C. and Ferguson, Neil M. and Anderson, Roy M.},
	year = {2003},
	pmid = {12766206},
}

@article{bettencourt_2008,
	title = {Real time bayesian estimation of the epidemic potential of emerging infectious diseases},
	issn = {19326203},
	doi = {10.1371/journal.pone.0002185},
	abstract = {Background: Fast changes in human demographics worldwide, coupled with increased mobility, and modified land uses make the threat of emerging infectious diseases increasingly important. Currently there is worldwide alert for H5N1 avian influenza becoming as transmissible in humans as seasonal influenza, and potentially causing a pandemic of unprecedented proportions. Here we show how epidemiological surveillance data for emerging infectious diseases can be interpreted in real time to assess changes in transmissibility with quantified uncertainty, and to perform running time predictions of new cases and guide logistics allocations. Methodology/Principal Findings: We develop an extension of standard epidemiological models, appropriate for emerging infectious diseases, that describes the probabilistic progression of case numbers due to the concurrent effects of (incipient) human transmission and multiple introductions from a reservoir. The model is cast in terms of surveillance observables and immediately suggests a simple graphical estimation procedure for the effective reproductive number R (mean number of cases generated by an infectious individual) of standard epidemics. For emerging infectious diseases, which typically show large relative case number fluctuations over time, we develop a Bayesian scheme for real time estimation of the probability distribution of the effective reproduction number and show how to use such inferences to formulate significance tests on future epidemiological observations. Conclusions/Significance: Violations of these significance tests define statistical anomalies that may signal changes in the epidemiology of emerging diseases and should trigger further field investigation. We apply the methodology to case data from World Health Organization reports to place bounds on the current transmissibility of H5N1 influenza in humans and establish a statistical basis for monitoring its evolution in real time. © 2008 Bettencourt, Ribeiro.},
	journal = {PLoS ONE},
	author = {Bettencourt, Luís M.A. and Ribeiro, Ruy M.},
	year = {2008},
	pmid = {18478118},
}

@article{ferguson_2001,
	title = {Transmission intensity and impact of control policies on the foot and mouth epidemic in {Great} {Britain}},
	issn = {00280836},
	doi = {10.1038/35097116},
	abstract = {The foot and mouth disease (FMD) epidemic in British livestock remains an ongoing cause for concern, with new cases still arising in previously unaffected areas. Epidemiological analyses have been vital in delivering scientific advice to government on effective control measures. Using disease, culling and census data on all livestock farms in Great Britain, we analysed the risk factors determining the spatiotemporal evolution of the epidemic and of the impact of control policies on FMD incidence. Here we show that the species mix, animal numbers and the number of distinct land parcels in a farm are central to explaining regional variation in transmission intensity. We use the parameter estimates thus obtained in a dynamical model of disease spread to show that extended culling programmes were essential for controlling the epidemic to the extent achieved, but demonstrate that the epidemic could have been substantially reduced in scale had the most efficient control measures been rigorously applied earlier.},
	journal = {Nature},
	author = {Ferguson, N. M. and Donnelly, C. A. and Anderson, R. M.},
	year = {2001},
	pmid = {11586365},
}

@article{kelly_2010,
	title = {Pandemic ({H1N1}) 2009 influenza community transmission was established in one {Australian} state when the virus was first identified in {North} {America}},
	issn = {19326203},
	doi = {10.1371/journal.pone.0011341},
	abstract = {Background: In mid-June 2009 the State of Victoria in Australia appeared to have the highest notification rate of pandemic (H1N1) 2009 influenza in the world. We hypothesise that this was because community transmission of pandemic influenza was already well established in Victoria at the time testing for the novel virus commenced. In contrast, this was not true for the pandemic in other parts of Australia, including Western Australia (WA). Methods: We used data from detailed case follow-up of patients with confirmed infection in Victoria and WA to demonstrate the difference in the pandemic curve in two Australian states on opposite sides of the continent. We modelled the pandemic in both states, using a susceptible-infected-removed model with Bayesian inference accounting for imported cases. Results: Epidemic transmission occurred earlier in Victoria and later in WA. Only 5\% of the first 100 Victorian cases were not locally acquired and three of these were brothers in one family. By contrast, 53\% of the first 102 cases in WA were associated with importation from Victoria. Using plausible model input data, estimation of the effective reproductive number for the Victorian epidemic required us to invoke an earlier date for commencement of transmission to explain the observed data. This was not required in modelling the epidemic in WA. Conclusion: Strong circumstantial evidence, supported by modelling, suggests community transmission of pandemic influenza was well established in Victoria, but not in WA, at the time testing for the novel virus commenced in Australia. The virus is likely to have entered Victoria and already become established around the time it was first identified in the US and Mexico. © 2010 Kelly et al.},
	journal = {PLoS ONE},
	author = {Kelly, Heath A. and Mercer, Geoff N. and Fielding, James E. and Dowse, Gary K. and Glass, Kathryn and Carcione, Dale and Grant, Kristina A. and Effler, Paul V. and Lester, Rosemary A.},
	year = {2010},
	pmid = {20596536},
}

@article{newman_2006,
	title = {Modularity and community structure in networks},
	issn = {00278424},
	doi = {10.1073/pnas.0601602103},
	abstract = {Many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. The problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. One highly effective approach is the optimization of the quality function known as "modularity" over the possible divisions of a network. Here I show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which I call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. I illustrate the method with applications to several published network data sets. © 2006 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Newman, M. E.J.},
	year = {2006},
	pmid = {16723398},
	keywords = {Clustering, Metabolic network, Modules, Partitioning, Social network},
}

@article{fortunato_2010,
	title = {Community detection in graphs},
	issn = {03701573},
	doi = {10.1016/j.physrep.2009.11.002},
	abstract = {The modern science of networks has brought significant advances to our understanding of complex systems. One of the most relevant features of graphs representing real systems is community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph, playing a similar role like, e.g., the tissues or the organs in the human body. Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of scientists working on it over the past few years. We will attempt a thorough exposition of the topic, from the definition of the main elements of the problem, to the presentation of most methods developed, with a special focus on techniques designed by statistical physicists, from the discussion of crucial issues like the significance of clustering and how methods should be tested and compared against each other, to the description of applications to real networks. © 2009 Elsevier B.V.},
	journal = {Physics Reports},
	author = {Fortunato, Santo},
	year = {2010},
	keywords = {Clusters, Statistical physics, Graphs},
}

@article{lancichinetti_2010,
	title = {Statistical significance of communities in networks},
	issn = {15393755},
	doi = {10.1103/PhysRevE.81.046110},
	abstract = {Nodes in real-world networks are usually organized in local modules. These groups, called communities, are intuitively defined as subgraphs with a larger density of internal connections than of external links. In this work, we define a measure aimed at quantifying the statistical significance of single communities. Extreme and order statistics are used to predict the statistics associated with individual clusters in random graphs. These distributions allows us to define one community significance as the probability that a generic clustering algorithm finds such a group in a random graph. The method is successfully applied in the case of real-world networks for the evaluation of the significance of their communities. © 2010 The American Physical Society.},
	journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
	author = {Lancichinetti, Andrea and Radicchi, Filippo and Ramasco, José J.},
	year = {2010},
}

@article{bianconi_2009,
	title = {Assessing the relevance of node features for network structure},
	issn = {00278424},
	doi = {10.1073/pnas.0811511106},
	abstract = {Networks describe a variety of interacting complex systems in social science, biology, and information technology. Usually the nodes of real networks are identified not only by their connections but also by some other characteristics. Examples of characteristics of nodes can be age, gender, or nationality of a person in a social network, the abundance of proteins in the cell taking part in protein-interaction networks, or the geographical position of airports that are connected by directed flights. Integrating the information on the connections of each node with the information about its characteristics is crucial to discriminating between the essential and negligible characteristics of nodes for the structure of the network. In this paper we propose a general indicator Θ, based on entropy measures, to quantify the dependence of a network's structure on a given set of features. We apply this method to social networks of friendships in U.S. schools, to the protein-interaction network of Saccharomyces cerevisiae and to the U.S. airport network, showing that the proposed measure provides information that complements other known measures.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Bianconia, Ginestra and Pinb, Paolo and Marsilia, Matteo},
	year = {2009},
	pmid = {19571013},
	keywords = {Social networks, Communities, Entropy, Inference},
}

@article{newman_2004,
	title = {Fast algorithm for detecting community structure in networks},
	issn = {1063651X},
	doi = {10.1103/PhysRevE.69.066133},
	abstract = {Many networks display community structure—groups of vertices within which connections are dense but between which they are sparser—and sensitive computer algorithms have in recent years been developed for detecting this structure. These algorithms, however, are computationally demanding, which limits their application to small networks. Here we describe an algorithm which gives excellent results when tested on both computer-generated and real-world networks and is much faster, typically thousands of times faster, than previous algorithms. We give several example applications, including one to a collaboration network of more than 50?000 physicists. © 2004 The American Physical Society.},
	journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
	author = {Newman, M. E.J.},
	year = {2004},
}

@article{clauset_2004,
	title = {Finding community structure in very large networks},
	issn = {1063651X},
	doi = {10.1103/PhysRevE.70.066111},
	abstract = {The discovery and analysis of community structure in networks is a topic of considerable recent interest within the physics community, but most methods proposed so far are unsuitable for very large networks because of their computational cost. Here we present a hierarchical agglomeration algorithm for detecting community structure which is faster than many competing algorithms: its running time on a network with [Formula presented] vertices and [Formula presented] edges is [Formula presented] where [Formula presented] is the depth of the dendrogram describing the community structure. Many real-world networks are sparse and hierarchical, with [Formula presented] and [Formula presented], in which case our algorithm runs in essentially linear time, [Formula presented]. As an example of the application of this algorithm we use it to analyze a network of items for sale on the web site of a large on-line retailer, items in the network being linked if they are frequently purchased by the same buyer. The network has more than 400?000 vertices and [Formula presented] edges. We show that our algorithm can extract meaningful communities from this network, revealing large-scale patterns present in the purchasing habits of customers. © 2004 The American Physical Society.},
	journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
	author = {Clauset, Aaron and Newman, M. E.J. and Moore, Cristopher},
	year = {2004},
	pmid = {15697438},
}

@article{blondel_2008,
	title = {Fast unfolding of communities in large networks},
	issn = {17425468},
	doi = {10.1088/1742-5468/2008/10/P10008},
	abstract = {We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad hoc modular networks. © 2008 IOP Publishing Ltd.},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Blondel, Vincent D. and Guillaume, Jean Loup and Lambiotte, Renaud and Lefebvre, Etienne},
	year = {2008},
	keywords = {Networks, New applications of statistical mechanics, Random graphs},
}

@article{mucha_2010,
	title = {Community structure in time-dependent, multiscale, and multiplex networks},
	issn = {00368075},
	doi = {10.1126/science.1184819},
	abstract = {Network science is an interdisciplinary endeavor, with methods and applications drawn from across the natural, social, and information sciences. A prominent problem in network science is the algorithmic detection of tightly connected groups of nodes known as communities. We developed a generalized framework of network quality functions that allowed us to study the community structure of arbitrary multislice networks, which are combinations of individual networks coupled through links that connect each node in one network slice to itself in other slices. This framework allows studies of community structure in a general setting encompassing networks that evolve over time, have multiple types of links (multiplexity), and have multiple scales.},
	journal = {Science},
	author = {Mucha, Peter J. and Richardson, Thomas and Macon, Kevin and Porter, Mason A. and Onnela, Jukka Pekka},
	year = {2010},
	pmid = {20466926},
}

@article{goldenberg_2009,
	title = {A survey of statistical network models},
	issn = {19358237},
	doi = {10.1561/2200000005},
	abstract = {Networks are ubiquitous in science and have become a focal point for discussion in everyday life. Formal statistical models for the analysis of network data have emerged as a major topic of interest in diverse areas of study, and most of these involve a form of graphical representation. Probability models on graphs date back to 1959. Along with empirical studies in social psychology and sociology from the 1960s, these early works generated an active "network community" and a substantial literature in the 1970s. This effort moved into the statistical literature in the late 1970s and 1980s, and the past decade has seen a burgeoning network literature in statistical physics and computer science. The growth of the World Wide Web and the emergence of online "networking communities" such as Facebook, MySpace, and LinkedIn, and a host of more specialized professional network communities has intensified interest in the study of networks and network data. Our goal in this review is to provide the reader with an entry point to this burgeoning literature. We begin with an overview of the historical development of statistical network modeling and then we introduce a number of examples that have been studied in the network literature. Our subsequent discussion focuses on a number of prominent static and dynamic network models and their interconnections. We emphasize formal model descriptions, and pay special attention to the interpretation of parameters and their estimation. We end with a description of some open problems and challenges for machine learning and statistics. © 2010 A. Goldenberg, A. X. Zheng, S. E. Fienberg and E. M. Airoldi.},
	journal = {Foundations and Trends in Machine Learning},
	author = {Goldenberg, Anna and Zheng, Alice X. and Fienberg, Stephen E. and Airoldi, Edoardo M.},
	year = {2009},
}

@article{zhao_2011,
	title = {Community extraction for social networks},
	issn = {00278424},
	doi = {10.1073/pnas.1006642108},
	abstract = {Analysis of networks and in particular discovering communities within networks has been a focus of recent work in several fields and has diverse applications. Most community detection methods focus on partitioning the entire network into communities, with the expectation of many ties within communities and few ties between. However, many networks contain nodes that do not fit in with any of the communities, and forcing every node into a community can distort results. Here we propose a new framework that extracts one community at a time, allowing for arbitrary structure in the remainder of the network, which can include weakly connected nodes. The main idea is that the strength of a community should depend on ties between its members and ties to the outside world, but not on ties between nonmembers. The proposed extraction criterion has a natural probabilistic interpretation in a wide class of models and performs well on simulated and real networks. For the case of the block model, we establish asymptotic consistency of estimated node labels and propose a hypothesis test for determining the number of communities.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Zhao, Yunpeng and Levina, Elizaveta and Zhu, Ji},
	year = {2011},
	pmid = {21502538},
}

@article{clauset_2008,
	title = {Hierarchical structure and the prediction of missing links in networks},
	issn = {14764687},
	doi = {10.1038/nature06830},
	abstract = {Networks have in recent years emerged as an invaluable tool for describing and quantifying complex systems in many branches of science. Recent studies suggest that networks often exhibit hierarchical organization, in which vertices divide into groups that further subdivide into groups of groups, and so forth over multiple scales. In many cases the groups are found to correspond to known functional units, such as ecological niches in food webs, modules in biochemical networks (protein interaction networks, metabolic networks or genetic regulatory networks) or communities in social networks. Here we present a general technique for inferring hierarchical structure from network data and show that the existence of hierarchy can simultaneously explain and quantitatively reproduce many commonly observed topological properties of networks, such as right-skewed degree distributions, high clustering coefficients and short path lengths. We further show that knowledge of hierarchical structure can be used to predict missing connections in partly known networks with high accuracy, and for more general network structures than competing techniques. Taken together, our results suggest that hierarchy is a central organizing principle of complex networks, capable of offering insight into many network phenomena. ©2008 Nature Publishing Group.},
	journal = {Nature},
	author = {Clauset, Aaron and Moore, Cristopher and Newman, M. E.J.},
	year = {2008},
	pmid = {18451861},
}

@article{rosvall_2010,
	title = {Mapping change in large networks},
	issn = {19326203},
	doi = {10.1371/journal.pone.0008694},
	abstract = {Change is a fundamental ingredient of interaction patterns in biology, technology, the economy, and science itself: Interactions within and between organisms change; transportation patterns by air, land, and sea all change; the global financial flow changes; and the frontiers of scientific research change. Networks and clustering methods have become important tools to comprehend instances of these large-scale structures, but without methods to distinguish between real trends and noisy data, these approaches are not useful for studying how networks change. Only if we can assign significance to the partitioning of single networks can we distinguish meaningful structural changes from random fluctuations. Here we show that bootstrap resampling accompanied by significance clustering provides a solution to this problem. To connect changing structures with the changing function of networks, we highlight and summarize the significant structural changes with alluvial diagrams and realize de Solla Price's vision of mapping change in science: studying the citation pattern between about 7000 scientific journals over the past decade, we find that neuroscience has transformed from an interdisciplinary specialty to a mature and stand-alone discipline. © 2010 Rosvall, Bergstrom.},
	journal = {PLoS ONE},
	author = {Rosvall, Martin and Bergstrom, Carl T.},
	year = {2010},
	pmid = {20111700},
}

@article{carissimo_2018,
	title = {Validation of community robustness},
	issn = {01679473},
	doi = {10.1016/j.csda.2017.10.006},
	abstract = {The large amount of work on community detection and its applications leaves unaddressed one important question: the statistical validation of the results. A methodology is presented that is able to clearly detect if the community structure found by some algorithms is statistically significant or is a result of chance, merely due to edge positions in the network. Given a community detection method and a network of interest, the proposal examines the stability of the partition recovered against random perturbations of the original graph structure. To address this issue, a perturbation strategy and a null model graph, which matches the original in some of its structural properties, but is otherwise a random graph, is specified. A set of procedures is built based on a special measure of clustering distance, namely Variation of Information, using tools set up for functional data analysis. The procedures determine whether the obtained clustering departs significantly from the null model. This strongly supports the robustness against perturbation of the algorithm used to identify the community structure. Results obtained with the proposed technique on simulated and real datasets are shown and discussed.},
	journal = {Computational Statistics and Data Analysis},
	author = {Carissimo, Annamaria and Cutillo, Luisa and Feis, Italia De},
	year = {2018},
	keywords = {Community, Multiple testing, Network, Variation of information},
}

@article{traag_2013,
	title = {Significant scales in community structure},
	issn = {20452322},
	doi = {10.1038/srep02930},
	abstract = {Many complex networks show signs of modular structure, uncovered by community detection. Although many methods succeed in revealing various partitions, it remains difficult to detect at what scale some partition is significant. This problem shows foremost in multi-resolution methods. We here introduce an efficient method for scanning for resolutions in one such method. Additionally, we introduce the notion of "significance" of a partition, based on subgraph probabilities. Significance is independent of the exact method used, so could also be applied in other methods, and can be interpreted as the gain in encoding a graph by making use of a partition. Using significance, we can determine "good" resolution parameters, which we demonstrate on benchmark networks. Moreover, optimizing significance itself also shows excellent performance. We demonstrate our method on voting data from the European Parliament. Our analysis suggests the European Parliament has become increasingly ideologically divided and that nationality plays no role.},
	journal = {Scientific Reports},
	author = {Traag, V. A. and Krings, G. and Van Dooren, P.},
	year = {2013},
}

@article{aldecoa_2011,
	title = {Deciphering network community structure by surprise},
	issn = {19326203},
	doi = {10.1371/journal.pone.0024195},
	abstract = {The analysis of complex networks permeates all sciences, from biology to sociology. A fundamental, unsolved problem is how to characterize the community structure of a network. Here, using both standard and novel benchmarks, we show that maximization of a simple global parameter, which we call Surprise (S), leads to a very efficient characterization of the community structure of complex synthetic networks. Particularly, S qualitatively outperforms the most commonly used criterion to define communities, Newman and Girvan's modularity (Q). Applying S maximization to real networks often provides natural, well-supported partitions, but also sometimes counterintuitive solutions that expose the limitations of our previous knowledge. These results indicate that it is possible to define an effective global criterion for community structure and open new routes for the understanding of complex networks. © 2011 Aldecoa, Marín.},
	journal = {PLoS ONE},
	author = {Aldecoa, Rodrigo and Marín, Ignacio},
	year = {2011},
	pmid = {21909420},
}

@article{Kojaku2018,
	title = {A generalised significance test for individual communities in networks},
	issn = {20452322},
	doi = {10.1038/s41598-018-25560-z},
	abstract = {Many empirical networks have community structure, in which nodes are densely interconnected within each community (i.e., a group of nodes) and sparsely across different communities. Like other local and meso-scale structure of networks, communities are generally heterogeneous in various aspects such as the size, density of edges, connectivity to other communities and significance. In the present study, we propose a method to statistically test the significance of individual communities in a given network. Compared to the previous methods, the present algorithm is unique in that it accepts different community-detection algorithms and the corresponding quality function for single communities. The present method requires that a quality of each community can be quantified and that community detection is performed as optimisation of such a quality function summed over the communities. Various community detection algorithms including modularity maximisation and graph partitioning meet this criterion. Our method estimates a distribution of the quality function for randomised networks to calculate a likelihood of each community in the given network. We illustrate our algorithm by synthetic and empirical networks.},
	journal = {Scientific Reports},
	author = {Kojaku, Sadamori and Masuda, Naoki},
	year = {2018},
	pmid = {29743534},
}

@article{Lambiotte2014,
	title = {Random walks, {Markov} processes and the multiscale modular organization of complex networks},
	issn = {23274697},
	doi = {10.1109/TNSE.2015.2391998},
	abstract = {Most methods proposed to uncover communities in complex networks rely on combinatorial graph properties. Usually an edge-counting quality function, such as modularity, is optimized over all partitions of the graph compared against a null random graph model. Here we introduce a systematic dynamical framework to design and analyze a wide variety of quality functions for community detection. The quality of a partition is measured by its Markov Stability, a time-parametrized function defined in terms of the statistical properties of a Markov process taking place on the graph. The Markov process provides a dynamical sweeping across all scales in the graph, and the time scale is an intrinsic parameter that uncovers communities at different resolutions. This dynamic-based community detection leads to a compound optimization, which favours communities of comparable centrality (as defined by the stationary distribution), and provides a unifying framework for spectral algorithms, as well as different heuristics for community detection, including versions of modularity and Potts model. Our dynamic framework creates a systematic link between different stochastic dynamics and their corresponding notions of optimal communities under distinct (node and edge) centralities. We show that the Markov Stability can be computed efficiently to find multi-scale community structure in large networks.},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Lambiotte, Renaud and Delvenne, Jean Charles and Barahona, Mauricio},
	year = {2014},
	keywords = {Complex networks, Communities, centrality, community detection, graph theory, Graph theory, multiscale structure, Multiscale structures, optimization, Optimization, partition stability, random walks},
}

@article{Peixoto2015,
	title = {Model selection and hypothesis testing for large-scale network models with overlapping groups},
	issn = {21603308},
	doi = {10.1103/PhysRevX.5.011033},
	abstract = {The effort to understand network systems in increasing detail has resulted in a diversity of methods designed to extract their large-scale structure from data. Unfortunately, many of these methods yield diverging descriptions of the same network, making both the comparison and understanding of their results a difficult challenge. A possible solution to this outstanding issue is to shift the focus away from ad hoc methods and move towards more principled approaches based on statistical inference of generative models. As a result, we face instead the more well-defined task of selecting between competing generative processes, which can be done under a unified probabilistic framework. Here, we consider the comparison between a variety of generative models including features such as degree correction, where nodes with arbitrary degrees can belong to the same group, and community overlap, where nodes are allowed to belong to more than one group. Because such model variants possess an increasing number of parameters, they become prone to overfitting. In this work, we present a method of model selection based on the minimum description length criterion and posterior odds ratios that is capable of fully accounting for the increased degrees of freedom of the larger models and selects the best one according to the statistical evidence available in the data. In applying this method to many empirical unweighted networks from different fields, we observe that community overlap is very often not supported by statistical evidence and is selected as a better model only for a minority of them. On the other hand, we find that degree correction tends to be almost universally favored by the available data, implying that intrinsic node proprieties (as opposed to group properties) are often an essential ingredient of network formation.},
	journal = {Physical Review X},
	author = {Peixoto, Tiago P.},
	year = {2015},
	keywords = {Complex systems, Interdisciplinary physics, Statistical physics},
}

@article{Zhang2014,
	title = {Scalable detection of statistically significant communities and hierarchies, using message passing for modularity},
	issn = {10916490},
	doi = {10.1073/pnas.1409770111},
	abstract = {Modularity is a popular measure of community structure. However, maximizing the modularity can lead to many competing partitions, with almost the same modularity, that are poorly correlated with each other. It can also produce illusory "communities" in random graphs where none exist. We address this problem by using the modularity as a Hamiltonian at finite temperature and using an efficient belief propagation algorithm to obtain the consensus of many partitions with high modularity, rather than looking for a single partition that maximizes it. We show analytically and numerically that the proposed algorithm works all of the way down to the detectability transition in networks generated by the stochastic block model. It also performs well on real-world networks, revealing large communities in some networks where previous work has claimed no communities exist. Finally we show that by applying our algorithm recursively, subdividing communities until no statistically significant subcommunities can be found, we can detect hierarchical structure in real-world networks more efficiently than previous methods.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Zhang, Pan and Moore, Cristopher},
	year = {2014},
	pmid = {25489096},
	keywords = {Community detection, Networks, Message-passing algorithms, Phase transitions, Statistical significance},
}

@inproceedings{Yang2012,
	title = {Defining and evaluating network communities based on ground-truth},
	isbn = {978-1-4503-1546-3},
	doi = {10.1145/2350190.2350193},
	abstract = {Nodes in real-world networks, such as social, information or technological networks, organize into communities where edges appear with high concentration among the members of the community. Identifying communities in networks has proven to be a challenging task mainly due to a plethora of definitions of a community, intractability of algorithms, issues with evaluation and the lack of a reliable gold-standard ground-truth. We study a set of 230 large social, collaboration and information networks where nodes explicitly define group memberships. We use these groups to define the notion of ground-truth communities. We then propose a methodology which allows us to compare and quantitatively evaluate different definitions of network communities on a large scale. We choose 13 commonly used definitions of network communities and examine their quality, sensitivity and robustness. We show that the 13 definitions naturally group into four classes. We find that two of these definitions, Conductance and Triad-participation-ratio, consistently give the best performance in identifying ground-truth communities. Copyright © 2012 ACM.},
	booktitle = {Proceedings of the {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	author = {Yang, Jaewon and Leskovec, Jure},
	year = {2012},
	keywords = {Community scores, Network communities, Social and information networks},
}

@article{Traag2013,
	title = {Significant scales in community structure},
	issn = {20452322},
	doi = {10.1038/srep02930},
	abstract = {Many complex networks show signs of modular structure, uncovered by community detection. Although many methods succeed in revealing various partitions, it remains difficult to detect at what scale some partition is significant. This problem shows foremost in multi-resolution methods. We here introduce an efficient method for scanning for resolutions in one such method. Additionally, we introduce the notion of "significance" of a partition, based on subgraph probabilities. Significance is independent of the exact method used, so could also be applied in other methods, and can be interpreted as the gain in encoding a graph by making use of a partition. Using significance, we can determine "good" resolution parameters, which we demonstrate on benchmark networks. Moreover, optimizing significance itself also shows excellent performance. We demonstrate our method on voting data from the European Parliament. Our analysis suggests the European Parliament has become increasingly ideologically divided and that nationality plays no role.},
	journal = {Scientific Reports},
	author = {Traag, V. A. and Krings, G. and Van Dooren, P.},
	year = {2013},
}

@article{Bianconia2009,
	title = {Assessing the relevance of node features for network structure},
	issn = {00278424},
	doi = {10.1073/pnas.0811511106},
	abstract = {Networks describe a variety of interacting complex systems in social science, biology, and information technology. Usually the nodes of real networks are identified not only by their connections but also by some other characteristics. Examples of characteristics of nodes can be age, gender, or nationality of a person in a social network, the abundance of proteins in the cell taking part in protein-interaction networks, or the geographical position of airports that are connected by directed flights. Integrating the information on the connections of each node with the information about its characteristics is crucial to discriminating between the essential and negligible characteristics of nodes for the structure of the network. In this paper we propose a general indicator Θ, based on entropy measures, to quantify the dependence of a network's structure on a given set of features. We apply this method to social networks of friendships in U.S. schools, to the protein-interaction network of Saccharomyces cerevisiae and to the U.S. airport network, showing that the proposed measure provides information that complements other known measures.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Bianconia, Ginestra and Pinb, Paolo and Marsilia, Matteo},
	year = {2009},
	pmid = {19571013},
	keywords = {Social networks, Communities, Entropy, Inference},
}

@article{Wilson2014,
	title = {A testing based extraction algorithm for identifying significant communities in networks},
	issn = {19417330},
	doi = {10.1214/14-AOAS760},
	abstract = {A common and important problem arising in the study of networks is how to divide the vertices of a given network into one or more groups, called communities, in such a way that vertices of the same community are more interconnected than vertices belonging to different ones. We propose and investigate a testing based community detection procedure called Extraction of Statistically Significant Communities (ESSC). The ESSC procedure is based on p-values for the strength of connection between a single vertex and a set of vertices under a reference distribution derived from a conditional configuration network model. The procedure automatically selects both the number of communities in the network and their size. Moreover, ESSC can handle overlapping communities and, unlike the majority of existing methods, identifies “background” vertices that do not belong to a well-defined community. The method has only one parameter, which controls the stringency of the hypothesis tests. We investigate the performance and potential use of ESSC and compare it with a number of existing methods, through a validation study using four real network data sets. In addition, we carry out a simulation study to assess the effectiveness of ESSC in networks with various types of community structure, including networks with overlapping communities and those with background vertices. These results suggest that ESSC is an effective exploratory tool for the discovery of relevant community structure in complex network systems. Data and software are available at http://www.unc.edu/∼jameswd/research.html.},
	journal = {Annals of Applied Statistics},
	author = {Wilson, James D. and Wang, Simi and Mucha, Peter J. and Bhamidi, Shankar and Nobel, Andrew B.},
	year = {2014},
	keywords = {Multiple testing, Community detection, Background, Extraction, Networks},
}

@article{Wilson2014,
	title = {A testing based extraction algorithm for identifying significant communities in networks},
	issn = {19417330},
	doi = {10.1214/14-AOAS760},
	abstract = {A common and important problem arising in the study of networks is how to divide the vertices of a given network into one or more groups, called communities, in such a way that vertices of the same community are more interconnected than vertices belonging to different ones. We propose and investigate a testing based community detection procedure called Extraction of Statistically Significant Communities (ESSC). The ESSC procedure is based on p-values for the strength of connection between a single vertex and a set of vertices under a reference distribution derived from a conditional configuration network model. The procedure automatically selects both the number of communities in the network and their size. Moreover, ESSC can handle overlapping communities and, unlike the majority of existing methods, identifies “background” vertices that do not belong to a well-defined community. The method has only one parameter, which controls the stringency of the hypothesis tests. We investigate the performance and potential use of ESSC and compare it with a number of existing methods, through a validation study using four real network data sets. In addition, we carry out a simulation study to assess the effectiveness of ESSC in networks with various types of community structure, including networks with overlapping communities and those with background vertices. These results suggest that ESSC is an effective exploratory tool for the discovery of relevant community structure in complex network systems. Data and software are available at http://www.unc.edu/∼jameswd/research.html.},
	journal = {Annals of Applied Statistics},
	author = {Wilson, James D. and Wang, Simi and Mucha, Peter J. and Bhamidi, Shankar and Nobel, Andrew B.},
	year = {2014},
	keywords = {Multiple testing, Community detection, Background, Extraction, Networks},
}

@article{Fortunato2007,
	title = {Resolution limit in community detection},
	issn = {00278424},
	doi = {10.1073/pnas.0605965104},
	abstract = {Detecting community structure is fundamental for uncovering the links between structure and function in complex networks and for practical applications in many disciplines such as biology and sociology. A popular method now widely used relies on the optimization of a quantity called modularity, which is a quality index for a partition of a network into communities. We find that modularity optimization may fail to identify modules smaller than a scale which depends on the total size of the network and on the degree of inter-connectedness of the modules, even in cases where modules are unambiguously defined. This finding is confirmed through several examples, both in artificial and in real social, biological, and technological networks, where we show that modularity optimization indeed does not resolve a large number of modules. A check of the modules obtained through modularity optimization is thus necessary, and we provide here key elements for the assessment of the reliability of this community detection method. © 2006 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Fortunato, Santo and Barthélemy, Marc},
	year = {2007},
	pmid = {17190818},
	keywords = {Complex networks, Metabolic networks, Modular structure, Social networks},
}

@article{Kumpula2007,
	title = {Limited resolution in complex network community detection with {Potts} model approach},
	issn = {14346028},
	doi = {10.1140/epjb/e2007-00088-4},
	abstract = {According to Fortunato and Barthélemy, modularity-based community detection algorithms have a resolution threshold such that small communities in a large network are invisible. Here we generalize their work and show that the q-state Potts community detection method introduced by Reichardt and Bornholdt also has a resolution threshold. The model contains a parameter by which this threshold can be tuned, but no a priori principle is known to select the proper value. Single global optimization criteria do not seem capable for detecting all communities if their size distribution is broad. © EDP Sciences/Società Italiana di Fisica/Springer-Verlag 2007.},
	journal = {European Physical Journal B},
	author = {Kumpula, J. M. and Saramäki, J. and Kaski, K. and Kertész, J.},
	year = {2007},
}

@article{Miyauchi2016,
	title = {Z-score-based modularity for community detection in networks},
	issn = {19326203},
	doi = {10.1371/journal.pone.0147805},
	abstract = {Identifying community structure in networks is an issue of particular interest in network science. The modularity introduced by Newman and Girvan is the most popular quality function for community detection in networks. In this study, we identify a problem in the concept of modularity and suggest a solution to overcome this problem. Specifically, we obtain a new quality function for community detection. We refer to the function as Z-modularity because it measures the Z-score of a given partition with respect to the fraction of the number of edges within communities. Our theoretical analysis shows that Z-modularity mitigates the resolution limit of the original modularity in certain cases. Computational experiments using both artificial networks and well-known real-world networks demonstrate the validity and reliability of the proposed quality function.},
	journal = {PLoS ONE},
	author = {Miyauchi, Atsushi and Kawase, Yasushi},
	year = {2016},
	pmid = {26808270},
}

@article{Miyauchi2016,
	title = {Z-score-based modularity for community detection in networks},
	issn = {19326203},
	doi = {10.1371/journal.pone.0147805},
	abstract = {Identifying community structure in networks is an issue of particular interest in network science. The modularity introduced by Newman and Girvan is the most popular quality function for community detection in networks. In this study, we identify a problem in the concept of modularity and suggest a solution to overcome this problem. Specifically, we obtain a new quality function for community detection. We refer to the function as Z-modularity because it measures the Z-score of a given partition with respect to the fraction of the number of edges within communities. Our theoretical analysis shows that Z-modularity mitigates the resolution limit of the original modularity in certain cases. Computational experiments using both artificial networks and well-known real-world networks demonstrate the validity and reliability of the proposed quality function.},
	journal = {PLoS ONE},
	author = {Miyauchi, Atsushi and Kawase, Yasushi},
	year = {2016},
	pmid = {26808270},
}

@article{Aldecoa2011,
	title = {Deciphering network community structure by surprise},
	issn = {19326203},
	doi = {10.1371/journal.pone.0024195},
	abstract = {The analysis of complex networks permeates all sciences, from biology to sociology. A fundamental, unsolved problem is how to characterize the community structure of a network. Here, using both standard and novel benchmarks, we show that maximization of a simple global parameter, which we call Surprise (S), leads to a very efficient characterization of the community structure of complex synthetic networks. Particularly, S qualitatively outperforms the most commonly used criterion to define communities, Newman and Girvan's modularity (Q). Applying S maximization to real networks often provides natural, well-supported partitions, but also sometimes counterintuitive solutions that expose the limitations of our previous knowledge. These results indicate that it is possible to define an effective global criterion for community structure and open new routes for the understanding of complex networks. © 2011 Aldecoa, Marín.},
	journal = {PLoS ONE},
	author = {Aldecoa, Rodrigo and Marín, Ignacio},
	year = {2011},
	pmid = {21909420},
}

@article{Aldecoa2011,
	title = {Deciphering network community structure by surprise},
	issn = {19326203},
	doi = {10.1371/journal.pone.0024195},
	abstract = {The analysis of complex networks permeates all sciences, from biology to sociology. A fundamental, unsolved problem is how to characterize the community structure of a network. Here, using both standard and novel benchmarks, we show that maximization of a simple global parameter, which we call Surprise (S), leads to a very efficient characterization of the community structure of complex synthetic networks. Particularly, S qualitatively outperforms the most commonly used criterion to define communities, Newman and Girvan's modularity (Q). Applying S maximization to real networks often provides natural, well-supported partitions, but also sometimes counterintuitive solutions that expose the limitations of our previous knowledge. These results indicate that it is possible to define an effective global criterion for community structure and open new routes for the understanding of complex networks. © 2011 Aldecoa, Marín.},
	journal = {PLoS ONE},
	author = {Aldecoa, Rodrigo and Marín, Ignacio},
	year = {2011},
	pmid = {21909420},
}

@article{Arnau2005,
	title = {Iterative cluster analysis of protein interaction data},
	issn = {13674803},
	doi = {10.1093/bioinformatics/bti021},
	abstract = {Motivation: Generation of fast tools of hierarchical clustering to be applied when distances among elements of a set are constrained, causing frequent distance ties, as happens in protein interaction data. Results: We present in this work the program UVCLUSTER, that iteratively explores distance datasets using hierarchical clustering. Once the user selects a group of proteins, UVCLUSTER converts the set of primary distances among them (i.e. the minimum number of steps, or interactions, required to connect two proteins) into secondary distances that measure the strength of the connection between each pair of proteins when the interactions for all the proteins in the group are considered. We show that this novel strategy has advantages over conventional clustering methods to explore protein-protein interaction dam. UVCLUSTER easily incorporates the information of the largest available interaction datasets to generate comprehensive primary distance tables. The versatility, simplicity of use and high speed of UVCLUSTER on standard personal computers suggest that it can be a benchmark analytical tool for interactome data analysis. © Oxford University Press 2004; all rights reserved.},
	journal = {Bioinformatics},
	author = {Arnau, Vicente and Mars, Sergio and Marín, Ignacio},
	year = {2005},
	pmid = {15374873},
}

@article{Hu2010,
	title = {Measuring the significance of community structure in complex networks},
	issn = {15393755},
	doi = {10.1103/PhysRevE.82.066106},
	abstract = {Many complex systems can be represented as networks, and separating a network into communities could simplify functional analysis considerably. Many approaches have recently been proposed to detect communities, but a method to determine whether the detected communities are significant is still lacking. In this paper, an index to evaluate the significance of communities in networks is proposed based on perturbation of the network. In contrast to previous approaches, the network is disturbed gradually, and the index is defined by integrating all of the similarities between the community structures before and after perturbation. Moreover, by taking the null model into account, the index eliminates scale effects. Thus, it can evaluate and compare the significance of communities in different networks. The method has been tested in many artificial and real-world networks. The results show that the index is in fact independent of the size of the network and the number of communities. With this approach, clear communities are found to always exist in social networks, but significant communities cannot be found in protein interactions and metabolic networks. © 2010 The American Physical Society.},
	journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
	author = {Hu, Yanqing and Nie, Yuchao and Yang, Hua and Cheng, Jie and Fan, Ying and Di, Zengru},
	year = {2010},
}

@article{Reichardt2006,
	title = {When are networks truly modular?},
	issn = {01672789},
	doi = {10.1016/j.physd.2006.09.009},
	abstract = {The study of cluster or community structure of complex networks contributes to the understanding of networks at a functional level. In many networks, latent classes of nodes are suspected which manifest themselves as communities, i.e. groups of nodes with a high link density among the nodes of the same class and low link density between nodes of different classes. Community detection algorithms are used to infer these classes, e.g. by finding a partition of the network which maximizes a quality function such as the network modularity Q [M. Newman, M. Girvan, Finding and evaluating community structure in networks, Phys. Rev. E 69 (2004) 026113]. However, it is known from numerical experiments that even purely random networks display intrinsic modularity and may be partitioned yielding high values of Q. Extending on our earlier results [J. Reichardt, S. Bornholdt, Statistical mechanics of community detection, Phys. Rev. E 74 (2006) 016110], the mapping of the community detection problem onto finding the ground state of a spin glass is exploited in order to derive analytical expressions for the expected modularity in random graphs and assess the theoretical limits to community detection. The results are independent of any specific community detection algorithm and allow for differentiation between modularity arising purely due to the search process in the large configuration space of possible partitionings on the one hand, or due to the actual presence of different classes of nodes on the other hand. © 2006 Elsevier Ltd. All rights reserved.},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Reichardt, Jörg and Bornholdt, Stefan},
	year = {2006},
	keywords = {Community detection, Graph clustering, Spin models},
}

@article{Sales-Pardo2007,
	title = {Extracting the hierarchical organization of complex systems},
	issn = {00278424},
	doi = {10.1073/pnas.0703740104},
	abstract = {Extracting understanding from the growing "sea" of biological and socioeconomic data is one of the most pressing scientific challenges facing us. Here, we introduce and validate an unsupervised method for extracting the hierarchical organization of complex biological, social, and technological networks. We define an ensemble of hierarchically nested random graphs, which we use to validate the method. We then apply our method to real-world networks, including the air-transportation network, an electronic circuit an e-mail exchange network, and metabolic networks. Our analysis of model and real networks demonstrates that our method extracts an accurate multiscale representation of a complex system. © 2007 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sales-Pardo, Marta and Guimerà, Roger and Moreira, André A. and Nunes Amaral, Luís A.},
	year = {2007},
	pmid = {17881571},
	keywords = {Cellular metabolism, Complex networks, Multiscale representation},
}

@article{Karrer2008,
	title = {Robustness of community structure in networks},
	issn = {15393755},
	doi = {10.1103/PhysRevE.77.046119},
	abstract = {The discovery of community structure is a common challenge in the analysis of network data. Many methods have been proposed for finding community structure, but few have been proposed for determining whether the structure found is statistically significant or whether, conversely, it could have arisen purely as a result of chance. In this paper we show that the significance of community structure can be effectively quantified by measuring its robustness to small perturbations in network structure. We propose a suitable method for perturbing networks and a measure of the resulting change in community structure and use them to assess the significance of community structure in a variety of networks, both real and computer generated. © 2008 The American Physical Society.},
	journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
	author = {Karrer, Brian and Levina, Elizaveta and Newman, M. E.J.},
	year = {2008},
}

@inproceedings{Chang2012,
	title = {Assessing statistical significance when partitioning large-scale brain networks},
	isbn = {978-1-4577-1858-8},
	doi = {10.1109/ISBI.2012.6235921},
	abstract = {Multivariate analysis of structural and functional brain imaging data can be used to produce network models of interaction or similarity between different brain structures. Graph partitioning methods can then be used to identify distinct subnetworks that may provide insight into the organization of the human brain. Although several efficient partitioning algorithms have been proposed, and their properties studied thoroughly, there has been limited work addressing the statistical significance of the resulting partitions. We present a new method to estimate the statistical significance of a network structure based on modularity. We derive a numerical approximation of the distribution of modularity on random graphs, and use this distribution to calculate a threshold that controls the type I error rate in partitioning graphs. We demonstrate the technique in application to brain subnetworks identified from diffusion-based fiber tracking data and from resting state fMRI data. © 2012 IEEE.},
	booktitle = {Proceedings - {International} {Symposium} on {Biomedical} {Imaging}},
	author = {Chang, Yu Teng and Pantazis, Dimitrios and Leahy, Richard M.},
	year = {2012},
	note = {ISSN: 19457928},
	keywords = {community structure, graph partitioning, modularity, significance testing},
}

@article{Sales-Pardo2007,
	title = {Extracting the hierarchical organization of complex systems},
	issn = {00278424},
	doi = {10.1073/pnas.0703740104},
	abstract = {Extracting understanding from the growing "sea" of biological and socioeconomic data is one of the most pressing scientific challenges facing us. Here, we introduce and validate an unsupervised method for extracting the hierarchical organization of complex biological, social, and technological networks. We define an ensemble of hierarchically nested random graphs, which we use to validate the method. We then apply our method to real-world networks, including the air-transportation network, an electronic circuit an e-mail exchange network, and metabolic networks. Our analysis of model and real networks demonstrates that our method extracts an accurate multiscale representation of a complex system. © 2007 by The National Academy of Sciences of the USA.},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sales-Pardo, Marta and Guimerà, Roger and Moreira, André A. and Nunes Amaral, Luís A.},
	year = {2007},
	pmid = {17881571},
	keywords = {Cellular metabolism, Complex networks, Multiscale representation},
}

@article{Carissimo2018,
	title = {Validation of community robustness},
	issn = {01679473},
	doi = {10.1016/j.csda.2017.10.006},
	abstract = {The large amount of work on community detection and its applications leaves unaddressed one important question: the statistical validation of the results. A methodology is presented that is able to clearly detect if the community structure found by some algorithms is statistically significant or is a result of chance, merely due to edge positions in the network. Given a community detection method and a network of interest, the proposal examines the stability of the partition recovered against random perturbations of the original graph structure. To address this issue, a perturbation strategy and a null model graph, which matches the original in some of its structural properties, but is otherwise a random graph, is specified. A set of procedures is built based on a special measure of clustering distance, namely Variation of Information, using tools set up for functional data analysis. The procedures determine whether the obtained clustering departs significantly from the null model. This strongly supports the robustness against perturbation of the algorithm used to identify the community structure. Results obtained with the proposed technique on simulated and real datasets are shown and discussed.},
	journal = {Computational Statistics and Data Analysis},
	author = {Carissimo, Annamaria and Cutillo, Luisa and Feis, Italia De},
	year = {2018},
	keywords = {Community, Multiple testing, Network, Variation of information},
}

@article{doi:10.1080/10618600.2020.1753529,
	title = {State-{Dependent} {Kernel} {Selection} for {Conditional} {Sampling} of {Graphs}},
	volume = {0},
	url = {https://doi.org/10.1080/10618600.2020.1753529},
	doi = {10.1080/10618600.2020.1753529},
	number = {0},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Scott, James A and Gandy, Axel},
	year = {2020},
	note = {Publisher: Taylor \& Francis},
	pages = {1--12},
}

@misc{Cori2020,
	title = {{EpiEstim}: {Estimate} {Time} {Varying} {Reproduction} {Numbers} from {Epidemic} {Curves}},
	url = {https://cran.r-project.org/package=EpiEstim},
	author = {Cori, Anne},
	year = {2020},
	annote = {R package version 2.2-3},
}

@misc{Boelle2015,
	title = {R0: {Estimation} of {R0} and {Real}-{Time} {Reproduction} {Number} from {Epidemics}},
	url = {https://cran.r-project.org/package=R0},
	author = {Boelle, Pierre-Yves and Obadia, Thomas},
	year = {2015},
	annote = {R package version 1.2-6},
}

@article{Thompson1985,
	title = {An {Introduction} to {Stochastic} {Modeling}.},
	issn = {01621459},
	doi = {10.2307/2287941},
	abstract = {Serving as the foundation for a one-semester course in stochastic processes for students familiar with elementary probability theory and calculus, Introduction to Stochastic Modeling, Third Edition, bridges the gap between basic probability and an intermediate level course in stochastic processes. The objectives of the text are to introduce students to the standard concepts and methods of stochastic modeling, to illustrate the rich diversity of applications of stochastic processes in the applied sciences, and to provide exercises in the application of simple stochastic analysis to realistic problems. * Realistic applications from a variety of disciplines integrated throughout the text* Plentiful, updated and more rigorous problems, including computer "challenges"* Revised end-of-chapter exercises sets-in all, 250 exercises with answers* New chapter on Brownian motion and related processes* Additional sections on Matingales and Poisson process* Solutions manual available to adopting instructors},
	journal = {Journal of the American Statistical Association},
	author = {Thompson, W. A. and Taylor, Howard M. and Karlin, Samuel},
	year = {1985},
}

@article{May1976,
	title = {Simple mathematical models with very complicated dynamics},
	issn = {00280836},
	doi = {10.1038/261459a0},
	abstract = {First-order difference equations arise in many contexts in the biological, economic and social sciences. Such equations, even though simple and deterministic, can exhibit a surprising array of dynamical behaviour, from stable points, to a bifurcating hierarchy of stable cycles, to apparently random fluctuations. There are consequently many fascinating problems, some concerned with delicate mathematical aspects of the fine structure of the trajectories, and some concerned with the practical implications and applications. This is an interpretive review of them. © 1976 Nature Publishing Group.},
	journal = {Nature},
	author = {May, Robert M.},
	year = {1976},
	pmid = {934280},
}

@article{Ferguson2020,
	title = {Report 13: {Estimating} the number of infections and the impact of non-pharmaceutical interventions on {COVID}-19 in 11 {European} countries},
	abstract = {The global impact of COVID-19 has been profound, and the public health threat it represents is the most serious seen in a respiratory virus since the 1918 H1N1 influenza pandemic. Here we present the results of epidemiological modelling which has informed policymaking in the UK and other countries in recent weeks. In the absence of a COVID-19 vaccine, we assess the potential role of a number of public health measures-so-called non-pharmaceutical interventions (NPIs)-aimed at reducing contact rates in the population and thereby reducing transmission of the virus. In the results presented here, we apply a previously published microsimulation model to two countries: the UK (Great Britain specifically) and the US. We conclude that the effectiveness of any one intervention in isolation is likely to be limited, requiring multiple interventions to be combined to have a substantial impact on transmission. Two fundamental strategies are possible: (a) mitigation, which focuses on slowing but not necessarily stopping epidemic spread-reducing peak healthcare demand while protecting those most at risk of severe disease from infection, and (b) suppression, which aims to reverse epidemic growth, reducing case numbers to low levels and maintaining that situation indefinitely. Each policy has major challenges. We find that that optimal mitigation policies (combining home isolation of suspect cases, home quarantine of those living in the same household as suspect cases, and social distancing of the elderly and others at most risk of severe disease) might reduce peak healthcare demand by 2/3 and deaths by half. However, the resulting mitigated epidemic would still likely result in hundreds of thousands of deaths and health systems (most notably intensive care units) being overwhelmed many times over. For countries able to achieve it, this leaves suppression as the preferred policy option. We show that in the UK and US context, suppression will minimally require a combination of social distancing of the entire population, home isolation of cases and household quarantine of their family members. This may need to be supplemented by school and university closures, though it should be recognised that such closures may have negative impacts on health systems due to increased},
	journal = {Imperial College COVID-19 Response Team},
	author = {Ferguson, Neil M and Laydon, Daniel and Nedjati-Gilani, Gemma and Imai, Natsuko and Ainslie, Kylie and Baguelin, Marc and Bhatia, Sangeeta and Boonyasiri, Adhiratha and Cucunubá, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Dorigatti, Ilaria and Fu, Han and Gaythorpe, Katy and Green, Will and Hamlet, Arran and Hinsley, Wes and Okell, Lucy C and Van Elsland, Sabine and Thompson, Hayley and Verity, Robert and Volz, Erik and Wang, Haowei and Wang, Yuanrong and Gt Walker, Patrick and Walters, Caroline and Winskill, Peter and Whittaker, Charles and Donnelly, Christl A and Riley, Steven and Ghani, Azra C},
	year = {2020},
}

@article{Heesterbeek2015,
	title = {Modeling infectious disease dynamics in the complex landscape of global health},
	volume = {347},
	issn = {10959203},
	url = {http://science.sciencemag.org/},
	doi = {10.1126/science.aaa4339},
	abstract = {Despite some notable successes in the control of infectious diseases, transmissible pathogens still pose an enormous threat to human and animal health. The ecological and evolutionary dynamics of infections play out on a wide range of interconnected temporal, organizational, and spatial scales, which span hours to months, cells to ecosystems, and local to global spread. Moreover, some pathogens are directly transmitted between individuals of a single species, whereas others circulate among multiple hosts, need arthropod vectors, or can survive in environmental reservoirs. Many factors, including increasing antimicrobial resistance, increased human connectivity and changeable human behavior, elevate prevention and control from matters of national policy to international challenge. In the face of this complexity, mathematical models offer valuable tools for synthesizing information to understand epidemiological patterns, and for developing quantitative evidence for decision-making in global health.},
	number = {6227},
	urldate = {2021-05-06},
	journal = {Science},
	author = {Heesterbeek, Hans and Anderson, Roy M. and Andreasen, Viggo and Bansal, Shweta and DeAngelis, Daniela and Dye, Chris and Eames, Ken T.D. and Edmunds, W. John and Frost, Simon D.W. and Funk, Sebastian and Hollingsworth, T. Deirdre and House, Thomas and Isham, Valerie and Klepac, Petra and Lessler, Justin and Lloyd-Smith, James O. and Metcalf, C. Jessica E. and Mollison, Denis and Pellis, Lorenzo and Pulliam, Juliet R.C. and Roberts, Mick G. and Viboud, Cecile and Arinaminpathy, Nimalan and Ball, Frank and Bogich, Tiffany and Gog, Julia and Grenfell, Bryan and Lloyd, Alun L. and Mclean, Angela and O'Neill, Philip and Pearson, Carl and Riley, Steven and Tomba, Gianpaolo Scalia and Trapman, Pieter and Wood, James},
	month = mar,
	year = {2015},
	pmid = {25766240},
	note = {Publisher: American Association for the Advancement of Science},
	file = {PDF:/Users/jamesscott/Zotero/storage/WAFLCV84/full-text.pdf:application/pdf},
}

@article{siettos_mathematical_2013-1,
	title = {Mathematical modeling of infectious disease dynamics},
	volume = {4},
	issn = {21505608},
	url = {/pmc/articles/PMC3710332/},
	doi = {10.4161/viru.24041},
	abstract = {Over the last years, an intensive worldwide effort is speeding up the developments in the establishment of a global surveillance network for combating pandemics of emergent and re-emergent infectious diseases. Scientists from different fields extending from medicine and molecular biology to computer science and applied mathematics have teamed up for rapid assessment of potentially urgent situations. Toward this aim mathematical modeling plays an important role in efforts that focus on predicting, assessing, and controlling potential outbreaks. To better understand and model the contagious dynamics the impact of numerous variables ranging from the micro host-pathogen level to host-to-host interactions, as well as prevailing ecological, social, economic, and demographic factors across the globe have to be analyzed and thoroughly studied. Here, we present and discuss the main approaches that are used for the surveillance and modeling of infectious disease dynamics. We present the basic concepts underpinning their implementation and practice and for each category we give an annotated list of representative works.},
	number = {4},
	urldate = {2021-05-06},
	journal = {Virulence},
	author = {Siettos, Constantinos I. and Russo, Lucia},
	year = {2013},
	note = {Publisher: Taylor and Francis Inc.},
	keywords = {Agent-based models, Dynamical models, Machine learning models, Mathematical epidemiology, Statistical models},
	pages = {295--306},
	file = {PDF:/Users/jamesscott/Zotero/storage/NVS6ND8V/full-text.pdf:application/pdf},
}

@article{Chretien2014,
	title = {Influenza forecasting in human populations: {A} scoping review},
	volume = {9},
	issn = {19326203},
	url = {www.plosone.org},
	doi = {10.1371/journal.pone.0094130},
	abstract = {Forecasts of influenza activity in human populations could help guide key preparedness tasks. We conducted a scoping review to characterize these methodological approaches and identify research gaps. Adapting the PRISMA methodology for systematic reviews, we searched PubMed, CINAHL, Project Euclid, and Cochrane Database of Systematic Reviews for publications in English since January 1, 2000 using the terms "influenza AND (forecast*OR predict*)", excluding studies that did not validate forecasts against independent data or incorporate influenza-related surveillance data from the season or pandemic for which the forecasts were applied. We included 35 publications describing population-based (N = 27), medical facility-based (N = 4), and regional or global pandemic spread (N = 4) forecasts. They included areas of North America (N = 15), Europe (N = 14), and/or Asia-Pacific region (N = 4), or had global scope (N = 3). Forecasting models were statistical (N = 18) or epidemiological (N = 17). Five studies used data assimilation methods to update forecasts with new surveillance data. Models used virological (N = 14), syndromic (N = 13), meteorological (N = 6), internet search query (N = 4), and/or other surveillance data as inputs. Forecasting outcomes and validation metrics varied widely. Two studies compared distinct modeling approaches using common data, 2 assessed model calibration, and 1 systematically incorporated expert input. Of the 17 studies using epidemiological models, 8 included sensitivity analysis. This review suggests need for use of good practices in influenza forecasting (e.g., sensitivity analysis); direct comparisons of diverse approaches; assessment of model calibration; integration of subjective expert input; operational research in pilot, real-world applications; and improved mutual understanding among modelers and public health officials. © 2014 Chretien et al.},
	number = {4},
	urldate = {2021-05-06},
	journal = {PLoS ONE},
	author = {Chretien, Jean Paul and George, Dylan and Shaman, Jeffrey and Chitale, Rohit A. and McKenzie, F. Ellis},
	month = apr,
	year = {2014},
	pmid = {24714027},
	note = {Publisher: Public Library of Science},
	keywords = {Pandemics, Database searching, Epidemiology, Forecasting, Infectious disease surveillance, Influenza, Public and occupational health, Systematic reviews},
	pages = {94130},
	file = {PDF:/Users/jamesscott/Zotero/storage/GQPT58J9/full-text.pdf:application/pdf},
}

@article{nsoesie_systematic_2014-1,
	title = {A systematic review of studies on forecasting the dynamics of influenza outbreaks},
	volume = {8},
	issn = {17502659},
	url = {www.influenzajournal.com},
	doi = {10.1111/irv.12226},
	abstract = {Forecasting the dynamics of influenza outbreaks could be useful for decision-making regarding the allocation of public health resources. Reliable forecasts could also aid in the selection and implementation of interventions to reduce morbidity and mortality due to influenza illness. This paper reviews methods for influenza forecasting proposed during previous influenza outbreaks and those evaluated in hindsight. We discuss the various approaches, in addition to the variability in measures of accuracy and precision of predicted measures. PubMed and Google Scholar searches for articles on influenza forecasting retrieved sixteen studies that matched the study criteria. We focused on studies that aimed at forecasting influenza outbreaks at the local, regional, national, or global level. The selected studies spanned a wide range of regions including USA, Sweden, Hong Kong, Japan, Singapore, United Kingdom, Canada, France, and Cuba. The methods were also applied to forecast a single measure or multiple measures. Typical measures predicted included peak timing, peak height, daily/weekly case counts, and outbreak magnitude. Due to differences in measures used to assess accuracy, a single estimate of predictive error for each of the measures was difficult to obtain. However, collectively, the results suggest that these diverse approaches to influenza forecasting are capable of capturing specific outbreak measures with some degree of accuracy given reliable data and correct disease assumptions. Nonetheless, several of these approaches need to be evaluated and their performance quantified in real-time predictions. © 2013 The Authors. Influenza and Other Respiratory Viruses Published by John Wiley \& Sons Ltd.},
	number = {3},
	urldate = {2021-05-06},
	journal = {Influenza and other Respiratory Viruses},
	author = {Nsoesie, Elaine O. and Brownstein, John S. and Ramakrishnan, Naren and Marathe, Madhav V.},
	month = may,
	year = {2014},
	pmid = {24373466},
	note = {Publisher: Blackwell Publishing},
	keywords = {Infectious diseases, Compartmental models, Individual-based models, Influenza forecasting, Pandemics, Time series models},
	pages = {309--316},
}

@article{Unkel2012,
	title = {Statistical methods for the prospective detection of infectious disease outbreaks: {A} review},
	volume = {175},
	issn = {09641998},
	url = {https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-985X.2011.00714.x},
	doi = {10.1111/j.1467-985X.2011.00714.x},
	abstract = {Unusual clusters of disease must be detected rapidly for effective public health interventions to be introduced. Over the past decade there has been a surge in interest in statistical methods for the early detection of infectious disease outbreaks. This growth in interest has given rise to much new methodological work, ranging across the spectrum of statistical methods. The paper presents a comprehensive review of the statistical approaches that have been proposed. Applications to both laboratory and syndromic surveillance data are provided to illustrate the various methods. © 2011 Royal Statistical Society.},
	number = {1},
	urldate = {2021-05-06},
	journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
	author = {Unkel, Steffen and Farrington, C. Paddy and Garthwaite, Paul H. and Robertson, Chris and Andrews, Nick},
	month = jan,
	year = {2012},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Biosurveillance, Clusters, Control chart, Epidemics, Infectious diseases, Outbreak, Prospective detection, Surveillance},
	pages = {49--82},
}

@article{Myers2000,
	title = {Forecasting disease risk for increased epidemic preparedness in public health},
	volume = {47},
	issn = {0065308X},
	url = {/pmc/articles/PMC3196833/},
	doi = {10.1016/s0065-308x(00)47013-2},
	abstract = {Emerging infectious diseases pose a growing threat to human populations. Many of the world's epidemic diseases (particularly those transmitted by intermediate hosts) are known to be highly sensitive to long-term changes in climate and short-term fluctuations in the weather. The application of environmental data to the study of disease offers the capability to demonstrate vector-environment relationships and potentially forecast the risk of disease outbreaks or epidemics. Accurate disease forecasting models would markedly improve epidemic prevention and control capabilities. This chapter examines the potential for epidemic forecasting and discusses the issues associated with the development of global networks for surveillance and prediction. Existing global systems for epidemic preparedness focus on disease surveillance using either expert knowledge or statistical modelling of disease activity and thresholds to identify times and areas of risk. Predictive health information systems would use monitored environmental variables, linked to a disease system, to be observed and provide prior information of outbreaks. The components and varieties of forecasting systems are discussed with selected examples, along with issues relating to further development.},
	urldate = {2021-05-06},
	journal = {Advances in Parasitology},
	author = {Myers, M. F. and Rogers, D. J. and Cox, J. and Flahault, A. and Hay, S. I.},
	year = {2000},
	pmid = {10997211},
	note = {Publisher: Academic Press},
	pages = {309--330},
	file = {PDF:/Users/jamesscott/Zotero/storage/U6Z9AMYP/full-text.pdf:application/pdf},
}

@article{Flaxman2020MA,
	title = {Reply to: {The} effect of interventions on {COVID}-19},
	volume = {588},
	url = {https://doi.org/10.1038/s41586-020-3026-x},
	doi = {10.1038/s41586-020-3026-x},
	number = {7839},
	journal = {Nature},
	author = {Flaxman, Seth and Mishra, Swapnil and Scott, James and Ferguson, Neil and Gandy, Axel and Bhatt, Samir},
	year = {2020},
	note = {ISBN: 1476-4687},
	pages = {E29--E32},
}

@article{mishra2020,
	title = {On the derivation of the renewal equation from an age-dependent branching process: an epidemic modelling perspective},
	journal = {arXiv preprint arXiv:2006.16487},
	author = {Mishra, Swapnil and Berah, Tresnia and Mellan, Thomas A and Unwin, H Juliette T and Vollmer, Michaela A and Parag, Kris V and Gandy, Axel and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
}

@article{Bhatt2020,
	title = {Semi-{Mechanistic} {Bayesian} {Modeling} of {COVID}-19 with {Renewal} {Processes}},
	url = {https://arxiv.org/abs/2012.00394},
	journal = {arXiv preprint arXiv:2012.00394},
	author = {Bhatt, Samir and Ferguson, Neil and Flaxman, Seth and Gandy, Axel and Mishra, Swapnil and Scott, James A},
	year = {2020},
}

@article{tokuda2011,
	title = {Visualizing distributions of covariance matrices},
	journal = {Columbia Univ., New York, USA, Tech. Rep},
	author = {Tokuda, Tomoki and Goodrich, Ben and Van Mechelen, I and Gelman, Andrew and Tuerlinckx, F},
	year = {2011},
	note = {Publisher: Citeseer},
	pages = {18},
}

@article{kermack_1932,
	title = {Contributions to the mathematical theory of epidemics. {II}. —{The} problem of endemicity},
	volume = {138},
	issn = {0950-1207},
	doi = {10.1098/rspa.1932.0171},
	abstract = {In a previous communication an attempt was made to investigate mathe­matically the course of an epidemic in a closed population of susceptible individuals. In order to simplify the problem certain definite assumptions were made, namely, that all individuals were equally susceptible, and that death resulted, or complete immunity was conferred, as the result of an attack. The infectivity of the individual and his chances of death or recovery were represented by arbitrary functions, and the chance of a new infection occurring was assumed to be proportional to the product of the infected and susceptible members of the population. In spite of the introduction of the arbitrary functions, it was shown that in general a critical density of population existed, such that if the actual density was less than this, no epidemic could occur, but if it exceeded this by n an epidemic would appear on the introduction of a focus of infection, and further that if n was small relative to the population density, the size of the epidemic would be 2 n per unit area. It was shown that these conclusions could be readily extended to the case of a metaxenous disease, that is, one in which transmission takes place through an intermediate host. It is the purpose of the present paper to consider the effect of the continuous introduction of fresh susceptible individuals into the population. It appeared desirable to investigate this point, since it might make it possible to interpret certain aspects of the incidence of disease not only in human communities where there is usually an influx of fresh susceptible individuals either by immigration or by birth, but also in the animal experiments carried out by Topley and others—where fresh animals were introduced at a constant rate into the cages in which cases of disease were already present—from which certain definite results were obtained.},
	number = {834},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	author = {Kermack, William Ogilvy {and} McKendrick, A. G.},
	month = oct,
	year = {1932},
}

@article{kermack_1933,
	title = {Contributions to the mathematical theory of epidemics. {III}.—{Further} studies of the problem of endemicity},
	volume = {141},
	issn = {0950-1207},
	doi = {10.1098/rspa.1933.0106},
	abstract = {In a previous paper (Part II of this series) an attempt was made to treat from a general point of view the problem of a single disease in a population which consisted of three categories of people—namely, never infected, sick and recovered—and in which the infectivity of the disease was a function of the period of illness, whilst the susceptibility of a recovered person was a function of the period which had elapsed since the time of his recovery. New individuals entering the population either by birth or by immigration naturally entered the category of the never infected which for convenience we called “virgins.” It was pointed out that the results obtained were subject to two important limitations: (1) that the disease under consideration was the only cause of death, and (2) that the age of the individuals did not affect their infectivity, susceptibility or reproductiveness. It is the purpose of the present paper to remove the first of these limitations by the introduction of constant non-specific death rates, which for the sake of generality are assumed to be different for virgins, sick, and recovered. It may be stated at once that the introduction of this additional factor produces surprisingly little change in the general nature of the results previously obtained, and that the conclusions of the previous paper hold with very little modifica­tion.},
	number = {843},
	journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
	author = {Kermack, William Ogilvy {and} McKendrick, A. G.},
	month = jul,
	year = {1933},
}

@article{Box_1962,
	title = {Some {Statistical} {Aspects} of {Adaptive} {Optimization} and {Control}},
	volume = {24},
	url = {https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.2517-6161.1962.tb00460.x},
	doi = {10.1111/j.2517-6161.1962.tb00460.x},
	abstract = {It is often necessary to adjust some variable X, such as the concentration of consecutive batches of a product, to keep X close to a specified target value. A second more complicated problem occurs when the independent variables X in a response function ?(X) are to be adjusted so that the derivatives ??/? X are kept close to a target value zero, thus maximizing or minimizing the response. These are shown to be problems of prediction, essentially, and the paper is devoted mainly to the estimation from past data of the "best" adjustments to be applied in the first problem.},
	number = {2},
	urldate = {2021-05-06},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Box, G. E. P. and Jenkins, G. M.},
	month = jul,
	year = {1962},
	note = {Publisher: Wiley},
	pages = {297--331},
}

@article{Roosa_2019,
	title = {Assessing parameter identifiability in compartmental dynamic models using a computational approach: application to infectious disease transmission models},
	volume = {16},
	issn = {1742-4682},
	doi = {10.1186/s12976-018-0097-6},
	number = {1},
	journal = {Theoretical Biology and Medical Modelling},
	author = {Roosa, Kimberlyn and Chowell, Gerardo},
	month = dec,
	year = {2019},
}

@article{Gibbons_2014,
	title = {Measuring underreporting and under-ascertainment in infectious disease datasets: a comparison of methods},
	volume = {14},
	issn = {1471-2458},
	doi = {10.1186/1471-2458-14-147},
	number = {1},
	journal = {BMC Public Health},
	author = {Gibbons, Cheryl L and Mangen, Marie-Josée J and Plass, Dietrich and Havelaar, Arie H and Brooke, Russell John and Kramarz, Piotr and Peterson, Karen L and Stuurman, Anke L and Cassini, Alessandro and Fèvre, Eric M and Kretzschmar, Mirjam EE},
	month = dec,
	year = {2014},
}

@article{bates_fitting_2015-2,
	title = {Fitting linear mixed-effects models using lme4},
	volume = {67},
	issn = {15487660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v067i01},
	doi = {10.18637/jss.v067.i01},
	abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
	number = {1},
	urldate = {2021-05-07},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Benjamin M. and Walker, Steven C.},
	month = oct,
	year = {2015},
	note = {Publisher: American Statistical Association},
	keywords = {Cholesky decomposition, Linear mixed models, Penalized least squares, Sparse matrix methods},
	pages = {1--48},
	file = {PDF:/Users/jamesscott/Zotero/storage/DBZPWIL6/full-text.pdf:application/pdf},
}

@article{hoffman_2014,
	title = {The no-{U}-turn sampler: {Adaptively} setting path lengths in {Hamiltonian} {Monte} {Carlo}},
	volume = {15},
	issn = {15337928},
	abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size e and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more efficiently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter e on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" samplers. © 2014 Matthew D. Hoffman and Andrew Gelman.},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matthew D. and Gelman, Andrew},
	year = {2014},
}

@article{stan_user_guide,
	title = {Stan {Modeling} {Language} {User}’s {Guide} and {Reference} {Manual}, {Version} 2.19.2.},
	abstract = {RSTAN package Stan Development Team (2013). Stan: A C++ Library for Probability and Sampling, Version 2.2.0. URL http://mc-stan.org/. Stan Development Team (2013). Stan Modeling Language User's Guide and Reference Manual, Version 2.2.0. URL http://mc-stan.org/. Hoffman, Matthew D. and Andrew Gelman. In press. The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research.},
	journal = {Interaction Flow Modeling Language},
	author = {{Stan Development Team}},
	year = {2020},
}

@misc{stan_modeling_language,
	title = {Stan {Modeling} {Language}},
	author = {Stan Development Team},
	year = {2017},
	note = {Publication Title: Web},
}

@inproceedings{Kucukelbir_2015,
	title = {Automatic variational inference in {Stan}},
	volume = {2015-January},
	abstract = {Variational inference is a scalable technique for approximate Bayesian inference. Deriving variational inference algorithms requires tedious model-specific calculations; this makes it difficult for non-experts to use. We propose an automatic variational inference algorithm, automatic differentiation variational inference (ADVI); we implement it in Stan (code available), a probabilistic programming system. In ADVI the user provides a Bayesian model and a dataset, nothing else. We make no conjugacy assumptions and support a broad class of models. The algorithm automatically determines an appropriate variational family and optimizes the variational objective. We compare ADVI to MCMC sampling across hierarchical generalized linear models, nonconjugate matrix factorization, and a mixture model. We train the mixture model on a quarter million images. With ADVI we can use variational inference on any model we write in Stan.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kucukelbir, Alp and Ranganath, Rajesh and Gelman, Andrew and Blei, David M.},
	year = {2015},
	note = {ISSN: 10495258},
}

@article{Kucukelbir_2017,
	title = {Automatic {Differentiation} {Variational} {Inference}},
	volume = {18},
	issn = {15337928},
	abstract = {Probabilistic modeling is iterative. A scientist posits a simple model, fits it to her data, refines it according to her analysis, and repeats. However, fitting complex models to large data is a bottleneck in this process. Deriving algorithms for new models can be both mathematically and computationally challenging, which makes it difficult to efficiently cycle through the steps. To this end, we develop automatic differentiation variational inference (advi). Using our method, the scientist only provides a probabilistic model and a dataset, nothing else. advi automatically derives an efficient variational inference algorithm, freeing the scientist to refine and explore many models. advi supports a broad class of models-no conjugacy assumptions are required. We study advi across ten modern probabilistic models and apply it to a dataset with millions of observations. We deploy advi as part of Stan, a probabilistic programming system.},
	journal = {Journal of Machine Learning Research},
	author = {Kucukelbir, Alp and Blei, David M. and Gelman, Andrew and Ranganath, Rajesh and Tran, Dustin},
	year = {2017},
}

@misc{FluSight,
	title = {{FluSight}: {Flu} {Forecasting}},
	url = {https://www.cdc.gov/flu/weekly/flusight/index.html},
	urldate = {2021-05-13},
}

@misc{CDCForecastHub,
	title = {{COVID} 19 forecast hub},
	url = {https://covid19forecasthub.org/},
	urldate = {2021-05-13},
}

@article{Reich_2019,
	title = {Accuracy of real-time multi-model ensemble forecasts for seasonal influenza in the {U}.{S}.},
	volume = {15},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1007486},
	number = {11},
	journal = {PLOS Computational Biology},
	author = {Reich, Nicholas G. and McGowan, Craig J. and Yamana, Teresa K. and Tushar, Abhinav and Ray, Evan L. and Osthus, Dave and Kandula, Sasikiran and Brooks, Logan C. and Crawford-Crudell, Willow and Gibson, Graham Casey and Moore, Evan and Silva, Rebecca and Biggerstaff, Matthew and Johansson, Michael A. and Rosenfeld, Roni and Shaman, Jeffrey},
	month = nov,
	year = {2019},
}

@article{dym_1980,
	title = {Principles of {Mathematical} {Modeling}},
	volume = {48},
	issn = {0002-9505},
	doi = {10.1119/1.12359},
	number = {11},
	journal = {American Journal of Physics},
	author = {Dym, Clive L. and Ivey, Elizabeth S. and Stewart, Maurice Bruce},
	month = nov,
	year = {1980},
}

@article{Volz_2021,
	title = {Assessing transmissibility of {SARS}-{CoV}-2 lineage {B}.1.1.7 in {England}},
	issn = {14764687},
	doi = {10.1038/s41586-021-03470-x},
	abstract = {The SARS-CoV-2 lineage B.1.1.7, designated a Variant of Concern 202012/01 (VOC) by Public Health England1, originated in the UK in late Summer to early Autumn 20202. Whole genome SARS-CoV-2 sequence data collected from community-based diagnostic testing shows an unprecedentedly rapid expansion of the B.1.1.7 lineage during Autumn 2020, suggesting a selective advantage. We find that changes in VOC frequency inferred from genetic data correspond closely to changes inferred by S-gene target failures (SGTF) in community-based diagnostic PCR testing. Analysis of trends in SGTF and non-SGTF case numbers in local areas across England shows that the VOC has higher transmissibility than non-VOC lineages, even if the VOC has a different latent period or generation time. The SGTF data indicate a transient shift in the age composition of reported cases, with a larger share of under 20 year olds among reported VOC than non-VOC cases. Time-varying reproduction numbers for the VOC and cocirculating lineages were estimated using SGTF and genomic data. The best supported models did not indicate a substantial difference in VOC transmissibility among different age groups. There is a consensus among all analyses that the VOC has a substantial transmission advantage with a 50\% to 100\% higher reproduction number.},
	journal = {Nature},
	author = {Volz, Erik and Mishra, Swapnil and Chand, Meera and Barrett, Jeffrey C. and Johnson, Robert and Geidelberg, Lily and Hinsley, Wes R. and Laydon, Daniel J. and Dabrera, Gavin and O’Toole, Áine and Amato, Roberto and Ragonnet-Cronin, Manon and Harrison, Ian and Jackson, Ben and Ariani, Cristina V. and Boyd, Olivia and Loman, Nicholas J. and McCrone, John T. and Gonçalves, Sónia and Jorgensen, David and Myers, Richard and Hill, Verity and Jackson, David K. and Gaythorpe, Katy and Groves, Natalie and Sillitoe, John and Kwiatkowski, Dominic P. and Flaxman, Seth and Ratmann, Oliver and Bhatt, Samir and Hopkins, Susan and Gandy, Axel and Rambaut, Andrew and Ferguson, Neil M.},
	year = {2021},
}

@misc{Vollmer_2020,
	title = {Report 20: {Using} mobility to estimate the transmission intensity of {COVID}-19 in {Italy}: {A} subnational analysis with future scenarios},
	abstract = {Italy was the first European country to experience sustained local transmission of COVID-19. As of 1st May 2020, the Italian health authorities reported 28,238 deaths nationally. To control the epidemic, the Italian government implemented a suite of non-pharmaceutical interventions (NPIs), including school and university closures, social distancing and full lockdown involving banning of public gatherings and non essential movement. In this report, we model the effect of NPIs on transmission using data on average mobility. We estimate that the average reproduction number (a measure of transmission intensity) is currently below one for all Italian regions, and significantly so for the majority of the regions. Despite the large number of deaths, the proportion of population that has been infected by SARS-CoV-2 (the attack rate) is far from the herd immunity threshold in all Italian regions, with the highest attack rate observed in Lombardy (13.18\% [10.66\%-16.70\%]). Italy is set to relax the currently implemented NPIs from 4th May 2020. Given the control achieved by NPIs, we consider three scenarios for the next 8 weeks: a scenario in which mobility remains the same as during the lockdown, a scenario in which mobility returns to pre-lockdown levels by 20\%, and a scenario in which mobility returns to pre-lockdown levels by 40\%. The scenarios explored assume that mobility is scaled evenly across all dimensions, that behaviour stays the same as before NPIs were implemented, that no pharmaceutical interventions are introduced, and it does not include transmission reduction from contact tracing, testing and the isolation of confirmed or suspected cases. New interventions, such as enhanced testing and contact tracing are going to be introduced and will likely contribute to reductions in transmission; therefore our estimates should be viewed as pessimistic projections. We find that, in the absence of additional interventions, even a 20\% return to pre-lockdown mobility could lead to a resurgence in the number of deaths far greater than experienced in the current wave in several regions. Future increases in the number of deaths will lag behind the increase in transmission intensity and so a second wave will not be immediately apparent from just monitoring of the daily number of deaths. Our results suggest that SARS-CoV-2 transmission as well as mobility should be closely monitored in the next weeks and months. To compensate for the increase in mobility that will occur due to the relaxation of the currently implemented NPIs, adherence to the recommended social distancing measures alongside enhanced community surveillance including swab testing, contact tracing and the early isolation of infections are of paramount importance to reduce the risk of resurgence in transmission.},
	author = {Vollmer, Michaela A.C. and Mishra, Swapnil and T Unwin, H. Juliette and Gandy, Axel and Mellan, Thomas A. and Bradley, Valerie and Zhu, Harrison and Coupland, Helen and Hawryluk, Iwona and Hutchinson, Michael and Ratmann, Oliver and Monod, Melodie and Walker, Patrick and Whittaker, Charlie and Cattarino, Lorenzo and Ciavarella, Constance and Cilloni, Lucia and Ainslie, Kylie and Baguelin, Marc and Bhatia, Sangeeta and Boonyasiri, Adhiratha and Brazeau, Nicholas and Charles, Giovanni and Cooper, Laura V. and Cucunuba, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Djaafara, Bimandra and Eaton, Jeff and van Elsland, Sabine L. and FitzJohn, Richard and Fraser, Keith and Gaythorpe, Katy and Green, Will and Hayes, Sarah and Imai, Natsuko and Jeffrey, Ben and Knock, Edward and Laydon, Daniel and Lees, John and Mangal, Tara and Mousa, Andria and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Olivera, Daniela and Parag, Kris V. and Pickles, Michael and Thompson, Hayley A. and Verity, Robert and Walters, Caroline and Wang, Haowei and Wang, Yuanrong and Watson, Oliver J. and Whittles, Lilith and Xi, Xiaoyue and Ghani, Azra and Riley, Steven M. and Okell, Lucy and Donnelly, Christl A. and Ferguson, Neil M. and Dorigatti, Ilaria and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
	doi = {10.1101/2020.05.05.20089359},
	note = {Publication Title: medRxiv},
}

@misc{Mellan_2020,
	title = {Subnational analysis of the {COVID}-19 epidemic in {Brazil}},
	abstract = {Brazil is currently reporting the second highest number of COVID-19 deaths in the world. Here we characterise the initial dynamics of COVID-19 across the country and assess the impact of non-pharmaceutical interventions (NPIs) that were implemented using a semi-mechanistic Bayesian hierarchical modelling approach. Our results highlight the significant impact these NPIs had across states, reducing an average Rt {\textgreater} 3 to an average of 1.5 by 9-May-2020, but that these interventions failed to reduce Rt {\textless} 1, congruent with the worsening epidemic Brazil has experienced since. We identify extensive heterogeneity in the epidemic trajectory across Brazil, with the estimated number of days to reach 0.1\% of the state population infected since the first nationally recorded case ranging from 20 days in São Paulo compared to 60 days in Goiás, underscoring the importance of sub-national analyses in understanding asynchronous state-level epidemics underlying the national spread and burden of COVID-19.},
	author = {Mellan, Thomas A. and Hoeltgebaum, Henrique H. and Mishra, Swapnil and Whittaker, Charlie and Schnekenberg, Ricardo P. and Gandy, Axel and Unwin, H. Juliette T. and Vollmer, Michaela A.C. and Coupland, Helen and Hawryluk, Iwona and Faria, Nuno Rodrigues and Vesga, Juan and Zhu, Harrison and Hutchinson, Michael and Ratmann, Oliver and Monod, Mélodie and Ainslie, Kylie E.C. and Baguelin, Marc and Bhatia, Sangeeta and Boonyasiri, Adhiratha and Brazeau, Nicholas and Charles, Giovanni and Cucunuba, Zulma and Cuomo-Dannenburg, Gina and Dighe, Amy and Eaton, Jeff and van Elsland, Sabine L. and Gaythorpe, Katy A.M. and Green, Will and Knock, Edward and Laydon, Daniel and Lees, John A. and Mousa, Andria and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Parag, Kris V. and Thompson, Hayley A. and Verity, Robert and Walters, Caroline E. and Wang, Haowei and Wang, Yuanrong and Watson, Oliver J. and Whittles, Lilith and Xi, Xiaoyue and Dorigatti, Ilaria and Walker, Patrick and Ghani, Azra C. and Riley, Steven and Ferguson, Neil M. and Donnelly, Christl A. and Flaxman, Seth and Bhatt, Samir},
	year = {2020},
	doi = {10.1101/2020.05.09.20096701},
	note = {Publication Title: medRxiv},
}

@article{Unwin_2020,
	title = {State-level tracking of {COVID}-19 in the {United} {States}},
	volume = {11},
	issn = {20411723},
	doi = {10.1038/s41467-020-19652-6},
	abstract = {As of 1st June 2020, the US Centres for Disease Control and Prevention reported 104,232 confirmed or probable COVID-19-related deaths in the US. This was more than twice the number of deaths reported in the next most severely impacted country. We jointly model the US epidemic at the state-level, using publicly available death data within a Bayesian hierarchical semi-mechanistic framework. For each state, we estimate the number of individuals that have been infected, the number of individuals that are currently infectious and the time-varying reproduction number (the average number of secondary infections caused by an infected person). We use changes in mobility to capture the impact that non-pharmaceutical interventions and other behaviour changes have on the rate of transmission of SARS-CoV-2. We estimate that Rt was only below one in 23 states on 1st June. We also estimate that 3.7\% [3.4\%–4.0\%] of the total population of the US had been infected, with wide variation between states, and approximately 0.01\% of the population was infectious. We demonstrate good 3 week model forecasts of deaths with low error and good coverage of our credible intervals.},
	number = {1},
	journal = {Nature Communications},
	author = {Unwin, H. Juliette T. and Mishra, Swapnil and Bradley, Valerie C. and Gandy, Axel and Mellan, Thomas A. and Coupland, Helen and Ish-Horowicz, Jonathan and Vollmer, Michaela A.C. and Whittaker, Charles and Filippi, Sarah L. and Xi, Xiaoyue and Monod, Mélodie and Ratmann, Oliver and Hutchinson, Michael and Valka, Fabian and Zhu, Harrison and Hawryluk, Iwona and Milton, Philip and Ainslie, Kylie E.C. and Baguelin, Marc and Boonyasiri, Adhiratha and Brazeau, Nick F. and Cattarino, Lorenzo and Cucunuba, Zulma and Cuomo-Dannenburg, Gina and Dorigatti, Ilaria and Eales, Oliver D. and Eaton, Jeffrey W. and van Elsland, Sabine L. and FitzJohn, Richard G. and Gaythorpe, Katy A.M. and Green, William and Hinsley, Wes and Jeffrey, Benjamin and Knock, Edward and Laydon, Daniel J. and Lees, John and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Okell, Lucy and Parag, Kris V. and Siveroni, Igor and Thompson, Hayley A. and Walker, Patrick and Walters, Caroline E. and Watson, Oliver J. and Whittles, Lilith K. and Ghani, Azra C. and Ferguson, Neil M. and Riley, Steven and Donnelly, Christl A. and Bhatt, Samir and Flaxman, Seth},
	year = {2020},
}

@article{Faria_2021,
	title = {Genomics and epidemiology of the {P}.1 {SARS}-{CoV}-2 lineage in {Manaus}, {Brazil}},
	issn = {0036-8075},
	doi = {10.1126/science.abh2644},
	abstract = {{\textless}p{\textgreater}Cases of SARS-CoV-2 infection in Manaus, Brazil, resurged in late 2020, despite previously high levels of infection. Genome sequencing of viruses sampled in Manaus between November 2020 and January 2021 revealed the emergence and circulation of a novel SARS-CoV-2 variant of concern. Lineage P.1, acquired 17 mutations, including a trio in the spike protein (K417T, E484K and N501Y) associated with increased binding to the human ACE2 receptor. Molecular clock analysis shows that P.1 emergence occurred around mid-November 2020 and was preceded by a period of faster molecular evolution. Using a two-category dynamical model that integrates genomic and mortality data, we estimate that P.1 may be 1.7–2.4-fold more transmissible, and that previous (non-P.1) infection provides 54–79\% of the protection against infection with P.1 that it provides against non-P.1 lineages. Enhanced global genomic surveillance of variants of concern, which may exhibit increased transmissibility and/or immune evasion, is critical to accelerate pandemic responsiveness.{\textless}/p{\textgreater}},
	journal = {Science},
	author = {Faria, Nuno R. and Mellan, Thomas A. and Whittaker, Charles and Claro, Ingra M. and Candido, Darlan da S. and Mishra, Swapnil and Crispim, Myuki A. E. and Sales, Flavia C. S. and Hawryluk, Iwona and McCrone, John T. and Hulswit, Ruben J. G. and Franco, Lucas A. M. and Ramundo, Mariana S. and de Jesus, Jaqueline G. and Andrade, Pamela S. and Coletti, Thais M. and Ferreira, Giulia M. and Silva, Camila A. M. and Manuli, Erika R. and Pereira, Rafael H. M. and Peixoto, Pedro S. and Kraemer, Moritz U. G. and Gaburo, Nelson and Camilo, Cecilia da C. and Hoeltgebaum, Henrique and Souza, William M. and Rocha, Esmenia C. and de Souza, Leandro M. and de Pinho, Mariana C. and Araujo, Leonardo J. T and Malta, Frederico S. V. and de Lima, Aline B. and Silva, Joice do P. and Zauli, Danielle A. G. and Ferreira, Alessandro C. de S. and Schnekenberg, Ricardo P and Laydon, Daniel J. and Walker, Patrick G. T. and Schlüter, Hannah M. and dos Santos, Ana L. P. and Vidal, Maria S. and Del Caro, Valentina S. and Filho, Rosinaldo M. F. and dos Santos, Helem M. and Aguiar, Renato S. and Proença-Modena, José L. and Nelson, Bruce and Hay, James A. and Monod, Mélodie and Miscouridou, Xenia and Coupland, Helen and Sonabend, Raphael and Vollmer, Michaela and Gandy, Axel and Prete, Carlos A. and Nascimento, Vitor H. and Suchard, Marc A. and Bowden, Thomas A. and Pond, Sergei L. K. and Wu, Chieh-Hsi and Ratmann, Oliver and Ferguson, Neil M. and Dye, Christopher and Loman, Nick J. and Lemey, Philippe and Rambaut, Andrew and Fraiji, Nelson A. and Carvalho, Maria do P. S. S. and Pybus, Oliver G. and Flaxman, Seth and Bhatt, Samir and Sabino, Ester C.},
	month = apr,
	year = {2021},
}

@article{olney_2021,
	title = {Estimating the {Effect} of {Social} {Distancing} {Interventions} on {COVID}-19 in the {United} {States}},
	issn = {0002-9262},
	doi = {10.1093/aje/kwaa293},
	abstract = {{\textless}p{\textgreater}Since its global emergence in 2020, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused multiple epidemics in the United States. Because medical treatments for the virus are still emerging and a vaccine is not yet available, state and local governments have sought to limit its spread by enacting various social distancing interventions such as school closures and lockdown, but the effectiveness of these interventions is unknown. We applied an established, semi-mechanistic Bayesian hierarchical model of these interventions on SARS-CoV-2 spread in Europe to the United States, using case fatalities from February 29, 2020 up to April 25, 2020, when some states began reversing their interventions. We estimated the effect of interventions across all states, contrasted the estimated reproduction number, Rt, for each state before and after lockdown, and contrasted predicted future fatalities with actual fatalities as a check on the model’s validity. Overall, school closures and lockdown are the only interventions modeled that have a reliable impact on Rt, and lockdown appears to have played a key role in reducing Rt below 1.0. We conclude that reversal of lockdown, without implementation of additional, equally effective interventions, will enable continued, sustained transmission of SARS-CoV-2 in the United States.{\textless}/p{\textgreater}},
	journal = {American Journal of Epidemiology},
	author = {Olney, Andrew M and Smith, Jesse and Sen, Saunak and Thomas, Fridtjof and Unwin, H Juliette T},
	month = jan,
	year = {2021},
}

@article{Hawryluk_2020,
	title = {Inference of {COVID}-19 epidemiological distributions from {Brazilian} hospital data},
	volume = {17},
	issn = {1742-5689},
	doi = {10.1098/rsif.2020.0596},
	abstract = {{\textless}p{\textgreater} Knowing COVID-19 epidemiological distributions, such as the time from patient admission to death, is directly relevant to effective primary and secondary care planning, and moreover, the mathematical modelling of the pandemic generally. We determine epidemiological distributions for patients hospitalized with COVID-19 using a large dataset ( {\textless}italic{\textgreater}N{\textless}/italic{\textgreater} = 21 000 − 157 000) from the Brazilian Sistema de Informação de Vigilância Epidemiológica da Gripe database. A joint Bayesian subnational model with partial pooling is used to simultaneously describe the 26 states and one federal district of Brazil, and shows significant variation in the mean of the symptom-onset-to-death time, with ranges between 11.2 and 17.8 days across the different states, and a mean of 15.2 days for Brazil. We find strong evidence in favour of specific probability density function choices: for example, the gamma distribution gives the best fit for onset-to-death and the generalized lognormal for onset-to-hospital-admission. Our results show that epidemiological distributions have considerable geographical variation, and provide the first estimates of these distributions in a low and middle-income setting. At the subnational level, variation in COVID-19 outcome timings are found to be correlated with poverty, deprivation and segregation levels, and weaker correlation is observed for mean age, wealth and urbanicity. {\textless}/p{\textgreater}},
	number = {172},
	journal = {Journal of The Royal Society Interface},
	author = {Hawryluk, Iwona and Mellan, Thomas A. and Hoeltgebaum, Henrique and Mishra, Swapnil and Schnekenberg, Ricardo P. and Whittaker, Charles and Zhu, Harrison and Gandy, Axel and Donnelly, Christl A. and Flaxman, Seth and Bhatt, Samir},
	month = nov,
	year = {2020},
}

@article{obadia_2012,
	title = {The {R0} package: a toolbox to estimate reproduction numbers for epidemic outbreaks},
	volume = {12},
	issn = {1472-6947},
	doi = {10.1186/1472-6947-12-147},
	number = {1},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Obadia, Thomas and Haneef, Romana and Boëlle, Pierre-Yves},
	month = dec,
	year = {2012},
}

@book{Anderson_2000,
	address = {New York, NY},
	title = {Stochastic {Epidemic} {Models} and {Their} {Statistical} {Analysis}},
	volume = {151},
	isbn = {978-0-387-95050-1},
	publisher = {Springer New York},
	author = {Andersson, Håkan and Britton, Tom},
	year = {2000},
	doi = {10.1007/978-1-4612-1158-7},
}

@article{hohle_2007,
	title = {{RLadyBug}—{An} {R} package for stochastic epidemic models},
	volume = {52},
	issn = {01679473},
	doi = {10.1016/j.csda.2006.11.016},
	number = {2},
	journal = {Computational Statistics {\textbackslash}\& Data Analysis},
	author = {Höhle, Michael and Feldmann, Ulrike},
	month = oct,
	year = {2007},
}

@article{merl_2010,
	title = {\textbf{amei} : {An} \textit{{R}} {Package} for the {Adaptive} {Management} of {Epidemiological} {Interventions}},
	volume = {36},
	issn = {1548-7660},
	doi = {10.18637/jss.v036.i06},
	number = {6},
	journal = {Journal of Statistical Software},
	author = {Merl, Daniel and Johnson, Leah R. and Gramacy, Robert B. and Mangel, Marc},
	year = {2010},
}

@article{Groendyke_2018,
	title = {\textbf{epinet} : {An} \textit{{R}} {Package} to {Analyze} {Epidemics} {Spread} across {Contact} {Networks}},
	volume = {83},
	issn = {1548-7660},
	doi = {10.18637/jss.v083.i11},
	number = {11},
	journal = {Journal of Statistical Software},
	author = {Groendyke, Chris and Welch, David},
	year = {2018},
}

@article{Jenness_2018,
	title = {\textbf{{EpiModel}} : {An} \textit{{R}} {Package} for {Mathematical} {Modeling} of {Infectious} {Disease} over {Networks}},
	volume = {84},
	issn = {1548-7660},
	doi = {10.18637/jss.v084.i08},
	number = {8},
	journal = {Journal of Statistical Software},
	author = {Jenness, Samuel M. and Goodreau, Steven M. and Morris, Martina},
	year = {2018},
}

@misc{recon,
	title = {The {R} {Epidemics} {Consortium}},
	url = {https://www.repidemicsconsortium.org/},
}

@misc{cran,
	title = {The {Comprehensive} {R} {Archive} {Network}},
}

@misc{Vasileios_2015,
	title = {acp: {Autoregressive} {Conditional} {Poisson}},
	url = {https://cran.r-project.org/package=acp},
	author = {Vasileios, Siakoulis},
	year = {2015},
	annote = {R package version 2.1},
}

@article{Liboschik_2017,
	title = {\{tscount\}: {An} \{{R}\} {Package} for {Analysis} of {Count} {Time} {Series} {Following} {Generalized} {Linear} {Models}},
	volume = {82},
	doi = {10.18637/jss.v082.i05},
	number = {5},
	journal = {Journal of Statistical Software},
	author = {Liboschik, Tobias and Fokianos, Konstantinos and Fried, Roland},
	year = {2017},
	pages = {1--51},
}

@article{Meyer_2017,
	title = {Spatio-{Temporal} {Analysis} of {Epidemic} {Phenomena} {Using} the \textit{{R}} {Package} \textbf{surveillance}},
	volume = {77},
	issn = {1548-7660},
	doi = {10.18637/jss.v077.i11},
	number = {11},
	journal = {Journal of Statistical Software},
	author = {Meyer, Sebastian and Held, Leonhard and Höhle, Michael},
	year = {2017},
}

@article{Held_2005,
	title = {A statistical framework for the analysis of multivariate infectious disease surveillance counts},
	volume = {5},
	issn = {1471-082X},
	doi = {10.1191/1471082X05st098oa},
	abstract = {{\textless}p{\textgreater}A framework for the statistical analysis of counts from infectious disease surveillance databases is proposed. In its simplest form, the model can be seen as a Poisson branching process model with immigration. Extensions to include seasonal effects, time trends and overdispersion are outlined. The model is shown to provide an adequate fit and reliable one-step-ahead prediction intervals for a typical infectious disease time series. In addition, a multivariate formulation is proposed, which is well suited to capture space-time dependence caused by the spatial spread of a disease over time. An analysis of two multivariate time series is described. All analyses have been done using general optimization routines, where ML estimates and corresponding standard errors are readily available.{\textless}/p{\textgreater}},
	number = {3},
	journal = {Statistical Modelling},
	author = {Held, Leonhard and Höhle, Michael and Hofmann, Mathias},
	month = oct,
	year = {2005},
}

@article{Paul_2008,
	title = {Multivariate modelling of infectious disease surveillance data},
	volume = {27},
	issn = {02776715},
	doi = {10.1002/sim.3440},
	number = {29},
	journal = {Statistics in Medicine},
	author = {Paul, M. and Held, L. and Toschke, A. M.},
	month = dec,
	year = {2008},
}

@article{Paul_2011,
	title = {Predictive assessment of a non-linear random effects model for multivariate time series of infectious disease counts},
	volume = {30},
	issn = {02776715},
	doi = {10.1002/sim.4177},
	number = {10},
	journal = {Statistics in Medicine},
	author = {Paul, M. and Held, L.},
	month = may,
	year = {2011},
}

@article{Held_2012,
	title = {Modeling seasonality in space-time infectious disease surveillance data},
	volume = {54},
	issn = {03233847},
	doi = {10.1002/bimj.201200037},
	number = {6},
	journal = {Biometrical Journal},
	author = {Held, Leonhard and Paul, Michaela},
	month = nov,
	year = {2012},
}

@article{Hauser_2020,
	title = {Estimation of {SARS}-{CoV}-2 mortality during the early stages of an epidemic: {A} modeling study in {Hubei}, {China}, and six regions in {Europe}},
	volume = {17},
	issn = {1549-1676},
	doi = {10.1371/journal.pmed.1003189},
	number = {7},
	journal = {PLOS Medicine},
	author = {Hauser, Anthony and Counotte, Michel J. and Margossian, Charles C. and Konstantinoudis, Garyfallos and Low, Nicola and Althaus, Christian L. and Riou, Julien},
	month = jul,
	year = {2020},
}

@article{Doremalen_2020,
	title = {Aerosol and {Surface} {Stability} of {SARS}-{CoV}-2 as {Compared} with {SARS}-{CoV}-1},
	volume = {382},
	issn = {0028-4793},
	doi = {10.1056/NEJMc2004973},
	number = {16},
	journal = {New England Journal of Medicine},
	author = {van Doremalen, Neeltje and Bushmaker, Trenton and Morris, Dylan H. and Holbrook, Myndi G. and Gamble, Amandine and Williamson, Brandi N. and Tamin, Azaibi and Harcourt, Jennifer L. and Thornburg, Natalie J. and Gerber, Susan I. and Lloyd-Smith, James O. and de Wit, Emmie and Munster, Vincent J.},
	month = apr,
	year = {2020},
}

@article{Chatzilena_2019,
	title = {Contemporary statistical inference for infectious disease models using {Stan}},
	volume = {29},
	issn = {17554365},
	doi = {10.1016/j.epidem.2019.100367},
	journal = {Epidemics},
	author = {Chatzilena, Anastasia and van Leeuwen, Edwin and Ratmann, Oliver and Baguelin, Marc and Demiris, Nikolaos},
	month = dec,
	year = {2019},
}

@article{Olney_2021,
	title = {Estimating the {Effect} of {Social} {Distancing} {Interventions} on {COVID}-19 in the {United} {States}},
	issn = {0002-9262},
	doi = {10.1093/aje/kwaa293},
	abstract = {{\textless}p{\textgreater}Since its global emergence in 2020, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused multiple epidemics in the United States. Because medical treatments for the virus are still emerging and a vaccine is not yet available, state and local governments have sought to limit its spread by enacting various social distancing interventions such as school closures and lockdown, but the effectiveness of these interventions is unknown. We applied an established, semi-mechanistic Bayesian hierarchical model of these interventions on SARS-CoV-2 spread in Europe to the United States, using case fatalities from February 29, 2020 up to April 25, 2020, when some states began reversing their interventions. We estimated the effect of interventions across all states, contrasted the estimated reproduction number, Rt, for each state before and after lockdown, and contrasted predicted future fatalities with actual fatalities as a check on the model’s validity. Overall, school closures and lockdown are the only interventions modeled that have a reliable impact on Rt, and lockdown appears to have played a key role in reducing Rt below 1.0. We conclude that reversal of lockdown, without implementation of additional, equally effective interventions, will enable continued, sustained transmission of SARS-CoV-2 in the United States.{\textless}/p{\textgreater}},
	journal = {American Journal of Epidemiology},
	author = {Olney, Andrew M and Smith, Jesse and Sen, Saunak and Thomas, Fridtjof and Unwin, H Juliette T},
	month = jan,
	year = {2021},
}

@misc{Grinsztajn_2021,
	title = {Bayesian workflow for disease transmission modeling in {Stan}},
	author = {Grinsztajn, Léo and Semenova, Elizaveta and Margossian, Charles C and Riou, Julien},
	year = {2021},
}

@article{Gelman_2013,
	title = {Philosophy and the practice of {Bayesian} statistics},
	volume = {66},
	issn = {00071102},
	doi = {10.1111/j.2044-8317.2011.02037.x},
	number = {1},
	journal = {British Journal of Mathematical and Statistical Psychology},
	author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
	month = feb,
	year = {2013},
}

@article{Gelman_2008,
	title = {A weakly informative default prior distribution for logistic and other regression models},
	volume = {2},
	issn = {1932-6157},
	doi = {10.1214/08-AOAS191},
	number = {4},
	journal = {The Annals of Applied Statistics},
	author = {Gelman, Andrew and Jakulin, Aleks and Pittau, Maria Grazia and Su, Yu-Sung},
	month = dec,
	year = {2008},
}

@article{Wong_2020,
	title = {Evidence that coronavirus superspreading is fat-tailed},
	volume = {117},
	issn = {0027-8424},
	doi = {10.1073/pnas.2018490117},
	abstract = {{\textless}p{\textgreater}Superspreaders, infected individuals who result in an outsized number of secondary cases, are believed to underlie a significant fraction of total SARS-CoV-2 transmission. Here, we combine empirical observations of SARS-CoV and SARS-CoV-2 transmission and extreme value statistics to show that the distribution of secondary cases is consistent with being fat-tailed, implying that large superspreading events are extremal, yet probable, occurrences. We integrate these results with interaction-based network models of disease transmission and show that superspreading, when it is fat-tailed, leads to pronounced transmission by increasing dispersion. Our findings indicate that large superspreading events should be the targets of interventions that minimize tail exposure.{\textless}/p{\textgreater}},
	number = {47},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Wong, Felix and Collins, James J.},
	month = nov,
	year = {2020},
}

@misc{ECDCForecastHub,
	title = {European {Covid}-19 {Forecast} {Hub}},
	url = {https://covid19forecasthub.eu/},
	urldate = {2021-05-25},
}

@misc{PHE,
	title = {Official {UK} {Coronavirus} {Dashboard}},
	url = {https://coronavirus.data.gov.uk/details/cases},
	author = {{Public Health England}},
	month = nov,
	year = {2020},
}

@misc{ons_antibody,
	title = {Coronavirus ({COVID}-19) antibody and vaccination data for the {UK} - {Office} for {National} {Statistics}},
	url = {https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/datasets/coronaviruscovid19antibodydatafortheuk},
	urldate = {2021-06-01},
	file = {Coronavirus (COVID-19) antibody and vaccination data for the UK - Office for National Statistics:/Users/jamesscott/Zotero/storage/AP8LCWUV/coronaviruscovid19antibodydatafortheuk.html:text/html},
}

@misc{ons_infections,
	title = {Coronavirus ({COVID}-19) {Infection} {Survey}: {England} - {Office} for {National} {Statistics}},
	url = {https://www.ons.gov.uk/peoplepopulationandcommunity/healthandsocialcare/conditionsanddiseases/datasets/coronaviruscovid19infectionsurveydata},
	urldate = {2021-06-01},
	file = {Coronavirus (COVID-19) Infection Survey\: England - Office for National Statistics:/Users/jamesscott/Zotero/storage/LPJ4XGDC/coronaviruscovid19infectionsurveydata.html:text/html},
}

@misc{ons_pop,
	title = {Population estimates for the {UK}, {England} and {Wales}, {Scotland} and {Northern} {Ireland} - {Office} for {National} {Statistics}},
	url = {https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/bulletins/annualmidyearpopulationestimates/latest},
	urldate = {2021-06-01},
	file = {Population estimates for the UK, England and Wales, Scotland and Northern Ireland - Office for National Statistics:/Users/jamesscott/Zotero/storage/E7X3SVP8/latest.html:text/html},
}
